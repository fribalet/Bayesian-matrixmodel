{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SeaFlow data (regridded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "import netCDF4 as nc4\n",
    "import numpy as np\n",
    "\n",
    "# load data\n",
    "datafile = 'data/SeaFlow_SizeDist_regrid-15-5.nc'\n",
    "\n",
    "data_seaflow = {}\n",
    "with nc4.Dataset(datafile) as nc:\n",
    "    for var in nc.variables:\n",
    "        data_seaflow[var] = nc.variables[var][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_min = data_seaflow['v_min']\n",
    "delta_v = 1.0/data_seaflow['delta_v_inv']\n",
    "v = v_min * 2**(np.arange(data_seaflow['m'])*delta_v) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model\n",
    "\n",
    "modified from *Sosik et al. (2003), Growth rates of coastal phytoplankton from time-series measurements with a submersible flow cytometer, Limnol. Oceanogr.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_code = '''data {\n",
    "    // size variables\n",
    "    int<lower=0> m;              // number of size classes\n",
    "    int<lower=0> nt;             // number of timesteps\n",
    "    int<lower=0> nt_obs;         // number of timesteps with observations\n",
    "    int<lower=0> dt;             // delta t in minutes\n",
    "    real<lower=0> E[nt];         // vector of incident radiation values\n",
    "    real<lower=0> v_min;         // size in smallest size class in um^-3\n",
    "    int<lower=0> delta_v_inv;    // inverse of delta_v \n",
    "    simplex[m] w_ini;            // initial conditions \n",
    "    real<lower=0,upper=nt*dt>  t_obs[nt_obs];     // the time of each observation\n",
    "    real<lower=0> obs[m,nt_obs];                  // observations\n",
    "    int<lower=0,upper=1> i_test[nt_obs];          // vector of 0s and 1s indicating which obs to leave as test\n",
    "}\n",
    "transformed data {\n",
    "    int j;\n",
    "    real<lower=0> delta_v;\n",
    "    real<lower=0> dt_days;                  // dt in units of days\n",
    "    real<lower=0> v[m];                     // vector of (minimum) sizes for each size class\n",
    "    int<lower=0> t[nt];                     // vector of times in minutes since start \n",
    "    int<lower=1, upper=nt> it_obs[nt_obs];  // the time index of each observation\n",
    "    int<lower=0> n_test;                    // number of test observations\n",
    "    \n",
    "    n_test = sum(i_test);               // calculate number of test observations as sum of indicator vector\n",
    "    \n",
    "    //DEFINE SIZE VECTOR\n",
    "    j        = 1 + delta_v_inv;         // define j index\n",
    "    delta_v  = 1.0/delta_v_inv;         // size increment         \n",
    "    dt_days  = dt/1440.0;               // dt expressed in days\n",
    "    for (i in 1:m){\n",
    "        v[i] = v_min*2^((i-1)*delta_v); // center of size bins\n",
    "    }\n",
    "\n",
    "    //DEFINE TIME VECTOR\n",
    "    t[1] = 0;                  //\n",
    "    for (i in 2:nt){\n",
    "        t[i] = (t[i-1] + dt);\n",
    "    }\n",
    "    \n",
    "    //DEFINE INDEX VECTOR\n",
    "    for (k in 1:nt_obs){\n",
    "        for (i in 1:nt){\n",
    "            if (t_obs[k]>=t[i] && t_obs[k]<t[i]+dt){\n",
    "                it_obs[k] = i;\n",
    "                break;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "parameters {\n",
    "    real<lower=0>             delta_mu; \n",
    "    real<lower=0>             delta_sigma; \n",
    "    real<lower=0>             delta_max[m-j+1]; \n",
    "    real<lower=0>             gamma_max;\n",
    "    real<lower=0, upper=5000> E_star; \n",
    "    real<lower=1e-10>         sigma; \n",
    "}\n",
    "transformed parameters {\n",
    "    matrix[m,nt_obs] mod_obspos;\n",
    "       {vector[m] w_curr;   // declare vector to hold current state \n",
    "        vector[m] w_next;   // declare vector to hold next state\n",
    "        real delta_i;       // declare division rate\n",
    "        real gamma;         // declare growth rate\n",
    "        real a;             // declare allometric parameter\n",
    "        real tmp;           \n",
    "        int ito = 1;\n",
    "        \n",
    "        w_curr = w_ini;     // set initial condition according to the first observation\n",
    "\n",
    "        for (it in 1:nt){                   // time-stepping loop\n",
    "            if (it == it_obs[ito]){         // record current solution if we need to compare to obs \n",
    "                mod_obspos[,ito] = w_curr;  // record current state in mod_obspos to compare with obs\n",
    "                ito += 1;                   \n",
    "                if (ito > nt_obs){\n",
    "                    break;\n",
    "                }\n",
    "            }\n",
    "\n",
    "            gamma = gamma_max * dt_days * (1.0 - exp(-E[it]/E_star));  // compute current growth rate according to light\n",
    "            w_next = rep_vector(0.0, m);                               // initialize state vector for next time\n",
    "            for (i in 1:m){                                  // size-class loop\n",
    "                if (i >= j){                                 \n",
    "                    delta_i = delta_max[i-j+1] * dt_days;    // size-specific delta_max\n",
    "                }\n",
    "                // fill subdiagonal (growth)\n",
    "                if (i < j){\n",
    "                    //A[i+1,i] = gamma;\n",
    "                    a = gamma;\n",
    "                    w_next[i+1] += a * w_curr[i];\n",
    "                } else if (i < m){\n",
    "                    //A[i+1,i] = gamma * (1.0-delta_i);\n",
    "                    a = gamma * (1.0-delta_i);\n",
    "                    w_next[i+1] += a * w_curr[i];\n",
    "                }\n",
    "                // fill (j-1)th superdiagonal (division)\n",
    "                if (i >= j){\n",
    "                    //A[i+1-j,i] = 2.0*delta_i;\n",
    "                    a = 2.0*delta_i;\n",
    "                    w_next[i+1-j] += a * w_curr[i];\n",
    "                }\n",
    "                // fill diagonal (stasis)\n",
    "                if (i < j){\n",
    "                    //A[i,i] = (1.0-gamma);\n",
    "                    a = (1.0-gamma);\n",
    "                    w_next[i] += a * w_curr[i];\n",
    "                } else if (i == m){\n",
    "                    //A[i,i] = (1.0-delta_i);\n",
    "                    a = (1.0-delta_i);\n",
    "                    w_next[i] += a * w_curr[i];\n",
    "                } else {\n",
    "                    //A[i,i] = (1.0-gamma) * (1.0-delta_i);\n",
    "                    a = (1.0-gamma) * (1.0-delta_i);\n",
    "                    w_next[i] += a * w_curr[i];\n",
    "                }\n",
    "            }\n",
    "            w_curr = w_next ./ sum(w_next);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "model {\n",
    "    real diff;\n",
    "    \n",
    "    // priors\n",
    "    delta_mu ~ normal(66.0, 1.0);\n",
    "    delta_sigma ~ normal(5.0, 1.0);\n",
    "    delta_max ~ normal(delta_mu, delta_sigma); // T[0.0,1440.0/dt];\n",
    "    gamma_max ~ uniform(0.0,1440.0/dt);\n",
    "    E_star ~ normal(3000.0,10.0);\n",
    "    sigma ~ exponential(1000.0);\n",
    "\n",
    "    // fitting observations\n",
    "    for (it in 1:nt_obs){\n",
    "        diff = 0.0;\n",
    "        if(i_test[it] == 0){\n",
    "        for (iv in 1:m){\n",
    "            diff += fabs(mod_obspos[iv,it] - obs[iv,it]);\n",
    "        }\n",
    "        diff = diff/sigma;\n",
    "        diff ~ normal(0.0, 1.0) T[0,];\n",
    "    }\n",
    "    }\n",
    "}\n",
    "generated quantities{\n",
    "    vector[n_test] log_like_test;   // vector of test obs likelihoods\n",
    "    {int k=1;                       // start counter for log_like_test vector; put in brackets so variables are local\n",
    "    real diff;                      // declare error variable\n",
    "    for(it in 1:nt_obs){            // loop over all observations\n",
    "        if(i_test[it] == 1){        // is this a test observation?\n",
    "        diff = 0.0;                 // start error variable at zero\n",
    "        for(iv in 1:m){             // loop over size classes\n",
    "            diff += fabs(mod_obspos[iv,it] - obs[iv,it]);  // accumulate error increment from each size class\n",
    "        }\n",
    "        diff = diff/sigma;                                 // normalize error to have unit standard deviation\n",
    "        log_like_test[k] = normal_lpdf(diff | 0.0, 1.0);   // compute test likelihood\n",
    "        k += 1;                     // step log_like_test index\n",
    "        }\n",
    "    }}\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for Stan model\n",
    "\n",
    "dt = 20 # in units of minutes\n",
    "\n",
    "data = {'dt':dt}\n",
    "for k in ('m','v_min','delta_v_inv'):\n",
    "    data[k] = data_seaflow[k]\n",
    "\n",
    "data['obs'] = data_seaflow['w_obs']\n",
    "data['t_obs'] = data_seaflow['time']\n",
    "data['E'] = data_seaflow['PAR']\n",
    "# use first measurements as initial conditions\n",
    "data['w_ini'] = data_seaflow['w_obs'][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove very first observations\n",
    "ind_obs = data['t_obs'] > 3\n",
    "data['t_obs'] = data['t_obs'][ind_obs]\n",
    "data['obs'] = data['obs'][:,ind_obs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the data\n",
    "\n",
    "limit_days = 3\n",
    "stride_t_obs = 20\n",
    "\n",
    "\n",
    "if limit_days > 0:\n",
    "    limit_minutes = limit_days*1440\n",
    "    \n",
    "    ind_obs = data['t_obs'] < limit_minutes\n",
    "    data['t_obs'] = data['t_obs'][ind_obs]\n",
    "    data['obs'] = data['obs'][:,ind_obs]\n",
    "\n",
    "    data['nt'] = int(limit_minutes//data['dt'])\n",
    "    \n",
    "if stride_t_obs > 0:\n",
    "    data['t_obs'] = data['t_obs'][::stride_t_obs]\n",
    "    data['obs'] = data['obs'][:,::stride_t_obs]\n",
    "\n",
    "data['nt_obs'] = data['obs'].shape[1]\n",
    "    \n",
    "# finally, add light data\n",
    "t = np.arange(data['nt'])*data['dt']\n",
    "data['E'] = np.interp(t, xp=data_seaflow['time'], fp=data_seaflow['PAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['i_test'] = np.concatenate([np.zeros(12,dtype=int),np.ones(12,dtype=int),np.zeros(67-24,dtype=int)])\n",
    "data['i_test'] = np.random.binomial(size=67, n=1, p= 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_4750d465e0dc8192f6e3218f302067d3 NOW.\n"
     ]
    }
   ],
   "source": [
    "import pystan\n",
    "\n",
    "model = pystan.StanModel(model_code=stan_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_4750d465e0dc8192f6e3218f302067d3.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "                     mean se_mean      sd      2.5%      25%      50%     75%   97.5%  n_eff   Rhat\n",
      "delta_mu            63.95    0.01    1.02     61.93    63.27    63.93   64.62   65.97   5383    1.0\n",
      "delta_sigma         13.71  8.6e-3     0.6     12.56     13.3     13.7   14.11   14.92   4834    1.0\n",
      "delta_max[1]         0.35  1.3e-3    0.08      0.23     0.29     0.34     0.4    0.54   3617    1.0\n",
      "delta_max[2]         1.08  2.4e-3    0.14      0.83     0.99     1.08    1.17    1.36   3204    1.0\n",
      "delta_max[3]         1.76  4.1e-3    0.27      1.28     1.58     1.75    1.93    2.35   4177    1.0\n",
      "delta_max[4]         2.71  6.6e-3    0.42      1.95     2.41     2.68    2.97     3.6   4053    1.0\n",
      "delta_max[5]         2.96  7.3e-3     0.5      2.08     2.61     2.93    3.26    4.02   4691    1.0\n",
      "delta_max[6]         3.33    0.01    0.86       1.9     2.76     3.26    3.82    5.25   4756    1.0\n",
      "delta_max[7]         48.9    0.51   19.13      6.64    38.26    50.94   62.22   81.28   1414    1.0\n",
      "delta_max[8]        63.16     0.2   13.73     36.38    53.86    63.42   72.52   90.19   4600    1.0\n",
      "delta_max[9]        64.07    0.19   13.69     37.24    54.99    63.96   73.27   90.77   5029    1.0\n",
      "delta_max[10]       63.87    0.21    13.7     37.11    54.76     64.0   73.29   90.61   4337    1.0\n",
      "gamma_max           28.78    0.05    2.44     24.14    27.14     28.7   30.35   33.79   2929    1.0\n",
      "E_star             2999.8    0.12   10.07    2980.4   2992.9   2999.9  3006.5  3019.2   6542    1.0\n",
      "sigma                0.12  1.0e-4  6.8e-3      0.11     0.12     0.12    0.13    0.14   4548    1.0\n",
      "log_like_test[1]    -1.26  9.0e-4    0.05     -1.37     -1.3    -1.26   -1.23   -1.17   3478    1.0\n",
      "log_like_test[2]    -1.29  1.2e-3    0.07     -1.45    -1.33    -1.28   -1.24   -1.17   3536    1.0\n",
      "log_like_test[3]    -2.63  5.3e-3    0.31     -3.28    -2.82    -2.61   -2.41   -2.05   3482    1.0\n",
      "log_like_test[4]    -1.99  3.0e-3    0.21     -2.43    -2.11    -1.97   -1.84   -1.61   4674    1.0\n",
      "log_like_test[5]    -1.52  2.7e-3    0.18     -1.92    -1.63     -1.5   -1.39   -1.23   4327    1.0\n",
      "log_like_test[6]    -1.82  3.2e-3    0.24     -2.33    -1.98    -1.81   -1.65    -1.4   5494    1.0\n",
      "log_like_test[7]    -1.73  3.2e-3    0.22     -2.23    -1.88    -1.72   -1.57   -1.35   4808    1.0\n",
      "log_like_test[8]    -3.22  9.5e-3    0.61     -4.59    -3.58    -3.16   -2.79   -2.18   4118    1.0\n",
      "log_like_test[9]    -2.63  7.7e-3    0.49     -3.72    -2.93    -2.59   -2.29   -1.76   4079    1.0\n",
      "log_like_test[10]   -3.67  9.9e-3    0.64     -5.01    -4.06    -3.64   -3.24   -2.51   4117    1.0\n",
      "log_like_test[11]   -2.29  5.2e-3    0.28     -2.91    -2.47    -2.27   -2.11   -1.78   2943    1.0\n",
      "log_like_test[12]   -3.36  7.8e-3    0.46     -4.32    -3.66    -3.34   -3.04    -2.5   3437    1.0\n",
      "log_like_test[13]   -2.42  5.2e-3     0.3     -3.06    -2.61     -2.4    -2.2   -1.88   3410    1.0\n",
      "log_like_test[14]   -1.92  4.2e-3    0.28     -2.54     -2.1     -1.9   -1.72   -1.46   4425    1.0\n",
      "log_like_test[15]    -1.6  3.3e-3    0.22      -2.1    -1.74    -1.58   -1.45   -1.23   4424    1.0\n",
      "log_like_test[16]   -1.09  9.9e-4    0.06     -1.24    -1.12    -1.08   -1.05   -1.01   3710    1.0\n",
      "log_like_test[17]   -1.78  2.8e-3    0.17     -2.19    -1.88    -1.76   -1.66   -1.49   3761    1.0\n",
      "log_like_test[18]   -1.77  2.2e-3    0.15     -2.09    -1.87    -1.76   -1.67   -1.52   4487    1.0\n",
      "log_like_test[19]   -1.96  3.6e-3    0.19     -2.36    -2.08    -1.95   -1.83   -1.61   2684    1.0\n",
      "log_like_test[20]   -2.44  7.2e-3    0.37     -3.23    -2.69    -2.42   -2.19   -1.76   2694    1.0\n",
      "log_like_test[21]   -3.87    0.01    0.54     -4.99    -4.22    -3.86   -3.51   -2.82   2686    1.0\n",
      "log_like_test[22]   -2.01  4.3e-3    0.31     -2.71     -2.2    -1.97   -1.78   -1.49   5335    1.0\n",
      "log_like_test[23]   -1.48  2.9e-3    0.18      -1.9    -1.58    -1.46   -1.35    -1.2   3728    1.0\n",
      "log_like_test[24]   -2.59  6.8e-3    0.39     -3.47    -2.83    -2.56   -2.32   -1.92   3338    1.0\n",
      "lp__               -250.2    0.08    3.02    -257.0   -252.0   -249.8  -248.0  -245.3   1573    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Wed Jan 15 21:51:02 2020.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "mcmc = model.sampling(data=data, iter=2000)\n",
    "print('\\n'.join(x for x in mcmc.__str__().split('\\n') if 'mod_obspos' not in x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
