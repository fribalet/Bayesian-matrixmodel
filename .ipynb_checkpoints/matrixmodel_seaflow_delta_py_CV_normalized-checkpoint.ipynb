{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SeaFlow data (regridded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "import netCDF4 as nc4\n",
    "import numpy as np\n",
    "\n",
    "# load data\n",
    "datafile = 'data/SeaFlow_SizeDist_regrid-15-5.nc'\n",
    "\n",
    "data_seaflow = {}\n",
    "with nc4.Dataset(datafile) as nc:\n",
    "    for var in nc.variables:\n",
    "        data_seaflow[var] = nc.variables[var][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_min = data_seaflow['v_min']\n",
    "delta_v = 1.0/data_seaflow['delta_v_inv']\n",
    "v = v_min * 2**(np.arange(data_seaflow['m'])*delta_v) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model\n",
    "\n",
    "modified from *Sosik et al. (2003), Growth rates of coastal phytoplankton from time-series measurements with a submersible flow cytometer, Limnol. Oceanogr.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_code = '''data {\n",
    "    // size variables\n",
    "    int<lower=0> m;              // number of size classes\n",
    "    int<lower=0> nt;             // number of timesteps\n",
    "    int<lower=0> nt_obs;         // number of timesteps with observations\n",
    "    int<lower=0> dt;             // delta t in minutes\n",
    "    real<lower=0> E[nt];         // vector of incident radiation values\n",
    "    real<lower=0> v_min;         // size in smallest size class in um^-3\n",
    "    int<lower=0> delta_v_inv;    // inverse of delta_v \n",
    "    simplex[m] w_ini;            // initial conditions \n",
    "    real<lower=0,upper=nt*dt>  t_obs[nt_obs];     // the time of each observation\n",
    "    real<lower=0> obs[m,nt_obs];                  // observations\n",
    "    int<lower=0,upper=1> i_test[nt_obs];          // vector of 0s and 1s indicating which obs to leave as test\n",
    "}\n",
    "transformed data {\n",
    "    int j;\n",
    "    real<lower=0> delta_v;\n",
    "    real<lower=0> dt_days;                  // dt in units of days\n",
    "    real<lower=0> v[m];                     // vector of (minimum) sizes for each size class\n",
    "    int<lower=0> t[nt];                     // vector of times in minutes since start \n",
    "    int<lower=1, upper=nt> it_obs[nt_obs];  // the time index of each observation\n",
    "    int<lower=0> n_test;                    // number of test observations\n",
    "    \n",
    "    n_test = sum(i_test);               // calculate number of test observations as sum of indicator vector\n",
    "    \n",
    "    //DEFINE SIZE VECTOR\n",
    "    j        = 1 + delta_v_inv;         // define j index\n",
    "    delta_v  = 1.0/delta_v_inv;         // size increment         \n",
    "    dt_days  = dt/1440.0;               // dt expressed in days\n",
    "    for (i in 1:m){\n",
    "        v[i] = v_min*2^((i-1)*delta_v); // center of size bins\n",
    "    }\n",
    "\n",
    "    //DEFINE TIME VECTOR\n",
    "    t[1] = 0;                  //\n",
    "    for (i in 2:nt){\n",
    "        t[i] = (t[i-1] + dt);\n",
    "    }\n",
    "    \n",
    "    //DEFINE INDEX VECTOR\n",
    "    for (k in 1:nt_obs){\n",
    "        for (i in 1:nt){\n",
    "            if (t_obs[k]>=t[i] && t_obs[k]<t[i]+dt){\n",
    "                it_obs[k] = i;\n",
    "                break;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "parameters {\n",
    "    real<lower=0>             delta_mu; \n",
    "    real<lower=0>             delta_sigma; \n",
    "    real<lower=0>             delta_max[m-j+1]; \n",
    "    real<lower=0>             gamma_max;\n",
    "    real<lower=0, upper=5000> E_star; \n",
    "    real<lower=1e-10>         sigma; \n",
    "}\n",
    "transformed parameters {\n",
    "    matrix[m,nt_obs] mod_obspos;\n",
    "       {vector[m] w_curr;   // declare vector to hold current state \n",
    "        vector[m] w_next;   // declare vector to hold next state\n",
    "        real delta_i;       // declare division rate\n",
    "        real gamma;         // declare growth rate\n",
    "        real a;             // declare allometric parameter\n",
    "        real tmp;           \n",
    "        int ito = 1;\n",
    "        \n",
    "        w_curr = w_ini;     // set initial condition according to the first observation\n",
    "\n",
    "        for (it in 1:nt){                   // time-stepping loop\n",
    "            if (it == it_obs[ito]){         // record current solution if we need to compare to obs \n",
    "                mod_obspos[,ito] = w_curr;  // record current state in mod_obspos to compare with obs\n",
    "                ito += 1;                   \n",
    "                if (ito > nt_obs){\n",
    "                    break;\n",
    "                }\n",
    "            }\n",
    "\n",
    "            gamma = gamma_max * dt_days * (1.0 - exp(-E[it]/E_star));  // compute current growth rate according to light\n",
    "            w_next = rep_vector(0.0, m);                               // initialize state vector for next time\n",
    "            for (i in 1:m){                                  // size-class loop\n",
    "                if (i >= j){                                 \n",
    "                    delta_i = delta_max[i-j+1] * dt_days;    // size-specific delta_max\n",
    "                }\n",
    "                // fill subdiagonal (growth)\n",
    "                if (i < j){\n",
    "                    //A[i+1,i] = gamma;\n",
    "                    a = gamma;\n",
    "                    w_next[i+1] += a * w_curr[i];\n",
    "                } else if (i < m){\n",
    "                    //A[i+1,i] = gamma * (1.0-delta_i);\n",
    "                    a = gamma * (1.0-delta_i);\n",
    "                    w_next[i+1] += a * w_curr[i];\n",
    "                }\n",
    "                // fill (j-1)th superdiagonal (division)\n",
    "                if (i >= j){\n",
    "                    //A[i+1-j,i] = 2.0*delta_i;\n",
    "                    a = 2.0*delta_i;\n",
    "                    w_next[i+1-j] += a * w_curr[i];\n",
    "                }\n",
    "                // fill diagonal (stasis)\n",
    "                if (i < j){\n",
    "                    //A[i,i] = (1.0-gamma);\n",
    "                    a = (1.0-gamma);\n",
    "                    w_next[i] += a * w_curr[i];\n",
    "                } else if (i == m){\n",
    "                    //A[i,i] = (1.0-delta_i);\n",
    "                    a = (1.0-delta_i);\n",
    "                    w_next[i] += a * w_curr[i];\n",
    "                } else {\n",
    "                    //A[i,i] = (1.0-gamma) * (1.0-delta_i);\n",
    "                    a = (1.0-gamma) * (1.0-delta_i);\n",
    "                    w_next[i] += a * w_curr[i];\n",
    "                }\n",
    "            }\n",
    "            w_curr = w_next ./ sum(w_next);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "model {\n",
    "    real diff;\n",
    "    \n",
    "    // priors\n",
    "    delta_mu ~ normal(66.0, 1.0);\n",
    "    delta_sigma ~ normal(5.0, 1.0);\n",
    "    delta_max ~ normal(delta_mu, delta_sigma); // T[0.0,1440.0/dt];\n",
    "    gamma_max ~ uniform(0.0,1440.0/dt);\n",
    "    E_star ~ normal(3000.0,10.0);\n",
    "    sigma ~ exponential(1000.0);\n",
    "\n",
    "    // fitting observations\n",
    "    for (it in 1:nt_obs){\n",
    "        diff = 0.0;\n",
    "        if(i_test[it] == 0){\n",
    "        for (iv in 1:m){\n",
    "            diff += fabs(mod_obspos[iv,it] - obs[iv,it]);\n",
    "        }\n",
    "        diff = diff/sigma;\n",
    "        diff ~ normal(0.0, 1.0) T[0,];\n",
    "    }\n",
    "    }\n",
    "}\n",
    "generated quantities{\n",
    "    real log_like_test = 0;             // test obs likelihoods\n",
    "    {int k=1;                       // start counter for log_like_test vector; put in brackets so variables are local\n",
    "    real diff;                      // declare error variable\n",
    "    for(it in 1:nt_obs){            // loop over all observations\n",
    "        if(i_test[it] == 1){        // is this a test observation?\n",
    "        diff = 0.0;                 // start error variable at zero\n",
    "        for(iv in 1:m){             // loop over size classes\n",
    "            diff += fabs(mod_obspos[iv,it] - obs[iv,it]);  // accumulate error increment from each size class\n",
    "        }\n",
    "        diff = diff/sigma;                                 // normalize error to have unit standard deviation\n",
    "        log_like_test += normal_lpdf(diff | 0.0, 1.0);   // compute test likelihood\n",
    "        k += 1;                     // step log_like_test index\n",
    "        }\n",
    "    }\n",
    "        log_like_test = log_like_test/n_test;\n",
    "    }\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for Stan model\n",
    "\n",
    "dt = 20 # in units of minutes\n",
    "\n",
    "data = {'dt':dt}\n",
    "for k in ('m','v_min','delta_v_inv'):\n",
    "    data[k] = data_seaflow[k]\n",
    "\n",
    "data['obs'] = data_seaflow['w_obs']\n",
    "data['t_obs'] = data_seaflow['time']\n",
    "data['E'] = data_seaflow['PAR']\n",
    "# use first measurements as initial conditions\n",
    "data['w_ini'] = data_seaflow['w_obs'][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove very first observations\n",
    "ind_obs = data['t_obs'] > 3\n",
    "data['t_obs'] = data['t_obs'][ind_obs]\n",
    "data['obs'] = data['obs'][:,ind_obs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the data\n",
    "\n",
    "limit_days = 3\n",
    "stride_t_obs = 20\n",
    "\n",
    "\n",
    "if limit_days > 0:\n",
    "    limit_minutes = limit_days*1440\n",
    "    \n",
    "    ind_obs = data['t_obs'] < limit_minutes\n",
    "    data['t_obs'] = data['t_obs'][ind_obs]\n",
    "    data['obs'] = data['obs'][:,ind_obs]\n",
    "\n",
    "    data['nt'] = int(limit_minutes//data['dt'])\n",
    "    \n",
    "if stride_t_obs > 0:\n",
    "    data['t_obs'] = data['t_obs'][::stride_t_obs]\n",
    "    data['obs'] = data['obs'][:,::stride_t_obs]\n",
    "\n",
    "data['nt_obs'] = data['obs'].shape[1]\n",
    "    \n",
    "# finally, add light data\n",
    "t = np.arange(data['nt'])*data['dt']\n",
    "data['E'] = np.interp(t, xp=data_seaflow['time'], fp=data_seaflow['PAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['i_test'] = np.concatenate([np.zeros(12,dtype=int),np.ones(12,dtype=int),np.zeros(67-24,dtype=int)])\n",
    "data['i_test'] = np.random.binomial(size=67, n=1, p= 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_44c2e449ae963229e59fe7211cca5bbf NOW.\n"
     ]
    }
   ],
   "source": [
    "import pystan\n",
    "\n",
    "model = pystan.StanModel(model_code=stan_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_44c2e449ae963229e59fe7211cca5bbf.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "                     mean se_mean      sd      2.5%      25%     50%     75%   97.5%  n_eff   Rhat\n",
      "delta_mu            63.92    0.01    1.02     61.94    63.23   63.92    64.6   65.89   5306    1.0\n",
      "delta_sigma         13.74  8.5e-3    0.61     12.57    13.33   13.71   14.14   14.98   5154    1.0\n",
      "delta_max[1]         0.37  1.3e-3    0.08      0.24     0.31    0.35    0.42    0.56   3986    1.0\n",
      "delta_max[2]         1.12  2.3e-3    0.14      0.87     1.02    1.11    1.21    1.41   3668    1.0\n",
      "delta_max[3]         1.74  3.7e-3    0.24      1.28     1.59    1.73    1.89    2.27   4249    1.0\n",
      "delta_max[4]         2.68  5.2e-3    0.37       2.0     2.42    2.67    2.92    3.46   5175    1.0\n",
      "delta_max[5]         3.01  7.7e-3    0.49      2.11     2.68    2.99    3.32    4.11   4129    1.0\n",
      "delta_max[6]         3.48    0.01    0.87      2.04     2.89    3.37    3.98    5.51   4123    1.0\n",
      "delta_max[7]         43.8     0.5    20.2      6.05    29.58   46.47   58.52   79.58   1610    1.0\n",
      "delta_max[8]        62.82    0.21   13.77     35.22    53.55   63.22   72.26   88.47   4506    1.0\n",
      "delta_max[9]        63.87    0.19   13.96     37.41    54.43   63.93    73.3   91.77   5666    1.0\n",
      "delta_max[10]       63.82    0.19   13.75     35.93    54.65   63.84   73.39   89.72   5318    1.0\n",
      "gamma_max           29.16    0.04    2.32      24.7    27.52   29.13    30.7   33.77   2716    1.0\n",
      "E_star             3000.2    0.12   10.02    2981.2   2993.5  3000.2  3006.6  3020.1   7040    1.0\n",
      "sigma                0.12  9.9e-5  6.7e-3      0.11     0.12    0.12    0.13    0.14   4605    1.0\n",
      "log_like_test       -2.57  2.6e-3    0.18     -2.95    -2.69   -2.56   -2.44   -2.23   5240    1.0\n",
      "lp__               -247.1    0.08     3.0    -253.9   -248.8  -246.7  -244.9  -242.4   1395    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Wed Jan 15 22:12:42 2020.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "mcmc = model.sampling(data=data, iter=2000)\n",
    "print('\\n'.join(x for x in mcmc.__str__().split('\\n') if 'mod_obspos' not in x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
