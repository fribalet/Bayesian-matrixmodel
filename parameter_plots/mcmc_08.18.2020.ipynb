{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit several models to seaflow + Zinser, save parameter samples as .csv for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data from files and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "import netCDF4 as nc4\n",
    "import numpy as np\n",
    "\n",
    "# load data\n",
    "datafiles = {\n",
    "    'seaflow':'../data/SeaFlow_SizeDist_regrid-25-8.nc',\n",
    "    'zinser':'../data/Zinser_SizeDist_calibrated-26-6.nc',\n",
    "}\n",
    "\n",
    "itestfiles = {\n",
    "    'seaflow':'../data/Zinser_SizeDist_calibrated-26-6-itest.csv', # same as zinser\n",
    "    'zinser':'../data/Zinser_SizeDist_calibrated-26-6-itest.csv',         \n",
    "}\n",
    "\n",
    "desc = {\n",
    "    'seaflow':'SeaFlow dataset',\n",
    "    'zinser':'Zinser dataset',    \n",
    "}\n",
    "data_gridded = {}\n",
    "for k in datafiles:\n",
    "    data_gridded[k] = {}\n",
    "    with nc4.Dataset(datafiles[k]) as nc:\n",
    "        for var in nc.variables:\n",
    "            data_gridded[k][var] = nc.variables[var][:]\n",
    "    desc[k] += ' (m={data[m]}, $\\Delta_v^{{-1}}$={data[delta_v_inv]})'.format(data=data_gridded[k])\n",
    "\n",
    "data_gridded[k]['PAR'] *= 200.0/22.0 # make light similar for this experiment (it is later normalized by E_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PhytoGreg\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:734: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  a.partition(kth, axis=axis, kind=kind, order=order)\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "for k in data_gridded:\n",
    "    dt = 20 # in units of minutes    \n",
    "    data[k] = {'dt':dt}\n",
    "    data[k]['prior_only'] = 0\n",
    "    for v in ('m','v_min','delta_v_inv'):\n",
    "        data[k][v] = data_gridded[k][v]\n",
    "    if 'seaflow' in k:\n",
    "        limit_days = 1\n",
    "        # new: average SeaFlow data in hourly bins\n",
    "        binsize = 60 # in minutes\n",
    "        numbins = int(np.ceil(data_gridded[k]['time'][-1]/binsize))      \n",
    "        data[k]['obs'] = np.full((data[k]['m'],numbins), fill_value=np.nan)\n",
    "        data[k]['t_obs'] = np.full(numbins, fill_value=np.nan)\n",
    " \n",
    "        i = 0\n",
    "        for ibin in range(numbins):\n",
    "            binind = np.logical_and(data_gridded[k]['time'] >= ibin*binsize,\n",
    "                                    data_gridded[k]['time'] < (ibin+1)*binsize)\n",
    "            if np.any(binind):\n",
    "                # TODO we may want to make this a sum when dealing with counts\n",
    "                data[k]['obs'][:,i] = np.mean(data_gridded[k]['w_obs'][:,binind], axis=1)\n",
    "                data[k]['t_obs'][i] = (ibin+0.5) * binsize\n",
    "                i += 1        \n",
    "        data[k]['obs'] = data[k]['obs'][:,:i]\n",
    "        data[k]['t_obs'] = data[k]['t_obs'][:i]        \n",
    "        \n",
    "        n = len(data_gridded[k]['PAR'])  \n",
    "        wsh = 30 # half of median filter window size; window size is 2*wsh+1\n",
    "        par = np.array([np.median(data_gridded[k]['PAR'][max(0,i-wsh):min(n,i+wsh+1)]) for i in range(n)]) # median filter PAR; see: medianfilter_par.ipynb\n",
    "    else:\n",
    "        limit_days = 2        \n",
    "        data[k]['obs'] = data_gridded[k]['w_obs']\n",
    "        data[k]['t_obs'] = data_gridded[k]['time']\n",
    "        par = data_gridded[k]['PAR']\n",
    "        \n",
    "    if limit_days > 0:\n",
    "        limit_minutes = limit_days*1440        \n",
    "        ind_obs = data[k]['t_obs'] < limit_minutes\n",
    "        data[k]['t_obs'] = data[k]['t_obs'][ind_obs]\n",
    "        data[k]['obs'] = data[k]['obs'][:,ind_obs]        \n",
    "        data[k]['nt'] = int(limit_minutes//data[k]['dt'])\n",
    "\n",
    "    data[k]['nt_obs'] = data[k]['t_obs'].size\n",
    "    \n",
    "#     # load cross-validation testing indices and add them to data\n",
    "    data[k]['i_test'] = np.loadtxt(itestfiles[k]).astype(int)\n",
    "    data[k]['i_test'] = data[k]['i_test'][:-1]                          # remove last index, so that dimensions agree\n",
    "\n",
    "    t = np.arange(data[k]['nt'])*data[k]['dt']\n",
    "    data[k]['E'] = np.interp(t, xp=data_gridded[k]['time'], fp=par)     # add light data\n",
    "    \n",
    "    # for now, add pseudo-count data\n",
    "    data[k]['obs_count'] = (1000*data[k]['obs']).astype(int)\n",
    "    \n",
    "        # consistency check\n",
    "    if len(data[k]['i_test']) != data[k]['nt_obs']:\n",
    "        raise ValueError('Invalid number of testing indices for \"{}\" (expected {}, got {}).'.format(k,data[k]['nt_obs'],len(data[k]['i_test'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfiles = {\n",
    "#    'm1': '../stancode_gallery2/matrixmodel_mlmultinom_estinilnorm2_freedelta_normparam_trackgrowth_xval2.stan',\n",
    "#    'm2': '../stancode_gallery2/matrixmodel_mlmultinom_estinilnorm2_monodelta2_normparam_trackgrowth_xval2.stan',\n",
    "#    'm3': '../stancode_gallery2/matrixmodel_mlmultinom_estinilnorm2_monodelta2_gammaiv6_normparam_trackgrowth_xval2.stan', \n",
    "#    'm4': '../stancode_gallery2/matrixmodel_mlmultinom_estinilnorm2_monodelta2_respv1_normparam_trackgrowth_xval2.stan', \n",
    "#    'm5': '../stancode_gallery2/matrixmodel_mlmultinom_estinilnorm2_monodelta2_respv2_normparam_trackgrowth_xval2.stan', \n",
    "#    'm6': '../stancode_gallery2/matrixmodel_mlmultinom_estinilnorm2_monodelta2_respiv6_normparam_trackgrowth_xval2.stan', \n",
    "    'm7': '../stancode_gallery2/matrixmodel_mlmultinom_estinilnorm2_monodelta2_respiv7_normparam_trackgrowth_xval2.stan',\n",
    "#    'm8': '../stancode_gallery2/matrixmodel_mlmultinom_estinilnorm2_monodelta2-lightsig_respiv6_normparam_trackgrowth_xval2.stan', \n",
    "#    'm9': '../stancode_gallery2/matrixmodel_mlmultinom_estinilnorm2_monodelta2-lightsig_respiv7_normparam_trackgrowth_xval2.stan', \n",
    "#    'm10': '../stancode_gallery2/matrixmodel_mlmultinom_estinilnorm2_monodelta2-lightsig_respv2_normparam_trackgrowth_xval2.stan', \n",
    "#    'm11': '../stancode_gallery2/matrixmodel_mlmultinom_estinilnorm2_monodelta2_resp_gammaiv6_normparam_trackgrowth_xval2.stan', \n",
    "#    'm12': '../stancode_gallery2/matrixmodel_mlmultinom_estinilnorm2_monodelta2_resp_gammaiv7_normparam_trackgrowth_xval2.stan', \n",
    "#    'm13': '../stancode_gallery2/matrixmodel_mlmultinom_estinilnorm2_monodelta2-lightsig_resp_gammaiv6_normparam_trackgrowth_xval2.stan', \n",
    "#    'm14': '../stancode_gallery2/matrixmodel_mlmultinom_estinilnorm2_monodelta2-lightsig_resp_gammaiv7_normparam_trackgrowth_xval2.stan',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL m7 NOW.\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "for name in modelfiles:\n",
    "        models[name] = pystan.StanModel(file=modelfiles[name], model_name=name, obfuscate_model_name=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:123 of 4000 iterations ended with a divergence (3.08 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.8 to remove the divergences.\n",
      "WARNING:pystan:2 of 4000 iterations saturated the maximum tree depth of 10 (0.05 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    }
   ],
   "source": [
    "mcmcs = {}\n",
    "\n",
    "for name in models:\n",
    "    mcmcs[name] = {}\n",
    "    for k in data:\n",
    "            mcmcs[name][k] = models[name].sampling(data=data[k], iter=2000)\n",
    "            df = pystan.misc.to_dataframe(mcmcs[name][k])\n",
    "            df.to_csv(\"fit_{name}_{dataset}.csv\".format(name=name,dataset=k),index=False)\n",
    "#             s  = mcmcs[name][k].summary()\n",
    "#             summary = pd.DataFrame(s['summary'], columns=s['summary_colnames'], index=s['summary_rownames'])\n",
    "#             summary.to_csv(\"fit_{name}_{dataset}_summary.csv\".format(name=name,dataset=k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit models and save to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:10 of 4000 iterations ended with a divergence (0.25 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.8 to remove the divergences.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
