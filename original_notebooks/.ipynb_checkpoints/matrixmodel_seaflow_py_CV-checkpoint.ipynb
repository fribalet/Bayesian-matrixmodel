{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SeaFlow data (regridded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import netCDF4 as nc4\n",
    "import numpy as np\n",
    "\n",
    "# load data\n",
    "datafile = 'data/SeaFlow_SizeDist_regrid-15-5.nc'\n",
    "\n",
    "data_seaflow = {}\n",
    "with nc4.Dataset(datafile) as nc:\n",
    "    for var in nc.variables:\n",
    "        data_seaflow[var] = nc.variables[var][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_min = data_seaflow['v_min']\n",
    "delta_v = 1.0/data_seaflow['delta_v_inv']\n",
    "v = v_min * 2**(np.arange(data_seaflow['m'])*delta_v) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model\n",
    "\n",
    "modified from *Sosik et al. (2003), Growth rates of coastal phytoplankton from time-series measurements with a submersible flow cytometer, Limnol. Oceanogr.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_code = '''data {\n",
    "    // size variables\n",
    "    int<lower=0> m;         // number of size classes\n",
    "    int<lower=0> nt;        // number of timesteps\n",
    "    int<lower=0> nt_obs;    // number of timesteps with observations\n",
    "    // model parameters and input\n",
    "    int<lower=0> dt;        // delta t in minutes\n",
    "    real<lower=0> E[nt];    // vector of incident radiation values\n",
    "    real<lower=0> v_min;    // size in smallest size class in um^-3\n",
    "    int<lower=0> delta_v_inv;   // inverse of delta_v \n",
    "    simplex[m] w_ini;       // initial conditions \n",
    "    // observations\n",
    "    real<lower=0,upper=nt*dt>  t_obs[nt_obs]; // the time of each observation\n",
    "    real<lower=0> obs[m,nt_obs]; // observations\n",
    "    int<lower=0,upper=1> i_test[nt_obs];          // vector of 0s and 1s indicating which obs to leave as test    \n",
    "}\n",
    "transformed data {\n",
    "    int j;\n",
    "    real<lower=0> delta_v;\n",
    "    real<lower=0> dt_days;  // dt in units of days\n",
    "    real<lower=0> v[m];     // vector of (minimum) sizes for each size class\n",
    "    int<lower=0> t[nt];     // vector of times in minutes since start \n",
    "    int<lower=1, upper=nt> it_obs[nt_obs]; // the time index of each observation\n",
    "    int<lower=0> n_test;                    // number of test observations\n",
    "\n",
    "    n_test = sum(i_test);               // calculate number of test observations as sum of indicator vector\n",
    "\n",
    "    j = 1 + delta_v_inv; \n",
    "    delta_v = 1.0/delta_v_inv;\n",
    "    dt_days = dt/1440.0;\n",
    "    for (i in 1:m){\n",
    "        v[i] = v_min*2^((i-1)*delta_v);\n",
    "    }\n",
    "    // populate time vector\n",
    "    t[1] = 0;\n",
    "    for (i in 2:nt){\n",
    "        t[i] = (t[i-1] + dt);\n",
    "    }\n",
    "    // populate index vector it_obs\n",
    "    for (k in 1:nt_obs){\n",
    "        for (i in 1:nt){\n",
    "            if (t_obs[k]>=t[i] && t_obs[k]<t[i]+dt){\n",
    "                it_obs[k] = i;\n",
    "                break;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "parameters {\n",
    "    real<lower=0> b; \n",
    "    real<lower=0> delta_max; \n",
    "    real<lower=0> gamma_max;\n",
    "    real<lower=0, upper=5000> E_star; \n",
    "    real<lower=1e-10> sigma; \n",
    "}\n",
    "transformed parameters {\n",
    "    matrix[m,nt_obs] mod_obspos;\n",
    "    {\n",
    "        // helper variables\n",
    "        vector[m] w_curr; \n",
    "        vector[m] w_next;\n",
    "        real delta_i;\n",
    "        real gamma;\n",
    "        real a;\n",
    "        real tmp;\n",
    "        int ito = 1;\n",
    "        \n",
    "        w_curr = w_ini;\n",
    "\n",
    "        for (it in 1:nt){ // time-stepping loop\n",
    "            // record current solution \n",
    "            if (it == it_obs[ito]){\n",
    "                mod_obspos[,ito] = w_curr;\n",
    "                ito += 1;\n",
    "                if (ito > nt_obs){\n",
    "                    break;\n",
    "                }\n",
    "            }\n",
    "            // compute gamma\n",
    "            gamma = gamma_max * dt_days * (1.0 - exp(-E[it]/E_star));\n",
    "\n",
    "            w_next = rep_vector(0.0, m);\n",
    "            for (i in 1:m){ // size-class loop\n",
    "                // compute delta_i\n",
    "                tmp = v[i]^b; \n",
    "                delta_i = delta_max * dt_days * (tmp/(1+tmp));\n",
    "                \n",
    "                // fill subdiagonal (growth)\n",
    "                if (i < j){\n",
    "                    //A[i+1,i] = gamma;\n",
    "                    a = gamma;\n",
    "                    w_next[i+1] += a * w_curr[i];\n",
    "                } else if (i < m){\n",
    "                    //A[i+1,i] = gamma * (1.0-delta_i);\n",
    "                    a = gamma * (1.0-delta_i);\n",
    "                    w_next[i+1] += a * w_curr[i];\n",
    "                }\n",
    "                // fill (j-1)th superdiagonal (division)\n",
    "                if (i >= j){\n",
    "                    //A[i+1-j,i] = 2.0*delta_i;\n",
    "                    a = 2.0*delta_i;\n",
    "                    w_next[i+1-j] += a * w_curr[i];\n",
    "                }\n",
    "                // fill diagonal (stasis)\n",
    "                if (i < j){\n",
    "                    //A[i,i] = (1.0-gamma);\n",
    "                    a = (1.0-gamma);\n",
    "                    w_next[i] += a * w_curr[i];\n",
    "                } else if (i == m){\n",
    "                    //A[i,i] = (1.0-delta_i);\n",
    "                    a = (1.0-delta_i);\n",
    "                    w_next[i] += a * w_curr[i];\n",
    "                } else {\n",
    "                    //A[i,i] = (1.0-gamma) * (1.0-delta_i);\n",
    "                    a = (1.0-gamma) * (1.0-delta_i);\n",
    "                    w_next[i] += a * w_curr[i];\n",
    "                }\n",
    "            }\n",
    "            w_curr = w_next ./ sum(w_next);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "model {\n",
    "    real diff;\n",
    "    \n",
    "    // priors\n",
    "    b ~ normal(1.0,0.8);\n",
    "    delta_max ~ uniform(0.0,1440.0/dt);\n",
    "    gamma_max ~ uniform(0.0,1440.0/dt);\n",
    "    E_star ~ normal(3000.0,1000.0);\n",
    "    sigma ~ exponential(1000.0);\n",
    "    // fitting observations\n",
    "    for (it in 1:nt_obs){\n",
    "        diff = 0.0;\n",
    "        if(i_test[it] == 0){\n",
    "        for (iv in 1:m){\n",
    "            diff += fabs(mod_obspos[iv,it] - obs[iv,it]);\n",
    "        }\n",
    "        diff = diff/sigma;\n",
    "        diff ~ normal(0.0, 1.0) T[0,];\n",
    "    }\n",
    "    }\n",
    "}\n",
    "generated quantities{\n",
    "    real log_like_test = 0;             // test obs likelihoods\n",
    "    {int k=1;                       // start counter for log_like_test vector; put in brackets so variables are local\n",
    "    real diff;                      // declare error variable\n",
    "    for(it in 1:nt_obs){            // loop over all observations\n",
    "        if(i_test[it] == 1){        // is this a test observation?\n",
    "        diff = 0.0;                 // start error variable at zero\n",
    "        for(iv in 1:m){             // loop over size classes\n",
    "            diff += fabs(mod_obspos[iv,it] - obs[iv,it]);  // accumulate error increment from each size class\n",
    "        }\n",
    "        diff = diff/sigma;                                 // normalize error to have unit standard deviation\n",
    "        log_like_test += normal_lpdf(diff | 0.0, 1.0);   // compute test likelihood\n",
    "        k += 1;                     // step log_like_test index\n",
    "        }\n",
    "    }\n",
    "        log_like_test = log_like_test/n_test;\n",
    "    }\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for Stan model\n",
    "\n",
    "dt = 20 # in units of minutes\n",
    "\n",
    "data = {'dt':dt}\n",
    "for k in ('m','v_min','delta_v_inv'):\n",
    "    data[k] = data_seaflow[k]\n",
    "\n",
    "data['obs'] = data_seaflow['w_obs']\n",
    "data['t_obs'] = data_seaflow['time']\n",
    "data['E'] = data_seaflow['PAR']\n",
    "# use first measurements as initial conditions\n",
    "data['w_ini'] = data_seaflow['w_obs'][:,0]\n",
    "\n",
    "# limit the data\n",
    "\n",
    "limit_days = 3\n",
    "stride_t_obs = 20\n",
    "\n",
    "# remove very first observations\n",
    "ind_obs = data['t_obs'] > 3\n",
    "data['t_obs'] = data['t_obs'][ind_obs]\n",
    "data['obs'] = data['obs'][:,ind_obs]\n",
    "\n",
    "if limit_days > 0:\n",
    "    limit_minutes = limit_days*1440\n",
    "    \n",
    "    ind_obs = data['t_obs'] < limit_minutes\n",
    "    data['t_obs'] = data['t_obs'][ind_obs]\n",
    "    data['obs'] = data['obs'][:,ind_obs]\n",
    "\n",
    "    data['nt'] = int(limit_minutes//data['dt'])\n",
    "    \n",
    "if stride_t_obs > 0:\n",
    "    data['t_obs'] = data['t_obs'][::stride_t_obs]\n",
    "    data['obs'] = data['obs'][:,::stride_t_obs]\n",
    "\n",
    "data['nt_obs'] = data['obs'].shape[1]\n",
    "    \n",
    "# finally, add light data\n",
    "t = np.arange(data['nt'])*data['dt']\n",
    "data['E'] = np.interp(t, xp=data_seaflow['time'], fp=data_seaflow['PAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['i_test'] = np.concatenate([np.zeros(50,dtype=int),np.ones(17,dtype=int)])\n",
    "#data['i_test'] = np.random.binomial(size=67, n=1, p= 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_c501d8329ccafef3e221f9d2919f259a NOW.\n"
     ]
    }
   ],
   "source": [
    "import pystan\n",
    "\n",
    "model = pystan.StanModel(model_code=stan_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:3162 of 4000 iterations ended with a divergence (79 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.8 to remove the divergences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_c501d8329ccafef3e221f9d2919f259a.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "                    mean se_mean      sd   2.5%     25%     50%    75%   97.5%  n_eff   Rhat\n",
      "b                   1.15  2.1e-3    0.04   1.07    1.12    1.15   1.17    1.22    352   1.01\n",
      "delta_max          66.79    0.31    4.91  54.06   64.61   68.27  70.44   71.84    254   1.01\n",
      "gamma_max           25.6    0.33    5.71  15.53    21.3   25.37  29.37   37.07    303    1.0\n",
      "E_star            3178.1   47.48  854.35 1542.1  2594.8  3170.2 3803.4  4767.7    324   1.01\n",
      "sigma               0.14  2.8e-4  7.0e-3   0.13    0.13    0.14   0.14    0.15    610    1.0\n",
      "log_like_test      -3.69    0.01     0.3  -4.33   -3.89   -3.67  -3.48   -3.16    679   1.01\n",
      "lp__              -160.7    0.09    1.84 -165.2  -161.7  -160.3 -159.3  -158.1    389    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Wed Jan 15 22:34:34 2020.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "mcmc = model.sampling(data=data, iter=2000)\n",
    "print('\\n'.join(x for x in mcmc.__str__().split('\\n') if 'mod_obspos' not in x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
