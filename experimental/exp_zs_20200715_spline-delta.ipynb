{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test first spline-based tim-dependent $\\delta$ formulation\n",
    " * add description here\n",
    " \n",
    "### general information about the different growth/respiration versions\n",
    "\n",
    " * for the functional form of the different size-dependent growth and respiration formulations see [this notebook](sizedep_formulations.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## global switches and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use test data (not all data is used for fitting/training)\n",
    "use_testdata = False\n",
    "\n",
    "# create plots of the data\n",
    "show_data = False\n",
    "\n",
    "# netCDF output file (set to None to not save output)\n",
    "savename_output = 'data_exp_zs_20200715_spline-delta.nc'\n",
    "\n",
    "# save the Stan output instead a few stats (only active if filename is specified above)\n",
    "save_stan_output = True\n",
    "\n",
    "# specify the Stan variable names to save; if set to None, all variables are saved \n",
    "# (only active if save_stan_output is True)\n",
    "varnames_save = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data from files and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "import netCDF4 as nc4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dateutil.parser\n",
    "\n",
    "# load data\n",
    "datafiles = {\n",
    "    'seaflow':'data/SeaFlow_SizeDist_regrid-25-8.nc',\n",
    "    'zinser':'data/Zinser_SizeDist_calibrated-26-6.nc',\n",
    "}\n",
    "\n",
    "itestfiles = {\n",
    "    'seaflow':'data/Zinser_SizeDist_calibrated-26-6-itest.csv', # same as zinser\n",
    "    'zinser':'data/Zinser_SizeDist_calibrated-26-6-itest.csv',         \n",
    "}\n",
    "\n",
    "desc = {\n",
    "    'seaflow':'SeaFlow dataset',\n",
    "    'zinser':'Zinser dataset',    \n",
    "}\n",
    "\n",
    "data_gridded = {}\n",
    "for dataname in datafiles:\n",
    "    data_gridded[dataname] = {}\n",
    "    with nc4.Dataset(datafiles[dataname]) as nc:\n",
    "        for var in nc.variables:\n",
    "            data_gridded[dataname][var] = nc.variables[var][:]\n",
    "    desc[dataname] += ' (m={data[m]}, $\\Delta_v^{{-1}}$={data[delta_v_inv]})'.format(data=data_gridded[dataname])\n",
    "\n",
    "# Now we load in count data\n",
    "for dataname in datafiles:\n",
    "\n",
    "    if 'seaflow' in dataname:\n",
    "        # Extract SeaFlow cell counts\n",
    "        seaflow = pd.read_csv('data/SeaFlow_PSD_hourlyCOUNT_m32.csv')\n",
    "        seaflow_counts = seaflow.values[:, 2:].T.astype(int)\n",
    "\n",
    "        # Redefine parameters to match 32-size class count data. We only keep PAR from the 25-size class data.\n",
    "        data_gridded[dataname]['m'] = seaflow_counts.shape[0]\n",
    "        data_gridded[dataname]['size_bounds'] = seaflow.columns[2:].values.astype(float) # extract size classes from dataframe\n",
    "        data_gridded[dataname]['v_min'] = data_gridded[dataname]['size_bounds'][0] # note these seem to be on a different scale\n",
    "        data_gridded[dataname]['delta_v_inv'] = int(np.round(1.0/np.log2(data_gridded[dataname]['size_bounds'][1]/data_gridded[dataname]['size_bounds'][0])))\n",
    "        data_gridded[dataname]['w_obs'] = (seaflow_counts/np.sum(seaflow_counts, axis=0)[None, :]).astype(float)\n",
    "        data_gridded[dataname]['counts'] = seaflow_counts\n",
    "        data_gridded[dataname]['obs_time'] = np.empty(shape=seaflow_counts.shape[1])\n",
    "\n",
    "        # Extract time stamps for each observation from SeaFlow data\n",
    "        ii = 0\n",
    "        for timestamp in np.asarray(seaflow['time'], dtype=str):\n",
    "            datetime = dateutil.parser.isoparse(timestamp)\n",
    "            if ii == 0:\n",
    "                initial = datetime\n",
    "            data_gridded['seaflow']['obs_time'][ii] = (datetime - initial).total_seconds()/60\n",
    "            ii += 1\n",
    "\n",
    "    elif 'zinser' in dataname:\n",
    "\n",
    "        # Extract Zinser cell counts\n",
    "        zinser = pd.read_csv('data/Zinser_Figure2A.csv')\n",
    "        #zinser_counts = zinser.values[:,1].astype(int) # cells A column\n",
    "        #zinser_counts = zinser.values[:,2].astype(int) # cells B column\n",
    "        zinser_counts = np.mean(zinser.values, axis=1).astype(int) # mean of both columns\n",
    "        \n",
    "        # Add counts to Zinser data\n",
    "        data_gridded[dataname]['counts'] = (data_gridded[dataname]['w_obs'] * zinser_counts).astype(int)\n",
    "        data_gridded[dataname]['obs_time'] = data_gridded[dataname]['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "def add_colorbar(ax, **cbarargs):\n",
    "    axins_cbar = inset_axes(ax, width='3%', height='90%', loc=5, bbox_to_anchor=(0.05,0.0,1,1), bbox_transform=ax.transAxes)\n",
    "    mpl.colorbar.ColorbarBase(axins_cbar, orientation='vertical', **cbarargs)\n",
    "\n",
    "if show_data:\n",
    "    for i,dataname in enumerate(data_gridded):\n",
    "        nrows = 3\n",
    "        sharex = np.array_equal(data_gridded[dataname]['time'], data_gridded[dataname]['obs_time'])\n",
    "\n",
    "        v_min = data_gridded[dataname]['v_min']\n",
    "        delta_v = 1.0/data_gridded[dataname]['delta_v_inv']\n",
    "        v = v_min * 2**(np.arange(data_gridded[dataname]['m'])*delta_v) \n",
    "\n",
    "        fig,axs = plt.subplots(nrows=nrows, sharex=sharex, figsize=(12,4*nrows))\n",
    "\n",
    "        ax = axs[0]\n",
    "        ax.set_title('raw '+desc[dataname], size=20)\n",
    "        ax.plot(data_gridded[dataname]['time'], data_gridded[dataname]['PAR'], color='gold')\n",
    "        ax.set(ylabel='PAR')\n",
    "\n",
    "        ax = axs[1]\n",
    "        pc = ax.pcolormesh(data_gridded[dataname]['obs_time'],v,data_gridded[dataname]['w_obs'])\n",
    "        ax.set(ylabel='size ($\\mu$m$^3$)')\n",
    "        #ax.text(0.01, 0.95, desc[dataname], color='white', size=16, transform=ax.transAxes, ha='left', va='top')\n",
    "        add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='size class proportion')\n",
    "\n",
    "        ax = axs[2]\n",
    "        pc = ax.pcolormesh(data_gridded[dataname]['obs_time'],v,data_gridded[dataname]['counts'])\n",
    "        ax.set(ylabel='size ($\\mu$m$^3$)')\n",
    "        #ax.text(0.01, 0.95, desc[dataname], color='white', size=16, transform=ax.transAxes, ha='left', va='top')\n",
    "        add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='counts')\n",
    "    axs[-1].set_xlabel=('time (minutes)')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process data and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for Stan model\n",
    "\n",
    "if 'data' not in globals():\n",
    "    data = {}\n",
    "\n",
    "for dataname in data_gridded:\n",
    "    dt = 20 # in units of minutes\n",
    "    \n",
    "    data[dataname] = {'dt':dt}\n",
    "    for v in ('m','v_min','delta_v_inv'):\n",
    "        data[dataname][v] = data_gridded[dataname][v]\n",
    "\n",
    "    if 'seaflow' in dataname:\n",
    "        limit_days = 1\n",
    "        data[dataname]['obs'] = data_gridded[dataname]['w_obs']\n",
    "        data[dataname]['t_obs'] = data_gridded[dataname]['obs_time']\n",
    "                \n",
    "        # median filter PAR\n",
    "        # see: medianfilter_par.ipynb\n",
    "        n = len(data_gridded[dataname]['PAR'])\n",
    "        wsh = 30 # half of median filter window size; window size is 2*wsh+1\n",
    "        par = np.array([np.median(data_gridded[dataname]['PAR'][max(0,i-wsh):min(n,i+wsh+1)]) for i in range(n)])\n",
    "    else:\n",
    "        limit_days = 2\n",
    "        \n",
    "        data[dataname]['obs'] = data_gridded[dataname]['w_obs']\n",
    "        data[dataname]['t_obs'] = data_gridded[dataname]['obs_time']\n",
    "        par = data_gridded[dataname]['PAR']\n",
    "        \n",
    "    if limit_days > 0:\n",
    "        limit_minutes = limit_days*1440\n",
    "        \n",
    "        ind_obs = data[dataname]['t_obs'] < limit_minutes\n",
    "        data[dataname]['t_obs'] = data[dataname]['t_obs'][ind_obs]\n",
    "        data[dataname]['obs'] = data[dataname]['obs'][:,ind_obs]\n",
    "        \n",
    "        data[dataname]['nt'] = int(limit_minutes//data[dataname]['dt'])\n",
    "\n",
    "    data[dataname]['nt_obs'] = data[dataname]['t_obs'].size\n",
    "    \n",
    "    if use_testdata:\n",
    "        # load cross-validation testing indices and add them to data\n",
    "        data[dataname]['i_test'] = np.loadtxt(itestfiles[dataname]).astype(int)\n",
    "        # remove last index, so that dimensions agree\n",
    "        data[dataname]['i_test'] = data[dataname]['i_test'][:-1]\n",
    "    else:\n",
    "        # set all indices to zero\n",
    "        data[dataname]['i_test'] = np.zeros(data[dataname]['nt_obs'], dtype=int)\n",
    "        \n",
    "    # switch on or off data fitting\n",
    "    data[dataname]['prior_only'] = 0\n",
    "    \n",
    "    # add light data\n",
    "    t = np.arange(data[dataname]['nt'])*data[dataname]['dt']\n",
    "    data[dataname]['E'] = np.interp(t, xp=data_gridded[dataname]['time'], fp=par)\n",
    "    \n",
    "    # real count data\n",
    "    data[dataname]['obs_count'] = data_gridded[dataname]['counts'][:, ind_obs]\n",
    "    \n",
    "    # consistency check\n",
    "    if len(data[dataname]['i_test']) != data[dataname]['nt_obs']:\n",
    "        raise ValueError('Invalid number of testing indices for \"{}\" (expected {}, got {}).'.format(dataname,data[dataname]['nt_obs'],len(data[dataname]['i_test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_data:\n",
    "    for i,dataname in enumerate(data):\n",
    "        nrows = 3\n",
    "\n",
    "        v_min = data[dataname]['v_min']\n",
    "        delta_v = 1.0/data[dataname]['delta_v_inv']\n",
    "        v = v_min * 2**(np.arange(data[dataname]['m'])*delta_v) \n",
    "        t = np.arange(data[dataname]['nt'])*data[dataname]['dt']\n",
    "\n",
    "\n",
    "        fig,axs = plt.subplots(nrows=nrows, sharex=True, figsize=(12,4*nrows))\n",
    "\n",
    "        ax = axs[0]\n",
    "        ax.set_title('processed '+desc[dataname], size=20)\n",
    "        ax.plot(t, data[dataname]['E'], color='gold')\n",
    "        ax.set(ylabel='E')\n",
    "\n",
    "        ax = axs[1]\n",
    "        pc = ax.pcolormesh(data[dataname]['t_obs'],v,data[dataname]['obs'])\n",
    "        ax.set(ylabel='size ($\\mu$m$^3$)')\n",
    "        #ax.text(0.01, 0.95, desc[dataname], color='white', size=16, transform=ax.transAxes, ha='left', va='top')\n",
    "        add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='size class proportion')\n",
    "        ax.set_xlim(left=0.0)\n",
    "\n",
    "        ax = axs[2]\n",
    "        pc = ax.pcolormesh(data[dataname]['t_obs'],v,data[dataname]['obs_count'])\n",
    "        ax.set(ylabel='size ($\\mu$m$^3$)')\n",
    "        #ax.text(0.01, 0.95, desc[dataname], color='white', size=16, transform=ax.transAxes, ha='left', va='top')\n",
    "        add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='counts')\n",
    "        ax.set_xlim(left=0.0)\n",
    "    axs[-1].set_xlabel('time (minutes)')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_model = {\n",
    "    #'m1':'m1',\n",
    "    #'m2':'m2',\n",
    "    #'m3':'m3',\n",
    "    #'m4':'m4',\n",
    "    #'m5':'m5',\n",
    "    #'m6':'m6',\n",
    "    #'m7':'m7',\n",
    "    #'m8':'m8',\n",
    "    #'m9':'m9',\n",
    "    #'m10':'m10',\n",
    "    #'m11':'m5-m6 hybrid',\n",
    "    #'m12':'m5-m7 hybrid',\n",
    "    #'m13':'m5-m8 hybrid',\n",
    "    #'m14':'m5-m9 hybrid',\n",
    "    #'m5tau':'m5 + time-dep div (2h bins)',\n",
    "    #'m7tau':'m7 + time-dep div (2h bins)',\n",
    "    'm5taus':'m5 + time-dep div (spline)',\n",
    "    'm7taus':'m7 + time-dep div (spline)',\n",
    "    'm5taus2':'m5 + time-dep div (spline), no size-dep',\n",
    "    'm7taus2':'m7 + time-dep div (spline), no size-dep',\n",
    "}\n",
    "# preparing for some regular expression magic\n",
    "model_code_replacements = {\n",
    "    'm1':(),\n",
    "    'm2':(),\n",
    "    'm3':(),\n",
    "    'm4':(),\n",
    "    'm5':(),\n",
    "    'm6':(),\n",
    "    'm7':(),\n",
    "    'm8':(),\n",
    "    'm9':(),\n",
    "    'm10':(),\n",
    "    'm11':(),\n",
    "    'm12':(),\n",
    "    'm13':(),\n",
    "    'm14':(),\n",
    "    'm5tau':(),\n",
    "    'm7tau':(),\n",
    "    'm5taus':(),\n",
    "    'm7taus':(),\n",
    "    'm5taus2':(),\n",
    "    'm7taus2':(),\n",
    "}\n",
    "model_stan_key = {\n",
    "    'm1':'c1',\n",
    "    'm2':'c2',\n",
    "    'm3':'c3',\n",
    "    'm4':'c4',\n",
    "    'm5':'c5',\n",
    "    'm6':'c6',\n",
    "    'm7':'c7',\n",
    "    'm8':'c8',\n",
    "    'm9':'c9',\n",
    "    'm10':'c10',\n",
    "    'm11':'c11',\n",
    "    'm12':'c12',\n",
    "    'm13':'c13',\n",
    "    'm14':'c14',\n",
    "    'm5tau':'c5tau',\n",
    "    'm7tau':'c7tau',\n",
    "    'm5taus':'c5taus',\n",
    "    'm7taus':'c7taus',\n",
    "    'm5taus2':'c5taus2',\n",
    "    'm7taus2':'c7taus2',\n",
    "}\n",
    "stan_files = {\n",
    "    'c1':'stancode_gallery2/trackvol_version/matrixmodel_mlmultinom_estinilnorm2_freedelta_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c2':'stancode_gallery2/trackvol_version/matrixmodel_mlmultinom_estinilnorm2_monodelta2_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c3':'stancode_gallery2/trackvol_version/matrixmodel_mlmultinom_estinilnorm2_monodelta2_gammaiv6_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c4':'stancode_gallery2/trackvol_version/matrixmodel_mlmultinom_estinilnorm2_monodelta2_respv1_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c5':'stancode_gallery2/trackvol_version/matrixmodel_mlmultinom_estinilnorm2_monodelta2_respv2_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c6':'stancode_gallery2/trackvol_version/matrixmodel_mlmultinom_estinilnorm2_monodelta2_respiv6_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c7':'stancode_gallery2/trackvol_version/matrixmodel_mlmultinom_estinilnorm2_monodelta2_respiv7_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c8':'stancode_gallery2/trackvol_version/matrixmodel_mlmultinom_estinilnorm2_monodelta2-lightsig_respiv6_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c9':'stancode_gallery2/trackvol_version/matrixmodel_mlmultinom_estinilnorm2_monodelta2-lightsig_respiv7_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c10':'stancode_gallery2/trackvol_version/matrixmodel_mlmultinom_estinilnorm2_monodelta2-lightsig_respv2_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c11':'stancode_gallery2/trackvol_version/matrixmodel_mlmultinom_estinilnorm2_monodelta2_resp_gammaiv6_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c12':'stancode_gallery2/trackvol_version/matrixmodel_mlmultinom_estinilnorm2_monodelta2_resp_gammaiv7_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c13':'stancode_gallery2/trackvol_version/matrixmodel_mlmultinom_estinilnorm2_monodelta2-lightsig_resp_gammaiv6_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c14':'stancode_gallery2/trackvol_version/matrixmodel_mlmultinom_estinilnorm2_monodelta2-lightsig_resp_gammaiv7_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c5tau':'stancode/matrixmodel_mlmultinom_estinilnorm2_monodelta2-time2hb_respv2_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c7tau':'stancode/matrixmodel_mlmultinom_estinilnorm2_monodelta2-time2hb_respiv7_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c5taus':'stancode/matrixmodel_mlmultinom_estinilnorm2_monodelta2-timespline_respv2_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c7taus':'stancode/matrixmodel_mlmultinom_estinilnorm2_monodelta2-timespline_respiv7_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c5taus2':'stancode/matrixmodel_mlmultinom_estinilnorm2_delta-timespline_respv2_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c7taus2':'stancode/matrixmodel_mlmultinom_estinilnorm2_delta-timespline_respiv7_normparam_trackgrowthvol_xval2.stan',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL m5taus NOW.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m5taus: code change detected, recompiling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL m7taus NOW.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m7taus: compiling\n",
      "m5taus: change in model code requires re-running model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m5taus (m5 + time-dep div (spline))\n",
      "Inference for Stan model: m5taus.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "                       mean se_mean      sd     2.5%     25%      50%     75%   97.5%  n_eff   Rhat\n",
      "delta_max             61.12    0.18    7.27    45.02   56.26    62.22   66.99   71.45   1588    1.0\n",
      "gamma_max              2.99    0.02    0.68     1.88     2.5     2.93    3.41    4.53   2020    1.0\n",
      "rho_max              5.4e-4  6.8e-6  5.5e-4   1.4e-5  1.5e-4   3.7e-4  7.5e-4  2.0e-3   6542    1.0\n",
      "E_star               2297.4   14.88  716.27   1077.5  1791.0   2245.3  2748.3  3905.8   2318    1.0\n",
      "sigma                1133.2    0.76   58.46   1021.5  1093.9   1131.1  1172.4  1252.0   5967    1.0\n",
      "divrate                0.76  1.2e-3    0.06     0.63    0.73     0.76     0.8    0.86   2215    1.0\n",
      "lp__                 -2.2e7    0.53   20.48   -2.2e7  -2.2e7   -2.2e7  -2.2e7  -2.2e7   1488    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Thu Jul 16 14:51:12 2020.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n",
      "\n",
      "m5taus: change in model code requires re-running model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:44 of 4000 iterations ended with a divergence (1.1 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.8 to remove the divergences.\n",
      "WARNING:pystan:908 of 4000 iterations saturated the maximum tree depth of 10 (22.7 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m5taus (m5 + time-dep div (spline))\n",
      "Inference for Stan model: m5taus.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "                        mean se_mean      sd    2.5%     25%     50%     75%   97.5%  n_eff   Rhat\n",
      "delta_max              34.09    0.23    8.49   22.68   28.25   32.34   37.57   57.71   1348    1.0\n",
      "gamma_max                7.7    0.03    0.82    5.83    7.13    7.85    8.41    8.77   1005    1.0\n",
      "rho_max                 1.53  3.2e-3    0.12    1.27    1.45    1.53    1.61    1.72   1336    1.0\n",
      "E_star                234.38     1.4   41.06  140.15  207.05  240.73  266.31  296.33    860    1.0\n",
      "sigma                 425.56    0.45   25.51  376.99  408.58  424.64   442.3  476.98   3166    1.0\n",
      "divrate                 0.76  2.2e-3    0.09    0.61     0.7    0.75    0.81    0.97   1746    1.0\n",
      "lp__                  -3.0e9    0.51   18.56  -3.0e9  -3.0e9  -3.0e9  -3.0e9  -3.0e9   1310    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Thu Jul 16 16:25:23 2020.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m7taus (m7 + time-dep div (spline))\n",
      "Inference for Stan model: m7taus.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "                       mean se_mean      sd    2.5%     25%     50%     75%   97.5%  n_eff   Rhat\n",
      "delta_max             69.13    0.04    2.65   62.19   67.84   69.96   71.13    71.9   5551    1.0\n",
      "gamma_max              4.87  3.2e-3    0.27    4.18    4.73    4.95    5.08    5.16   7114    1.0\n",
      "rho_max                2.92    0.02    1.48    0.17    1.72     3.1    4.21    5.08   8107    1.0\n",
      "E_star               540.21     3.5   250.0   127.8  357.74  521.74  696.79  1091.3   5088    1.0\n",
      "sigma                1250.3     0.8    63.6  1128.8  1207.0  1249.5  1291.3  1378.8   6285    1.0\n",
      "xi                     0.01  2.0e-5  1.4e-3    0.01    0.01    0.01    0.02    0.02   4784    1.0\n",
      "xir                    0.13  8.9e-4    0.04    0.08     0.1    0.12    0.15    0.23   2133    1.0\n",
      "divrate                0.68  8.6e-4    0.05    0.58    0.64    0.67    0.71    0.78   3523    1.0\n",
      "lp__                 -2.2e7    0.56    21.1  -2.2e7  -2.2e7  -2.2e7  -2.2e7  -2.2e7   1431    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Thu Jul 16 18:00:26 2020.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n",
      "\n",
      "m7taus: change in model code requires re-running model\n"
     ]
    }
   ],
   "source": [
    "import pystan\n",
    "import re\n",
    "import time\n",
    "\n",
    "def get_max_rhat(fit):\n",
    "    s = fit.summary()\n",
    "    irhat = s['summary_colnames'].index(\"Rhat\")\n",
    "    return np.nanmax(s['summary'][:,irhat])\n",
    "\n",
    "if 'models' not in globals():\n",
    "    models = {}\n",
    "if 'mcmcs' not in globals():\n",
    "    mcmcs = {}\n",
    "if 'maxrhats' not in globals():\n",
    "    maxrhats = {}\n",
    "if 'sampling_time' not in globals():\n",
    "    sampling_time = {}\n",
    "    \n",
    "try_again = True\n",
    "refit_all = False\n",
    "\n",
    "refit_required = {}\n",
    "stan_base_code = {}\n",
    "for key,stan_file in stan_files.items():\n",
    "    with open(stan_file) as f:\n",
    "        stan_base_code[key] = f.read()\n",
    "\n",
    "stan_code = {}\n",
    "for model in desc_model:\n",
    "    code_split = stan_base_code[model_stan_key[model]].split('\\n')\n",
    "    code_split_new = []\n",
    "    for line in code_split:\n",
    "        line_new = line\n",
    "        for replacement in model_code_replacements[model]:\n",
    "            m = re.match(replacement[0],line_new)\n",
    "            if m:\n",
    "                line_new = m.groups(0)[0]+replacement[1]\n",
    "                print('{}: patching in \"{}\"'.format(model, line_new))\n",
    "        code_split_new.append(line_new)\n",
    "                \n",
    "    stan_code[model] = '\\n'.join(code_split_new)\n",
    "\n",
    "for model in desc_model:\n",
    "    refit_required[model] = True\n",
    "    if model in models and models[model].model_code == stan_code[model]:\n",
    "        print('{}: unchanged code, not recompiling'.format(model))\n",
    "        refit_required[model] = False\n",
    "    else:\n",
    "        if model in models:\n",
    "            print('{}: code change detected, recompiling'.format(model))\n",
    "        else:\n",
    "            print('{}: compiling'.format(model))\n",
    "        models[model] = pystan.StanModel(model_code=stan_code[model], model_name=model, obfuscate_model_name=False)\n",
    "\n",
    "# run a bunch of experiments -- this may take a while\n",
    "for model in models:\n",
    "    if model not in maxrhats:\n",
    "        maxrhats[model] = {}\n",
    "    if model not in sampling_time:\n",
    "        sampling_time[model] = {}\n",
    "    for dataname in data:\n",
    "        if dataname not in maxrhats[model]:\n",
    "            maxrhats[model][dataname] = []\n",
    "        if dataname not in sampling_time[model]:\n",
    "            sampling_time[model][dataname] = []\n",
    "        if model in mcmcs:\n",
    "            if dataname in mcmcs[model] and not refit_all and not refit_required[model]:\n",
    "                print('{}: found existing results:'.format(model))\n",
    "                print('{} ({})'.format(model, desc_model[model])) \n",
    "                print('\\n'.join(x for x in mcmcs[model][dataname].__str__().split('\\n') if '[' not in x))\n",
    "                rhat_max = get_max_rhat(mcmcs[model][dataname])\n",
    "                if try_again and rhat_max >= 1.1:\n",
    "                    print('{}: found Rhat={:.3f}, trying again'.format(model,rhat_max))\n",
    "                else:\n",
    "                    print('{}: not re-running model'.format(model))\n",
    "                    print()\n",
    "                    continue\n",
    "            elif refit_all:\n",
    "                print('{}: refit_all is active, re-running model'.format(model))\n",
    "            elif refit_required[model]:\n",
    "                print('{}: change in model code requires re-running model'.format(model))\n",
    "        else:\n",
    "            mcmcs[model] = {}\n",
    "        for itry in range(3):\n",
    "            t0 = time.time()\n",
    "            mcmcs[model][dataname] = models[model].sampling(data=data[dataname], iter=2000)\n",
    "            sampling_time[model][dataname].append(time.time() - t0) # in seconds\n",
    "            # get max Rhat\n",
    "            rhat_max = get_max_rhat(mcmcs[model][dataname])\n",
    "            maxrhats[model][dataname].append(rhat_max)\n",
    "            if rhat_max < 1.1:\n",
    "                break\n",
    "            print('{}: in try {}/3 found Rhat={:.3f}, trying again'.format(model,itry+1,rhat_max))\n",
    "        print('{} ({})'.format(model, desc_model[model])) \n",
    "        print('\\n'.join(x for x in mcmcs[model][dataname].__str__().split('\\n') if '[' not in x))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['axes.labelsize'] = 20\n",
    "mpl.rcParams['legend.fontsize'] = 16\n",
    "mpl.rcParams['axes.titlesize'] = 26\n",
    "mpl.rcParams['figure.figsize'] = (24,12)\n",
    "mpl.rcParams['xtick.labelsize'] = 16\n",
    "mpl.rcParams['ytick.labelsize'] = 16\n",
    "\n",
    "# set the color for each model\n",
    "num_model = len(mcmcs)\n",
    "if num_model <= 10:\n",
    "    colors_model = {model:'C{}'.format(imodel) for imodel,model in enumerate(mcmcs)}\n",
    "else:\n",
    "    colors_model = {model:mpl.cm.viridis(imodel/(num_model-1)) for imodel,model in enumerate(mcmcs)}\n",
    "    \n",
    "maxrhats_final = {model:{dataname:get_max_rhat(mcmcs[model][dataname]) for dataname in data} for model in mcmcs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_desc = {'divrate':'daily division rate','E_star':'E*'}\n",
    "# add known values here\n",
    "reference_values = {'zinser':{'divrate':0.69}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot posterior values of tau\n",
    "for ax,dataname in zip(axs.flat,data):\n",
    "\n",
    "    nt_1day = 1440//data[dataname]['dt']\n",
    "    t_1day = np.arange(nt_1day)*data[dataname]['dt']\n",
    "    \n",
    "    for model,mcmc in mcmcs.items():\n",
    "        if 'tau[1]' not in mcmc[dataname].flatnames:\n",
    "            continue\n",
    "        if mcmc[dataname]['tau'].shape[1] < nt_1day:\n",
    "            fig, ax = plt.subplots(figsize=(20,6))\n",
    "            ax.set_title(desc_model[model] + '\\n' + desc[dataname])\n",
    "            ax.boxplot(mcmc[dataname]['tau'])\n",
    "            \n",
    "            num_tau = mcmc[dataname]['tau'].shape[1]\n",
    "            if num_tau == 12:\n",
    "                ax.set_xticks(np.arange(0.5,num_tau+1.5))\n",
    "                xlabels = ['{:2d}:00'.format((2*x)%24) for x in range(13)]\n",
    "                ax.set_xticklabels(xlabels)\n",
    "            ax.grid(axis='y')\n",
    "            ax.set_ylabel('$\\\\tau$')\n",
    "\n",
    "            if maxrhats_final[model][dataname] > 1.1:\n",
    "                ax.text(0.5, 0.5, 'no convergence ($\\\\hat{R}>1.1$)', color='darkred', size=26, transform=ax.transAxes, ha='center', va='center')\n",
    "            None\n",
    "            \n",
    "        else:\n",
    "            fig, axs = plt.subplots(nrows=2, sharex=True, sharey=True)\n",
    "            ax = axs[0]\n",
    "            ax.set_title('{}: {} $\\\\tau$ posterior samples'.format(desc[dataname], desc_model[model]))\n",
    "            for i in range(5):\n",
    "                ll = ax.plot(t_1day, mcmc[dataname]['tau'][i,:], alpha=0.5)\n",
    "                ax.plot(t_1day-1440, mcmc[dataname]['tau'][i,:], alpha=0.5, ls=':', color=ll[0].get_color())\n",
    "                ax.plot(t_1day+1440, mcmc[dataname]['tau'][i,:], alpha=0.5, ls=':', color=ll[0].get_color())\n",
    "            ax.grid(True)\n",
    "\n",
    "            qq = np.percentile(mcmc[dataname]['tau'], q=(5,25,50,75,95), axis=0)\n",
    "            \n",
    "            ax = axs[1]\n",
    "            ax.set_title('{}: {} $\\\\tau$ posterior distribution'.format(desc[dataname], desc_model[model]))\n",
    "            ax.fill_between(t_1day, qq[0,:], qq[-1,:], alpha=0.25, color='gold')\n",
    "            ax.fill_between(t_1day, qq[1,:], qq[-2,:], alpha=0.5, color='gold')\n",
    "            ax.plot(t_1day, qq[2,:], color='gold')\n",
    "        \n",
    "            ax.set_xlim((-100,1440+100))\n",
    "            ax.set_ylim((0.0, 1.05))\n",
    "            ax.set_xlabel('time (minutes)')\n",
    "            ax.grid(True)\n",
    "            \n",
    "            fig.savefig('spline_posterior_{}_{}.png'.format(dataname, model), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ylim_top = 0\n",
    "for dataname in data:\n",
    "    for model in mcmcs:\n",
    "        ylim_top = max(ylim_top, len(maxrhats[model][dataname]))\n",
    "ylim_top += 1\n",
    "\n",
    "fig, axs = plt.subplots(nrows=len(data), figsize=(max(24,len(mcmcs)*4.5),len(data)*9), sharex=True, sharey=True)\n",
    "for ax,dataname in zip(axs.flat,data):\n",
    "    xticks = []\n",
    "    xticklabels = []\n",
    "    for i,model in enumerate(mcmcs):\n",
    "        \n",
    "        height_bad = sum(rh > 1.1 for rh in maxrhats[model][dataname])\n",
    "        height_good = len(maxrhats[model][dataname]) - height_bad\n",
    "        \n",
    "        x = i\n",
    "        ax.bar(x=x, height=height_bad, color='tab:red', label='max $\\\\\\\\hat{R}$ > 1.1')\n",
    "        ax.bar(x=x, height=height_good, bottom=height_bad, color='tab:green', label='max $\\\\hat{R} \\le$ 1.1')\n",
    "        \n",
    "        if len(sampling_time[model][dataname]) != height_bad+height_good:\n",
    "            print('{}, {}: Timing information inconsistent.'.format(dataname, desc_model[model]))\n",
    "        else:\n",
    "            for it, t in enumerate(sampling_time[model][dataname]):\n",
    "                ax.text(x, it+0.5, '{:.0f}:{:02.0f}'.format(t//60, t%60), ha='center', va='center', size=30)\n",
    "            \n",
    "        xticks.append(x)\n",
    "        xticklabels.append(desc_model[model].replace(',',',\\n'))\n",
    "    \n",
    "    ax.set(ylabel='number of Stan sampling runs', xticks=xticks, ylim=(0, ylim_top))\n",
    "    ax.set_title('convergence/$\\hat{R}$ statistics for '+desc[dataname], size=20)\n",
    "    ax.set_xticklabels(xticklabels)#, rotation=8)\n",
    "    ax.grid(axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated code can handle all data[dataname]['i_test'] == 0 and draw only a single bar\n",
    "if np.all(data[dataname]['i_test'] == 0):\n",
    "    num_bars = 1\n",
    "else:\n",
    "    num_bars = 3\n",
    "\n",
    "height = np.zeros(num_bars)\n",
    "for dataname in data:\n",
    "    obs = data[dataname]['obs']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(max(24,len(mcmcs)*4.5),9))\n",
    "    xticks = []\n",
    "    xticklabels = []\n",
    "    for i,model in enumerate(mcmcs):\n",
    "        mod_mean = np.mean(mcmcs[model][dataname]['mod_obspos'], axis=0)\n",
    "        mod_mean /= np.sum(mod_mean, axis=0)\n",
    "        \n",
    "        e = np.sum((mod_mean-obs)**2,axis=0)\n",
    "        #print(desc_model[model],e)\n",
    "        \n",
    "        height[0] = np.mean(e)\n",
    "        if num_bars > 1:\n",
    "            height[1] = np.mean(e[data[dataname]['i_test'] == 0])\n",
    "            height[2] = np.mean(e[data[dataname]['i_test'] == 1])\n",
    "        \n",
    "        x = (num_bars+1)*i+np.arange(num_bars)\n",
    "        ax.bar(x=x, height=height, color=colors_model[model])\n",
    "        for xx,text in zip(x,['overall mean','training mean','test mean']):\n",
    "            ax.text(xx, 0, '  '+text, rotation=90, ha='center', va='bottom', size=20)\n",
    "        if maxrhats_final[model][dataname] > 1.1:\n",
    "            ax.text(x[num_bars//3], 0, '  no convergence ($\\\\hat{R}>1.1$)', rotation=45, ha='center', va='bottom', size=30, color='darkred')\n",
    "        xticks.append(x[num_bars//3])\n",
    "        xticklabels.append(desc_model[model].replace(',',',\\n').replace('(','\\n('))\n",
    "    \n",
    "    if ax.get_ylim()[1] > 0.005:\n",
    "        ax.set_ylim(top=0.005)\n",
    "    ax.set(ylabel='sum of squared column differences', xticks=xticks)\n",
    "    ax.set_title('model misfit for '+desc[dataname], size=20)\n",
    "    ax.set_xticklabels(xticklabels)#, rotation=8)\n",
    "    ax.grid(axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_labels = True\n",
    "for dataname in data:\n",
    "    if 'zinser' in dataname:\n",
    "        fig, ax = plt.subplots(figsize=(14,14))\n",
    "        ax.set_title(desc[dataname], size=20)\n",
    "        \n",
    "        for model in mcmcs:\n",
    "            # misfit to data\n",
    "\n",
    "            obs = data[dataname]['obs']\n",
    "\n",
    "            tmp = mcmcs[model][dataname]['mod_obspos']\n",
    "            tmp/= np.sum(tmp, axis=1)[:,None,:]\n",
    "            tmp -= obs[None,:,:]\n",
    "            tmp **= 2\n",
    "            \n",
    "            if np.all(data[dataname]['i_test'] == 0):\n",
    "                e0 = np.mean(np.sum(tmp, axis=1), axis=1)\n",
    "                xlabel_suffix = ''\n",
    "            else:\n",
    "                e0 = np.mean(np.sum(tmp[:,:,data[dataname]['i_test'] == 1], axis=1), axis=1)\n",
    "                xlabel_suffix = ' (test data)'\n",
    "            \n",
    "            # misfit to division rate\n",
    "\n",
    "            e1 = np.abs(mcmcs[model][dataname]['divrate'] - reference_values[dataname]['divrate'])\n",
    "        \n",
    "            q0 = np.percentile(e0, q=(5,25,50,75,95))\n",
    "            q1 = np.percentile(e1, q=(5,25,50,75,95))\n",
    "            \n",
    "            eb = ax.errorbar(x=q0[2], y=q1[2], xerr=np.array((q0[2]-q0[0], q0[-1]-q0[2]))[:,None], marker='o', ms=10, label=desc_model[model], color=colors_model[model])\n",
    "            ax.errorbar(x=q0[2], y=q1[2], yerr=np.array((q1[2]-q1[0], q1[-1]-q1[2]))[:,None], color=eb[0].get_color())\n",
    "            \n",
    "            if add_labels:\n",
    "                ax.text(q0[2], q1[2], ' '+desc_model[model], color=eb[0].get_color(), size=20)\n",
    "            \n",
    "            if maxrhats_final[model][dataname] > 1.1:\n",
    "                ax.plot(q0[2], q1[2], marker='x', color='darkred', zorder=10, markersize=30, markeredgewidth=3)\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "        ax.set(xlabel='size distribution misfit'+xlabel_suffix, ylabel='daily division rate misfit')\n",
    "        ax.set_xlim(left=0.0)\n",
    "        ax.set_ylim(bottom=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datanames = tuple(data.keys())\n",
    "if len(datanames) > 1:\n",
    "    fig, ax = plt.subplots(figsize=(14,14))\n",
    "\n",
    "    for model in mcmcs:\n",
    "        qq = {}\n",
    "        # misfit to data\n",
    "        for dataname in datanames:\n",
    "            obs = data[dataname]['obs']\n",
    "\n",
    "            tmp = mcmcs[model][dataname]['mod_obspos']\n",
    "            tmp/= np.sum(tmp, axis=1)[:,None,:]\n",
    "            tmp -= obs[None,:,:]\n",
    "            tmp **= 2\n",
    "\n",
    "            if np.all(data[dataname]['i_test'] == 0):\n",
    "                e0 = np.mean(np.sum(tmp, axis=1), axis=1)\n",
    "            else:\n",
    "                e0 = np.mean(np.sum(tmp[:,:,data[dataname]['i_test'] == 1], axis=1), axis=1)\n",
    "\n",
    "            qq[dataname] = np.percentile(e0, q=(5,25,50,75,95))\n",
    "\n",
    "        q0 = qq[datanames[0]]\n",
    "        q1 = qq[datanames[1]]\n",
    "\n",
    "        eb = ax.errorbar(x=q0[2], y=q1[2], xerr=np.array((q0[2]-q0[0], q0[-1]-q0[2]))[:,None], marker='o', ms=10, label=desc_model[model], color=colors_model[model])\n",
    "        ax.errorbar(x=q0[2], y=q1[2], yerr=np.array((q1[2]-q1[0], q1[-1]-q1[2]))[:,None], color=eb[0].get_color())\n",
    "        if maxrhats_final[model][dataname] > 1.1:\n",
    "            ax.plot(q0[2], q1[2], marker='x', color='darkred', zorder=10, markersize=30, markeredgewidth=3)\n",
    "\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    ax.set(xlabel='{} size distribution misfit'.format(desc[datanames[0]]), \n",
    "           ylabel='{} size distribution misfit'.format(desc[datanames[1]]))\n",
    "    ax.set_xlim(left=0.0)\n",
    "    ax.set_ylim(bottom=0.0)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fig2a = pd.read_csv('data/Zinser_Figure2A.csv')\n",
    "t_zinser = data_fig2a['exper time'] * 60\n",
    "ab_mean_norm = 0.5*(data_fig2a['cells A'].values/data_fig2a['cells A'].values[0] + \n",
    "                    data_fig2a['cells B'].values/data_fig2a['cells B'].values[0])\n",
    "\n",
    "add_labels = True\n",
    "for dataname in data:\n",
    "    if 'zinser' in dataname:\n",
    "        fig, ax = plt.subplots(figsize=(14,14))\n",
    "        ax.set_title(desc[dataname], size=20)\n",
    "        \n",
    "        for model in mcmcs:\n",
    "            # make sure the time is right, if not implement something fancier\n",
    "            assert all(t_zinser.values[:-1] == data[dataname]['t_obs'])\n",
    "            \n",
    "            # misfit to normalized abundance\n",
    "            \n",
    "            e0 = np.mean(np.abs(np.sum(mcmcs[model][dataname]['mod_obspos'], axis=1)[:,1:]-ab_mean_norm[1:-1]), axis=1)\n",
    "            \n",
    "            # misfit to division rate\n",
    "\n",
    "            e1 = np.abs(mcmcs[model][dataname]['divrate'] - reference_values[dataname]['divrate'])\n",
    "        \n",
    "            q0 = np.percentile(e0, q=(5,25,50,75,95))\n",
    "            q1 = np.percentile(e1, q=(5,25,50,75,95))\n",
    "            \n",
    "            eb = ax.errorbar(x=q0[2], y=q1[2], xerr=np.array((q0[2]-q0[0], q0[-1]-q0[2]))[:,None], marker='o', ms=10, label=desc_model[model], color=colors_model[model])\n",
    "            ax.errorbar(x=q0[2], y=q1[2], yerr=np.array((q1[2]-q1[0], q1[-1]-q1[2]))[:,None], color=eb[0].get_color())\n",
    "            if add_labels:\n",
    "                ax.text(q0[2], q1[2], ' '+desc_model[model], color=eb[0].get_color(), size=20)\n",
    "            if maxrhats_final[model][dataname] > 1.1:\n",
    "                ax.plot(q0[2], q1[2], marker='x', color='darkred', zorder=10, markersize=30, markeredgewidth=3)\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "        ax.set(xlabel='normalized abundance misfit (hourly division rate)', ylabel='daily division rate misfit')\n",
    "        ax.set_xlim(left=0.0)\n",
    "        ax.set_ylim(bottom=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for param in ('divrate','E_star'):\n",
    "    for dataname in data:\n",
    "        num_mcmcs = len(mcmcs)\n",
    "        fig, ax = plt.subplots(figsize=(24,3*num_mcmcs))\n",
    "        ax.set_title('{} for {}'.format(param_desc[param], desc[dataname]))\n",
    "        ax.violinplot([mcmcs[model][dataname][param] for model in mcmcs], showmedians=True, vert=False)\n",
    "        ax.invert_yaxis()\n",
    "        ax.grid(axis='x')\n",
    "        ax.set(yticks=np.arange(1,num_mcmcs+1), yticklabels=[desc_model[model].replace(',',',\\n') for model in mcmcs])\n",
    "        if dataname in reference_values and param in reference_values[dataname]:\n",
    "            ax.axvline(reference_values[dataname][param], color='tab:green', lw=3)\n",
    "        for i,model in enumerate(mcmcs):\n",
    "            if maxrhats_final[model][dataname] > 1.1:\n",
    "                ax.text(0.5, i+1, 'no convergence ($\\\\hat{R}>1.1$)', color='darkred', size=26, transform=ax.get_yaxis_transform(), ha='center', va='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for dataname in data:\n",
    "    for model,mcmc in mcmcs.items():\n",
    "        j = data_gridded[dataname]['delta_v_inv'] + 1\n",
    "        m = data_gridded[dataname]['m']\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(20,6))\n",
    "        ax.set_title(desc_model[model] + '\\n' + desc[dataname])\n",
    "        ax.boxplot(mcmc[dataname]['delta'])\n",
    "        xlabels = [str(x) for x in range(j,m+1)]\n",
    "        xlabels[0] = 'j='+xlabels[0]\n",
    "        xlabels[-1] = 'm='+xlabels[-1]\n",
    "        ax.set_xticklabels(xlabels)\n",
    "        ax.grid(axis='y')\n",
    "        ax.set_ylabel('$\\\\delta_{max}$')\n",
    "        \n",
    "        if maxrhats_final[model][dataname] > 1.1:\n",
    "            ax.text(0.5, 0.5, 'no convergence ($\\\\hat{R}>1.1$)', color='darkred', size=26, transform=ax.transAxes, ha='center', va='center')\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_fig2a = pd.read_csv('data/Zinser_Figure2A.csv')\n",
    "\n",
    "t_zinser = data_fig2a['exper time'] * 60\n",
    "a_norm = data_fig2a['cells A'].copy()\n",
    "a_norm /= a_norm[0]\n",
    "b_norm = data_fig2a['cells B'].copy()\n",
    "b_norm /= b_norm[0]\n",
    "\n",
    "colors = {'model':'darkred', 'obs':'0.1'}\n",
    "\n",
    "norm = mpl.colors.Normalize(0.0,0.15)\n",
    "norm_diff = mpl.colors.Normalize(-0.1,0.1)\n",
    "\n",
    "for dataname in data:\n",
    "    t = data[dataname]['dt']*np.arange(data[dataname]['nt'])\n",
    "    delta_v = 1.0/data_gridded[dataname]['delta_v_inv']\n",
    "    v_ext = data[dataname]['v_min'] * 2**(np.arange(data[dataname]['m']+1)*delta_v) \n",
    "    v = v_ext[:-1]\n",
    "    v_width = v_ext[1:] - v_ext[:-1]\n",
    "        \n",
    "    for model,mcmc in mcmcs.items():\n",
    "        \n",
    "        res = {'model':np.mean(mcmc[dataname]['mod_obspos'], axis=0), 'obs':data[dataname]['obs']}\n",
    "        res_sum1 = res['model']/np.sum(res['model'], axis=0)[None,:]\n",
    "        diff = res_sum1-res['obs']\n",
    "\n",
    "        if maxrhats_final[model][dataname] > 1.1:\n",
    "            fig, ax = plt.subplots(figsize=(24,4))\n",
    "            ax.set_title(desc_model[model] + '\\n' + desc[dataname])\n",
    "            ax.set(xticks=[], yticks=[])\n",
    "            ax.text(0.5, 0.5, 'no convergence ($\\\\hat{R}>1.1$)', color='darkred', size=26, transform=ax.transAxes, ha='center', va='center')\n",
    "            continue\n",
    "        \n",
    "        fig,axs = plt.subplots(6,1,sharex=True,figsize=(24,40))\n",
    "        axs[0].set_title(desc_model[model] + '\\n' + desc[dataname])\n",
    "\n",
    "        ax = axs[0]\n",
    "        ax.plot(t, data[dataname]['E'], color='gold')\n",
    "        ax.set(xlim=(data[dataname]['t_obs'][0],t[-1]), ylabel='PAR')\n",
    "\n",
    "        ax = axs[1]\n",
    "        pc = ax.pcolormesh(data[dataname]['t_obs'],v,res['obs'],norm=norm)\n",
    "        ax.set(ylabel='size ($\\mu$m$^3$)', title='size distribution data')\n",
    "        add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='size class proportion')\n",
    "\n",
    "        ax = axs[2]\n",
    "        ax.set(ylabel='size ($\\mu$m$^3$)', title='size distribution model posterior')\n",
    "        pc = ax.pcolormesh(data[dataname]['t_obs'],v,res_sum1,norm=norm)\n",
    "\n",
    "        ax = axs[3]\n",
    "        pc = ax.pcolormesh(data[dataname]['t_obs'],v,diff,norm=norm_diff, cmap='PiYG')\n",
    "        ax.set(ylabel='size ($\\mu$m$^3$)', title='model - data misfit')\n",
    "        add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='difference in size class proportion')\n",
    "        \n",
    "        qq = np.percentile(np.sum(mcmc[dataname]['mod_obspos'], axis=1), axis=0, q=(5,25,50,75,95))\n",
    "    \n",
    "        ax = axs[4]\n",
    "        ax.fill_between(data[dataname]['t_obs'], qq[0,:], qq[-1,:], alpha=0.25, color='gold')\n",
    "        ax.fill_between(data[dataname]['t_obs'], qq[1,:], qq[-2,:], alpha=0.5, color='gold')\n",
    "        ax.plot(data[dataname]['t_obs'], qq[2,:], color='gold')\n",
    "        if 'zinser' in dataname:\n",
    "            ax.plot(t_zinser, a_norm, color='black', marker='s', label='Zinser normalized \"cells A\"')\n",
    "            ax.plot(t_zinser, b_norm, color='red', marker='^', label='Zinser normalized \"cells B\"')\n",
    "            for iday in range(2):\n",
    "                ax.axvspan(iday*24*60+12*60, iday*24*60+22*60, color='0.7', zorder=0)\n",
    "            ax.legend()\n",
    "        ax.grid(True)\n",
    "        ax.set(ylabel='sum across size classes', title='relative increase in population size (division)')\n",
    "\n",
    "        ax = axs[5]\n",
    "        prop = np.mean(np.abs(diff),axis=0)\n",
    "        ax.plot(data[dataname]['t_obs'], prop, label='mean(abs(diff)), avg: {:.6f}'.format(np.mean(prop)))\n",
    "        prop = np.sum(diff**2,axis=0)\n",
    "        ax.plot(data[dataname]['t_obs'], prop, label='sum(diff$^2$), avg: {:.6f}'.format(np.mean(prop)))\n",
    "        ax.set(xlabel='time (minutes)', ylabel='model-observation misfit')\n",
    "        ax.grid(True)\n",
    "        ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "if 'varnames_save' not in globals():\n",
    "    varnames_save = None\n",
    "\n",
    "if savename_output is not None:    \n",
    "    with nc4.Dataset(savename_output, 'w') as nc:\n",
    "        for dataname in data:\n",
    "            ncg = nc.createGroup(dataname)\n",
    "\n",
    "            if save_stan_output:\n",
    "                dimensions = {\n",
    "                    'obstime':int(data[dataname]['nt_obs']),\n",
    "                    'time':int(data[dataname]['nt']),\n",
    "                    'sizeclass':int(data[dataname]['m']),\n",
    "                    'm_minus_j_plus_1':int(data[dataname]['m']-data[dataname]['delta_v_inv']),\n",
    "                }\n",
    "                dimensions_inv = {v:k for k,v in dimensions.items()}\n",
    "                for d in dimensions:\n",
    "                    ncg.createDimension(d, dimensions[d])\n",
    "                    \n",
    "                ncg.createVariable('time', int, ('time',))\n",
    "                ncg.variables['time'][:] = int(data[dataname]['dt']) * np.arange(data[dataname]['nt'])\n",
    "                ncg.variables['time'].units = 'minutes since start of experiment'\n",
    "                \n",
    "                ncg.createVariable('obstime', int, ('obstime',))\n",
    "                ncg.variables['obstime'][:] = data[dataname]['t_obs'].astype(int)\n",
    "                ncg.variables['obstime'].units = 'minutes since start of experiment'\n",
    "                ncg.variables['obstime'].long_name = 'time of observations'\n",
    "\n",
    "                for v in ('dt', 'm', 'v_min', 'delta_v_inv', 'obs', 'i_test', 'E', 'obs_count'):\n",
    "                    if isinstance(data[dataname][v], int):\n",
    "                        ncg.createVariable(v, int, zlib=True)\n",
    "                        ncg.variables[v][:] = data[dataname][v]\n",
    "                    elif isinstance(data[dataname][v], float):\n",
    "                        ncg.createVariable(v, float, zlib=True)\n",
    "                        ncg.variables[v][:] = data[dataname][v]\n",
    "                    else:\n",
    "                        dims = tuple(dimensions_inv[d] for d in data[dataname][v].shape)\n",
    "                        ncg.createVariable(v, data[dataname][v].dtype, dims, zlib=True)\n",
    "                        ncg.variables[v][:] = data[dataname][v]\n",
    "                \n",
    "                for imodel,model in enumerate(mcmcs):\n",
    "                    ncm = ncg.createGroup(model)\n",
    "                    \n",
    "                    dimensions['sample'] = mcmcs[model][dataname]['mod_obspos'].shape[0]\n",
    "                    dimensions_inv[dimensions['sample']] = 'sample'\n",
    "                    ncm.createDimension('sample', dimensions['sample'])\n",
    "                    if 'tau[1]' in mcmcs[model][dataname].flatnames:\n",
    "                        nt_1day = 1440//data[dataname]['dt']\n",
    "                        if mcmcs[model][dataname]['tau'].shape[1] == nt_1day:\n",
    "                            dimensions['time_oneday'] = mcmcs[model][dataname]['tau'].shape[1]\n",
    "                            dimensions_inv[dimensions['time_oneday']] = 'time_oneday'\n",
    "                            ncm.createDimension('time_oneday', dimensions['time_oneday'])\n",
    "                        else:\n",
    "                            dimensions['tau'] = mcmcs[model][dataname]['tau'].shape[1]\n",
    "                            dimensions_inv[dimensions['tau']] = 'tau'\n",
    "                            ncm.createDimension('tau', dimensions['tau'])\n",
    "                    \n",
    "                    # write model description\n",
    "                    ncm.setncattr('description', desc_model[model])\n",
    "                    ncm.setncattr('code', stan_files[model_stan_key[model]])\n",
    "                    \n",
    "                    varnames = set(v.split('[')[0] for v in mcmcs[model][dataname].flatnames)\n",
    "                    if varnames_save is None:\n",
    "                        varnames_curr = varnames\n",
    "                    else:\n",
    "                        varnames_curr = varnames_save\n",
    "                        \n",
    "                    for v in varnames_curr:\n",
    "                        if v in varnames:\n",
    "                            try:\n",
    "                                dims = tuple(dimensions_inv[d] for d in mcmcs[model][dataname][v].shape)\n",
    "                                ncm.createVariable(v, float, dims, zlib=True)\n",
    "                                ncm.variables[v][:] = mcmcs[model][dataname][v]\n",
    "                            except:\n",
    "                                warnings.warn('Cannot save variable \"{}\" for model \"{}\"; shape {} does not match know dimensions.'.format(v, model, mcmcs[model][dataname][v].shape))\n",
    "                        else:\n",
    "                            warnings.warn('Cannot find variable \"{}\" for model \"{}\".'.format(v, model))\n",
    "            else:\n",
    "                for i,model in enumerate(mcmcs):\n",
    "                    if i == 0:\n",
    "                        ncg.createDimension('model', len(mcmcs))\n",
    "                        ncg.createDimension('sample', mcmcs[model][dataname]['divrate'].shape[0])\n",
    "\n",
    "                        ncg.createVariable('divrate', float, ('model','sample'))\n",
    "                        ncg.createVariable('sumsqdiff', float, ('model','sample'))\n",
    "                        ncg.variables['sumsqdiff'].setncattr('long_name', 'sum of squared column differences')\n",
    "\n",
    "                    ncg.variables['divrate'][i,:] = mcmcs[model][dataname]['divrate']\n",
    "\n",
    "                    obs = data[dataname]['obs']\n",
    "\n",
    "                    tmp = mcmcs[model][dataname]['mod_obspos']\n",
    "                    tmp/= np.sum(tmp, axis=1)[:,None,:]\n",
    "                    tmp -= obs[None,:,:]\n",
    "                    tmp **= 2\n",
    "\n",
    "                    if np.all(data[dataname]['i_test'] == 0):\n",
    "                        ncg.variables['sumsqdiff'][i,:] = np.mean(np.sum(tmp, axis=1), axis=1)\n",
    "                        if i == 0:\n",
    "                            ncg.variables['sumsqdiff'].setncattr('data_used', 'all data')\n",
    "                    else:\n",
    "                        nc.variables['sumsqdiff'][i,:] = np.mean(np.sum(tmp[:,:,data[dataname]['i_test'] == 1], axis=1), axis=1)\n",
    "                        if i == 0:\n",
    "                            ncg.variables['sumsqdiff'].setncattr('data_used', 'testing data')\n",
    "\n",
    "                    for iv,v in enumerate(('gamma_max','rho_max','xi','xir','E_star')):\n",
    "                        if i == 0:\n",
    "                            ncg.createVariable(v, float, ('model','sample'))\n",
    "                        if v in mcmcs[model][dataname].flatnames:\n",
    "                            ncg.variables[v][i,:] = mcmcs[model][dataname][v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
