{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test of all code in `stancode_gallery1` for count data\n",
    " * using code from `/experimental/experimental_zinser_seaflow_20200518_modelfit_clone2_truecounts.ipynb` to compute counts\n",
    " \n",
    "### general information about the different growth/respiration versions\n",
    "\n",
    " * for the functional form of the different size-dependent growth and respiration formulations see [this notebook](sizedep_formulations.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data from files and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "import netCDF4 as nc4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dateutil.parser\n",
    "import sys\n",
    "\n",
    "# load data\n",
    "datafiles = {\n",
    "    'seaflow':'data/SeaFlow_SizeDist_regrid-25-8.nc',\n",
    "    'zinser':'data/Zinser_SizeDist_calibrated-26-6.nc',\n",
    "}\n",
    "\n",
    "itestfiles = {\n",
    "    'seaflow':'data/Zinser_SizeDist_calibrated-26-6-itest.csv', # same as zinser\n",
    "    'zinser':'data/Zinser_SizeDist_calibrated-26-6-itest.csv',         \n",
    "}\n",
    "\n",
    "desc = {\n",
    "    'seaflow':'SeaFlow dataset',\n",
    "    'zinser':'Zinser dataset',    \n",
    "}\n",
    "\n",
    "data_gridded = {}\n",
    "for dataname in datafiles:\n",
    "    data_gridded[dataname] = {}\n",
    "    with nc4.Dataset(datafiles[dataname]) as nc:\n",
    "        for var in nc.variables:\n",
    "            data_gridded[dataname][var] = nc.variables[var][:]\n",
    "    desc[dataname] += ' (m={data[m]}, $\\Delta_v^{{-1}}$={data[delta_v_inv]})'.format(data=data_gridded[dataname])\n",
    "\n",
    "# Now we load in count data\n",
    "for dataname in datafiles:\n",
    "\n",
    "    if 'seaflow' in dataname:\n",
    "        # Extract SeaFlow cell counts\n",
    "        seaflow = pd.read_csv('data/SeaFlow_PSD_hourlyCOUNT_m32.csv')\n",
    "        seaflow_counts = seaflow.values[:, 2:].T.astype(int)\n",
    "\n",
    "        # Redefine parameters to match 32-size class count data. We only keep PAR from the 25-size class data.\n",
    "        data_gridded[dataname]['m'] = seaflow_counts.shape[0]\n",
    "        data_gridded[dataname]['size_bounds'] = seaflow.columns[2:].values.astype(float) # extract size classes from dataframe\n",
    "        data_gridded[dataname]['v_min'] = data_gridded[dataname]['size_bounds'][0] # note these seem to be on a different scale\n",
    "        data_gridded[dataname]['delta_v_inv'] = int(np.round(1.0/np.log2(data_gridded[dataname]['size_bounds'][1]/data_gridded[dataname]['size_bounds'][0])))\n",
    "        data_gridded[dataname]['w_obs'] = (seaflow_counts/np.sum(seaflow_counts, axis=0)[None, :]).astype(float)\n",
    "        data_gridded[dataname]['counts'] = seaflow_counts\n",
    "        data_gridded[dataname]['obs_time'] = np.empty(shape=seaflow_counts.shape[1])\n",
    "\n",
    "        # Extract time stamps for each observation from SeaFlow data\n",
    "        ii = 0\n",
    "        for timestamp in np.asarray(seaflow['time'], dtype=str):\n",
    "            datetime = dateutil.parser.isoparse(timestamp)\n",
    "            if ii == 0:\n",
    "                initial = datetime\n",
    "            data_gridded['seaflow']['obs_time'][ii] = (datetime - initial).total_seconds()/60\n",
    "            ii += 1\n",
    "\n",
    "    elif 'zinser' in dataname:\n",
    "\n",
    "        # Extract Zinser cell counts\n",
    "        zinser = pd.read_csv('data/Zinser_Figure2A.csv')\n",
    "        #zinser_counts = zinser.values[:,1].astype(int) # cells A column\n",
    "        #zinser_counts = zinser.values[:,2].astype(int) # cells B column\n",
    "        zinser_counts = np.mean(zinser.values, axis=1).astype(int) # mean of both columns\n",
    "        \n",
    "        # Add counts to Zinser data\n",
    "        data_gridded[dataname]['counts'] = (data_gridded[dataname]['w_obs'] * zinser_counts).astype(int)\n",
    "        data_gridded[dataname]['obs_time'] = data_gridded[dataname]['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "def add_colorbar(ax, **cbarargs):\n",
    "    axins_cbar = inset_axes(ax, width='3%', height='90%', loc=5, bbox_to_anchor=(0.05,0.0,1,1), bbox_transform=ax.transAxes)\n",
    "    mpl.colorbar.ColorbarBase(axins_cbar, orientation='vertical', **cbarargs)\n",
    "\n",
    "for i,dataname in enumerate(data_gridded):\n",
    "    nrows = 3\n",
    "    sharex = np.array_equal(data_gridded[dataname]['time'], data_gridded[dataname]['obs_time'])\n",
    "    \n",
    "    v_min = data_gridded[dataname]['v_min']\n",
    "    delta_v = 1.0/data_gridded[dataname]['delta_v_inv']\n",
    "    v = v_min * 2**(np.arange(data_gridded[dataname]['m'])*delta_v) \n",
    "    \n",
    "    fig,axs = plt.subplots(nrows=nrows, sharex=sharex, figsize=(12,4*nrows))\n",
    "    \n",
    "    ax = axs[0]\n",
    "    ax.set_title('raw '+desc[dataname], size=20)\n",
    "    ax.plot(data_gridded[dataname]['time'], data_gridded[dataname]['PAR'], color='gold')\n",
    "    ax.set(ylabel='PAR')\n",
    "\n",
    "    ax = axs[1]\n",
    "    pc = ax.pcolormesh(data_gridded[dataname]['obs_time'],v,data_gridded[dataname]['w_obs'])\n",
    "    ax.set(ylabel='size ($\\mu$m$^3$)')\n",
    "    #ax.text(0.01, 0.95, desc[dataname], color='white', size=16, transform=ax.transAxes, ha='left', va='top')\n",
    "    add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='size class proportion')\n",
    "\n",
    "    ax = axs[2]\n",
    "    pc = ax.pcolormesh(data_gridded[dataname]['obs_time'],v,data_gridded[dataname]['counts'])\n",
    "    ax.set(ylabel='size ($\\mu$m$^3$)')\n",
    "    #ax.text(0.01, 0.95, desc[dataname], color='white', size=16, transform=ax.transAxes, ha='left', va='top')\n",
    "    add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='counts')\n",
    "axs[-1].set_xlabel=('time (minutes)')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process data and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for Stan model\n",
    "\n",
    "if 'data' not in globals():\n",
    "    data = {}\n",
    "if 'mcmcs' not in globals():\n",
    "    mcmcs = {}\n",
    "if 'models' not in globals():\n",
    "    models = {}\n",
    "\n",
    "for dataname in data_gridded:\n",
    "    dt = 20 # in units of minutes\n",
    "    \n",
    "    data[dataname] = {'dt':dt}\n",
    "    for v in ('m','v_min','delta_v_inv'):\n",
    "        data[dataname][v] = data_gridded[dataname][v]\n",
    "\n",
    "    if 'seaflow' in dataname:\n",
    "        limit_days = 1\n",
    "        data[dataname]['obs'] = data_gridded[dataname]['w_obs']\n",
    "        data[dataname]['t_obs'] = data_gridded[dataname]['obs_time']\n",
    "                \n",
    "        # median filter PAR\n",
    "        # see: medianfilter_par.ipynb\n",
    "        n = len(data_gridded[dataname]['PAR'])\n",
    "        wsh = 30 # half of median filter window size; window size is 2*wsh+1\n",
    "        par = np.array([np.median(data_gridded[dataname]['PAR'][max(0,i-wsh):min(n,i+wsh+1)]) for i in range(n)])\n",
    "    else:\n",
    "        limit_days = 2\n",
    "        \n",
    "        data[dataname]['obs'] = data_gridded[dataname]['w_obs']\n",
    "        data[dataname]['t_obs'] = data_gridded[dataname]['obs_time']\n",
    "        par = data_gridded[dataname]['PAR']\n",
    "        \n",
    "    if limit_days > 0:\n",
    "        limit_minutes = limit_days*1440\n",
    "        \n",
    "        ind_obs = data[dataname]['t_obs'] < limit_minutes\n",
    "        data[dataname]['t_obs'] = data[dataname]['t_obs'][ind_obs]\n",
    "        data[dataname]['obs'] = data[dataname]['obs'][:,ind_obs]\n",
    "        \n",
    "        data[dataname]['nt'] = int(limit_minutes//data[dataname]['dt'])\n",
    "\n",
    "    data[dataname]['nt_obs'] = data[dataname]['t_obs'].size\n",
    "    \n",
    "    # load cross-validation testing indices and add them to data\n",
    "    data[dataname]['i_test'] = np.loadtxt(itestfiles[dataname]).astype(int)\n",
    "    # remove last index, so that dimensions agree\n",
    "    data[dataname]['i_test'] = data[dataname]['i_test'][:-1]\n",
    "    \n",
    "    # add light data\n",
    "    t = np.arange(data[dataname]['nt'])*data[dataname]['dt']\n",
    "    data[dataname]['E'] = np.interp(t, xp=data_gridded[dataname]['time'], fp=par)\n",
    "    \n",
    "    # real count data\n",
    "    data[dataname]['obs_count'] = data_gridded[dataname]['counts'][:, ind_obs]\n",
    "    \n",
    "    # consistency check\n",
    "    if len(data[dataname]['i_test']) != data[dataname]['nt_obs']:\n",
    "        raise ValueError('Invalid number of testing indices for \"{}\" (expected {}, got {}).'.format(dataname,data[dataname]['nt_obs'],len(data[dataname]['i_test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,dataname in enumerate(data):\n",
    "    nrows = 3\n",
    "    \n",
    "    v_min = data[dataname]['v_min']\n",
    "    delta_v = 1.0/data[dataname]['delta_v_inv']\n",
    "    v = v_min * 2**(np.arange(data[dataname]['m'])*delta_v) \n",
    "    t = np.arange(data[dataname]['nt'])*data[dataname]['dt']\n",
    "    \n",
    "    \n",
    "    fig,axs = plt.subplots(nrows=nrows, sharex=True, figsize=(12,4*nrows))\n",
    "    \n",
    "    ax = axs[0]\n",
    "    ax.set_title('processed '+desc[dataname], size=20)\n",
    "    ax.plot(t, data[dataname]['E'], color='gold')\n",
    "    ax.set(ylabel='E')\n",
    "\n",
    "    ax = axs[1]\n",
    "    pc = ax.pcolormesh(data[dataname]['t_obs'],v,data[dataname]['obs'])\n",
    "    ax.set(ylabel='size ($\\mu$m$^3$)')\n",
    "    #ax.text(0.01, 0.95, desc[dataname], color='white', size=16, transform=ax.transAxes, ha='left', va='top')\n",
    "    add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='size class proportion')\n",
    "    ax.set_xlim(left=0.0)\n",
    "\n",
    "    ax = axs[2]\n",
    "    pc = ax.pcolormesh(data[dataname]['t_obs'],v,data[dataname]['obs_count'])\n",
    "    ax.set(ylabel='size ($\\mu$m$^3$)')\n",
    "    #ax.text(0.01, 0.95, desc[dataname], color='white', size=16, transform=ax.transAxes, ha='left', va='top')\n",
    "    add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='counts')\n",
    "    ax.set_xlim(left=0.0)\n",
    "axs[-1].set_xlabel('time (minutes)')\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan\n",
    "import re\n",
    "\n",
    "desc_model = {\n",
    "    's1':'m1',\n",
    "    's2':'m2',\n",
    "    's3':'m3',\n",
    "    's4':'m4',\n",
    "    's5':'m5',\n",
    "    's6':'m6',\n",
    "    's7':'m7',\n",
    "    's8':'m8',\n",
    "    's9':'m9',\n",
    "    's10':'m10',\n",
    "    's11':'m5 + size-dep growth (m5-m6 hybrid)',\n",
    "    's12':'m5 + size-dep growth (m5-m7 hybrid)',\n",
    "}\n",
    "# preparing for some regular expression magic\n",
    "model_code_replacements = {\n",
    "    's1':(),\n",
    "    's2':(),\n",
    "    's3':(),\n",
    "    's4':(),\n",
    "    's5':(),\n",
    "    's6':(),\n",
    "    's7':(),\n",
    "    's8':(),\n",
    "    's9':(),\n",
    "    's10':(),\n",
    "    's11':(),\n",
    "    's12':(),\n",
    "}\n",
    "model_stan_key = {\n",
    "    's1':'c1',\n",
    "    's2':'c2',\n",
    "    's3':'c3',\n",
    "    's4':'c4',\n",
    "    's5':'c5',\n",
    "    's6':'c6',\n",
    "    's7':'c7',\n",
    "    's8':'c8',\n",
    "    's9':'c9',\n",
    "    's10':'c10',\n",
    "    's11':'c56',\n",
    "    's12':'c57',\n",
    "}\n",
    "stan_files = {\n",
    "    'c1':'stancode_gallery1/matrixmodel_multinom_estinilnorm_freedelta_normparam_trackgrowth_xval.stan',\n",
    "    'c2':'stancode_gallery1/matrixmodel_multinom_estinilnorm_monodelta_normparam_trackgrowth_xval.stan',\n",
    "    'c3':'stancode_gallery1/matrixmodel_multinom_estinilnorm_monodelta_gammaiv6_normparam_trackgrowth_xval.stan',\n",
    "    'c4':'stancode_gallery1/matrixmodel_multinom_estinilnorm_monodelta_respv1_normparam_trackgrowth_xval.stan',\n",
    "    'c5':'stancode_gallery1/matrixmodel_multinom_estinilnorm_monodelta_respv2_normparam_trackgrowth_xval.stan',\n",
    "    'c6':'stancode_gallery1/matrixmodel_multinom_estinilnorm_monodelta_respiv6_normparam_trackgrowth_xval.stan',\n",
    "    'c7':'stancode_gallery1/matrixmodel_multinom_estinilnorm_monodelta_respiv7_normparam_trackgrowth_xval.stan',\n",
    "    'c8':'stancode_gallery1/matrixmodel_multinom_estinilnorm_monodelta-lightsig_respiv6_normparam_trackgrowth_xval.stan',\n",
    "    'c9':'stancode_gallery1/matrixmodel_multinom_estinilnorm_monodelta-lightsig_respiv7_normparam_trackgrowth_xval.stan',\n",
    "    'c10':'stancode_gallery1/matrixmodel_multinom_estinilnorm_monodelta-lightsig_respv2_normparam_trackgrowth_xval.stan',\n",
    "    'c56':'stancode/matrixmodel_multinom_estinilnorm_monodelta_resp_gammaiv6_normparam_trackgrowth_xval.stan',\n",
    "    'c57':'stancode/matrixmodel_multinom_estinilnorm_monodelta_resp_gammaiv7_normparam_trackgrowth_xval.stan',\n",
    "}\n",
    "\n",
    "refit_required = {}\n",
    "stan_base_code = {}\n",
    "for key,stan_file in stan_files.items():\n",
    "    with open(stan_file) as f:\n",
    "        stan_base_code[key] = f.read()\n",
    "\n",
    "stan_code = {}\n",
    "for name in desc_model:\n",
    "    code_split = stan_base_code[model_stan_key[name]].split('\\n')\n",
    "    code_split_new = []\n",
    "    for line in code_split:\n",
    "        line_new = line\n",
    "        for replacement in model_code_replacements[name]:\n",
    "            m = re.match(replacement[0],line_new)\n",
    "            if m:\n",
    "                line_new = m.groups(0)[0]+replacement[1]\n",
    "                print('{}: patching in \"{}\"'.format(name, line_new))\n",
    "        code_split_new.append(line_new)\n",
    "                \n",
    "    stan_code[name] = '\\n'.join(code_split_new)\n",
    "\n",
    "for name in desc_model:\n",
    "    refit_required[name] = True\n",
    "    if name in models and models[name].model_code == stan_code[name]:\n",
    "        print('{}: unchanged code, not recompiling'.format(name))\n",
    "        refit_required[name] = False\n",
    "    else:\n",
    "        if name in models:\n",
    "            print('{}: code change detected, recompiling'.format(name))\n",
    "        else:\n",
    "            print('{}: compiling'.format(name))\n",
    "        models[name] = pystan.StanModel(model_code=stan_code[name], model_name=name, obfuscate_model_name=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "refit_all = False\n",
    "\n",
    "def get_max_rhat(fit):\n",
    "    s = fit.summary()\n",
    "    irhat = s['summary_colnames'].index(\"Rhat\")\n",
    "    return np.nanmax(s['summary'][:,irhat])\n",
    "\n",
    "def get_mean_rhat(fit):\n",
    "    s = fit.summary()\n",
    "    irhat = s['summary_colnames'].index(\"Rhat\")\n",
    "    return np.nanmean(s['summary'][:,irhat])\n",
    "\n",
    "if 'maxrhats' not in globals():\n",
    "    maxrhats = {}\n",
    "if 'meanrhats' not in globals():\n",
    "    meanrhats = {}\n",
    "if 'sampling_time' not in globals():\n",
    "    sampling_time = {}\n",
    "\n",
    "    \n",
    "try_again = False\n",
    "\n",
    "# run a bunch of experiments -- this may take a while\n",
    "for name in models:\n",
    "    if name not in maxrhats:\n",
    "        maxrhats[name] = {}\n",
    "    if name not in meanrhats:\n",
    "        meanrhats[name] = {}\n",
    "    if name not in sampling_time:\n",
    "        sampling_time[name] = {}\n",
    "    for dataname in data:\n",
    "        if dataname not in maxrhats[name]:\n",
    "            maxrhats[name][dataname] = []\n",
    "        if dataname not in meanrhats[name]:\n",
    "            meanrhats[name][dataname] = []\n",
    "        if dataname not in sampling_time[name]:\n",
    "            sampling_time[name][dataname] = []\n",
    "        if name in mcmcs:\n",
    "            if dataname in mcmcs[name] and not refit_all and not refit_required[name]:\n",
    "                print('{} ({})'.format(name, desc_model[name])) \n",
    "                print('\\n'.join(x for x in mcmcs[name][dataname].__str__().split('\\n') if 'mod_obspos' not in x and 'theta' not in x and 'w_ini' not in x and 'incr' not in x))\n",
    "                rhat_max = get_max_rhat(mcmcs[name][dataname])\n",
    "                if try_again and rhat_max >= 1.1:\n",
    "                    print('{}: found Rhat={:.3f}, trying again'.format(name,rhat_max))\n",
    "                else:\n",
    "                    continue\n",
    "        else:\n",
    "            mcmcs[name] = {}\n",
    "        for itry in range(3):\n",
    "            t0 = time.time()\n",
    "            mcmcs[name][dataname] = models[name].sampling(data=data[dataname], iter=2000)\n",
    "            sampling_time[name][dataname].append(time.time() - t0) # in seconds\n",
    "            meanrhats[name][dataname].append(get_mean_rhat(mcmcs[name][dataname]))\n",
    "            # get max Rhat\n",
    "            rhat_max = get_max_rhat(mcmcs[name][dataname])\n",
    "            maxrhats[name][dataname].append(rhat_max)\n",
    "            if rhat_max < 1.1:\n",
    "                break\n",
    "            print('{}: in try {}/3 found Rhat={:.3f}, trying again'.format(name,itry+1,rhat_max))\n",
    "        print('{} ({})'.format(name, desc_model[name])) \n",
    "        print('\\n'.join(x for x in mcmcs[name][dataname].__str__().split('\\n') if 'mod_obspos' not in x and 'theta' not in x and 'w_ini' not in x and 'incr' not in x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['axes.labelsize'] = 20\n",
    "mpl.rcParams['legend.fontsize'] = 16\n",
    "mpl.rcParams['axes.titlesize'] = 26\n",
    "mpl.rcParams['figure.figsize'] = (24,12)\n",
    "mpl.rcParams['xtick.labelsize'] = 16\n",
    "mpl.rcParams['ytick.labelsize'] = 16\n",
    "\n",
    "maxrhats_final = {name:{dataname:get_max_rhat(mcmcs[name][dataname]) for dataname in data} for name in mcmcs}        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ylim_top = 0\n",
    "for dataname in data:\n",
    "    for name in mcmcs:\n",
    "        ylim_top = max(ylim_top, len(maxrhats[name][dataname]))\n",
    "ylim_top += 1\n",
    "\n",
    "fig, axs = plt.subplots(nrows=len(data), figsize=(max(24,len(mcmcs)*4.5),len(data)*9), sharex=True, sharey=True)\n",
    "for ax,dataname in zip(axs.flat,data):\n",
    "    xticks = []\n",
    "    xticklabels = []\n",
    "    for i,name in enumerate(mcmcs):\n",
    "        \n",
    "        height_bad = sum(rh > 1.1 for rh in maxrhats[name][dataname])\n",
    "        height_good = len(maxrhats[name][dataname]) - height_bad\n",
    "        \n",
    "        x = i\n",
    "        ax.bar(x=x, height=height_bad, color='tab:red', label='max $\\\\\\\\hat{R}$ > 1.1')\n",
    "        ax.bar(x=x, height=height_good, bottom=height_bad, color='tab:green', label='max $\\\\hat{R} \\le$ 1.1')\n",
    "        xticks.append(x)\n",
    "        xticklabels.append(desc_model[name].replace(',',',\\n'))\n",
    "    \n",
    "    ax.set(ylabel='number of Stan sampling runs', xticks=xticks, ylim=(0, ylim_top))\n",
    "    ax.set_title('convergence/$\\hat{R}$ statistics for '+desc[dataname], size=20)\n",
    "    ax.set_xticklabels(xticklabels)#, rotation=8)\n",
    "    ax.grid(axis='y')\n",
    "\n",
    "for dataname in data:\n",
    "    fig, ax = plt.subplots(figsize=(16,9))\n",
    "    ax.set_title('{} dataset'.format(dataname))\n",
    "    for name in mcmcs:\n",
    "        ax.scatter(maxrhats[name][dataname], sampling_time[name][dataname], label='{}'.format(desc_model[name]), s=120)\n",
    "\n",
    "    ax.set(xlabel='max $\\\\hat{R}$', ylabel='runtime')\n",
    "    ax.set_xscale('log')\n",
    "    ax.grid(True)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = np.zeros(3)\n",
    "for dataname in data:\n",
    "    obs = data[dataname]['obs']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(max(24,len(mcmcs)*4.5),9))\n",
    "    xticks = []\n",
    "    xticklabels = []\n",
    "    for i,name in enumerate(mcmcs):\n",
    "        mod_mean = np.mean(mcmcs[name][dataname]['mod_obspos'], axis=0)\n",
    "        mod_mean /= np.sum(mod_mean, axis=0)\n",
    "        \n",
    "        e = np.sum((mod_mean-obs)**2,axis=0)\n",
    "        #print(desc_model[name],e)\n",
    "        \n",
    "        height[0] = np.mean(e)\n",
    "        height[1] = np.mean(e[data[dataname]['i_test'] == 0])\n",
    "        height[2] = np.mean(e[data[dataname]['i_test'] == 1])\n",
    "        \n",
    "        x = 4*i+np.arange(3)\n",
    "        ax.bar(x=x, height=height)\n",
    "        for xx,text in zip(x,['overall mean','training mean','test mean']):\n",
    "            ax.text(xx, 0, '  '+text, rotation=90, ha='center', va='bottom', size=20)\n",
    "        if maxrhats_final[name][dataname] > 1.1:\n",
    "            ax.text(x[1], 0, '  no convergence ($\\\\hat{R}>1.1$)', rotation=45, ha='center', va='bottom', size=30, color='darkred')\n",
    "        xticks.append(x[1])\n",
    "        xticklabels.append(desc_model[name].replace(',',',\\n').replace('(','\\n('))\n",
    "    \n",
    "    if ax.get_ylim()[1] > 0.005:\n",
    "        ax.set_ylim(top=0.005)\n",
    "    ax.set(ylabel='sum of squared column differences', xticks=xticks)\n",
    "    ax.set_title('model misfit for '+desc[dataname], size=20)\n",
    "    ax.set_xticklabels(xticklabels)#, rotation=8)\n",
    "    ax.grid(axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param_desc = {'divrate':'daily division rate','E_star':'E*'}\n",
    "# add known values here\n",
    "reference_values = {'zinser':{'divrate':0.63}}\n",
    "\n",
    "for param in ('divrate','E_star'):\n",
    "    for dataname in data:\n",
    "        num_mcmcs = len(mcmcs)\n",
    "        fig, ax = plt.subplots(figsize=(24,3*num_mcmcs))\n",
    "        ax.set_title('{} for {}'.format(param_desc[param], desc[dataname]))\n",
    "        ax.violinplot([mcmcs[name][dataname][param] for name in mcmcs], showmedians=True, vert=False)\n",
    "        ax.invert_yaxis()\n",
    "        ax.grid(axis='x')\n",
    "        ax.set(yticks=np.arange(1,num_mcmcs+1), yticklabels=[desc_model[name].replace(',',',\\n') for name in mcmcs])\n",
    "        if dataname in reference_values and param in reference_values[dataname]:\n",
    "            ax.axvline(reference_values[dataname][param], color='tab:green', lw=3)\n",
    "        for i,name in enumerate(mcmcs):\n",
    "            if maxrhats_final[name][dataname] > 1.1:\n",
    "                ax.text(0.5, i+1, 'no convergence ($\\\\hat{R}>1.1$)', color='darkred', size=26, transform=ax.get_yaxis_transform(), ha='center', va='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for dataname in data:\n",
    "    for name,mcmc in mcmcs.items():\n",
    "        j = data_gridded[dataname]['delta_v_inv'] + 1\n",
    "        m = data_gridded[dataname]['m']\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(20,6))\n",
    "        ax.set_title(desc_model[name] + '\\n' + desc[dataname])\n",
    "        ax.boxplot(mcmc[dataname]['delta_max'])\n",
    "        xlabels = [str(x) for x in range(j,m+1)]\n",
    "        xlabels[0] = 'j='+xlabels[0]\n",
    "        xlabels[-1] = 'm='+xlabels[-1]\n",
    "        ax.set_xticklabels(xlabels)\n",
    "        ax.grid(axis='y')\n",
    "        ax.set_ylabel('$\\\\delta_{max}$')\n",
    "        \n",
    "        if maxrhats_final[name][dataname] > 1.1:\n",
    "            ax.text(0.5, 0.5, 'no convergence ($\\\\hat{R}>1.1$)', color='darkred', size=26, transform=ax.transAxes, ha='center', va='center')\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_fig2a = pd.read_csv('data/Zinser_Figure2A.csv')\n",
    "\n",
    "t_zinser = data_fig2a['exper time'] * 60\n",
    "a_norm = data_fig2a['cells A'].copy()\n",
    "a_norm /= a_norm[0]\n",
    "b_norm = data_fig2a['cells B'].copy()\n",
    "b_norm /= b_norm[0]\n",
    "\n",
    "colors = {'model':'darkred', 'obs':'0.1'}\n",
    "\n",
    "norm = mpl.colors.Normalize(0.0,0.15)\n",
    "norm_diff = mpl.colors.Normalize(-0.1,0.1)\n",
    "\n",
    "for dataname in data:\n",
    "    for name,mcmc in mcmcs.items():\n",
    "        t = data[dataname]['dt']*np.arange(data[dataname]['nt'])\n",
    "        v_ext = data[dataname]['v_min'] * 2**(np.arange(data[dataname]['m']+1)*delta_v) \n",
    "        v = v_ext[:-1]\n",
    "        v_width = v_ext[1:] - v_ext[:-1]\n",
    "        \n",
    "        res = {'model':np.mean(mcmc[dataname]['mod_obspos'], axis=0), 'obs':data[dataname]['obs']}\n",
    "        res_sum1 = res['model']/np.sum(res['model'], axis=0)[None,:]\n",
    "        diff = res_sum1-res['obs']\n",
    "\n",
    "        if maxrhats_final[name][dataname] > 1.1:\n",
    "            fig, ax = plt.subplots(figsize=(24,4))\n",
    "            ax.set_title(desc_model[name] + '\\n' + desc[dataname])\n",
    "            ax.set(xticks=[], yticks=[])\n",
    "            ax.text(0.5, 0.5, 'no convergence ($\\\\hat{R}>1.1$)', color='darkred', size=26, transform=ax.transAxes, ha='center', va='center')\n",
    "            continue\n",
    "        \n",
    "        fig,axs = plt.subplots(6,1,sharex=True,figsize=(24,40))\n",
    "        axs[0].set_title(desc_model[name] + '\\n' + desc[dataname])\n",
    "\n",
    "        ax = axs[0]\n",
    "        ax.plot(t, data[dataname]['E'], color='gold')\n",
    "        ax.set(xlim=(data[dataname]['t_obs'][0],t[-1]), ylabel='PAR')\n",
    "\n",
    "        ax = axs[1]\n",
    "        pc = ax.pcolormesh(data[dataname]['t_obs'],v,res['obs'],norm=norm)\n",
    "        ax.set(ylabel='size ($\\mu$m$^3$)', title='size distribution data')\n",
    "        add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='size class proportion')\n",
    "\n",
    "        ax = axs[2]\n",
    "        ax.set(ylabel='size ($\\mu$m$^3$)', title='size distribution model posterior')\n",
    "        pc = ax.pcolormesh(data[dataname]['t_obs'],v,res_sum1,norm=norm)\n",
    "\n",
    "        ax = axs[3]\n",
    "        pc = ax.pcolormesh(data[dataname]['t_obs'],v,diff,norm=norm_diff, cmap='PiYG')\n",
    "        ax.set(ylabel='size ($\\mu$m$^3$)', title='model - data misfit')\n",
    "        add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='difference in size class proportion')\n",
    "        \n",
    "        qq = np.percentile(np.sum(mcmc[dataname]['mod_obspos'], axis=1), axis=0, q=(5,25,50,75,95))\n",
    "    \n",
    "        ax = axs[4]\n",
    "        ax.fill_between(data[dataname]['t_obs'], qq[0,:], qq[-1,:], alpha=0.25, color='gold')\n",
    "        ax.fill_between(data[dataname]['t_obs'], qq[1,:], qq[-2,:], alpha=0.5, color='gold')\n",
    "        ax.plot(data[dataname]['t_obs'], qq[2,:], color='gold')\n",
    "        if 'zinser' in dataname:\n",
    "            ax.plot(t_zinser, a_norm, color='black', marker='s', label='Zinser normalized \"cells A\"')\n",
    "            ax.plot(t_zinser, b_norm, color='red', marker='^', label='Zinser normalized \"cells B\"')\n",
    "            for iday in range(2):\n",
    "                ax.axvspan(iday*24*60+12*60, iday*24*60+22*60, color='0.7', zorder=0)\n",
    "            ax.legend()\n",
    "        ax.grid(True)\n",
    "        ax.set(ylabel='sum across size classes', title='relative increase in population size (division)')\n",
    "\n",
    "        ax = axs[5]\n",
    "        prop = np.mean(np.abs(diff),axis=0)\n",
    "        ax.plot(data[dataname]['t_obs'], prop, label='mean(abs(diff)), avg: {:.6f}'.format(np.mean(prop)))\n",
    "        prop = np.sum(diff**2,axis=0)\n",
    "        ax.plot(data[dataname]['t_obs'], prop, label='sum(diff$^2$), avg: {:.6f}'.format(np.mean(prop)))\n",
    "        ax.set(xlabel='time (minutes)', ylabel='model-observation misfit')\n",
    "        ax.grid(True)\n",
    "        ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a few new preliminary plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data for plotting\n",
    "\n",
    "import netCDF4 as nc4\n",
    "\n",
    "for dataname in data:\n",
    "\n",
    "    ncname = 'data_experimental_zinser_seaflow_20200603_gallery1_test2_{}.nc'.format(dataname)\n",
    "\n",
    "    with nc4.Dataset(ncname, 'w') as nc:\n",
    "        for i,name in enumerate(mcmcs):\n",
    "            if i == 0:\n",
    "                nc.createDimension('model', len(mcmcs))\n",
    "                nc.createDimension('sample', mcmcs[name][dataname]['divrate'].shape[0])\n",
    "            \n",
    "                nc.createVariable('divrate', float, ('model','sample'))\n",
    "                nc.createVariable('sumsqdiff', float, ('model','sample'))\n",
    "                nc.variables['sumsqdiff'].setncattr('long_name', 'sum of squared column differences')\n",
    "                \n",
    "            nc.variables['divrate'][i,:] = mcmcs[name][dataname]['divrate']\n",
    "            \n",
    "            obs = data[dataname]['obs']\n",
    "\n",
    "            tmp = mcmcs[name][dataname]['mod_obspos']\n",
    "            tmp/= np.sum(tmp, axis=1)[:,None,:]\n",
    "            tmp -= obs[None,:,:]\n",
    "            tmp **= 2\n",
    "            \n",
    "            nc.variables['sumsqdiff'][i,:] = np.mean(np.sum(tmp[:,:,data[dataname]['i_test'] == 1], axis=1), axis=1)\n",
    "            \n",
    "            for iv,v in enumerate(('gamma_max','rho_max','xi','xir','E_star')):\n",
    "                if i == 0:\n",
    "                    nc.createVariable(v, float, ('model','sample'))\n",
    "                if v in mcmcs[name][dataname].flatnames:\n",
    "                    nc.variables[v][i,:] = mcmcs[name][dataname][v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param_desc = {'divrate':'daily division rate','E_star':'E*'}\n",
    "# add known values here\n",
    "reference_values = {'zinser':{'divrate':0.63}}\n",
    "\n",
    "model_shortname = {name:name.replace('s','m') for name in mcmcs}\n",
    "\n",
    "height = np.zeros(3)\n",
    "for dataname in data:\n",
    "    if 'zinser' in dataname:\n",
    "        fig, ax = plt.subplots(figsize=(16,16))\n",
    "\n",
    "        for name in mcmcs:\n",
    "            # misfit to data\n",
    "\n",
    "            obs = data[dataname]['obs']\n",
    "\n",
    "            tmp = mcmcs[name][dataname]['mod_obspos']\n",
    "            tmp/= np.sum(tmp, axis=1)[:,None,:]\n",
    "            tmp -= obs[None,:,:]\n",
    "            tmp **= 2\n",
    "\n",
    "            e0 = np.mean(np.sum(tmp[:,:,data[dataname]['i_test'] == 1], axis=1), axis=1)\n",
    "            \n",
    "            # misfit to division rate\n",
    "\n",
    "            e1 = np.sqrt(np.mean((mcmcs[name][dataname]['divrate'] - reference_values[dataname]['divrate'])**2))\n",
    "        \n",
    "            ax.scatter(np.mean(e0), np.mean(e1), label=model_shortname[name]+': '+desc_model[name], s=120)\n",
    "        \n",
    "        ax.legend()\n",
    "        ax.set_xlim(left=0.0)\n",
    "        ax.set_ylim(bottom=0.0)\n",
    "        '''\n",
    "        xticks = []\n",
    "        xticklabels = []\n",
    "        for i,name in enumerate(mcmcs):\n",
    "            \n",
    "\n",
    "        if ax.get_ylim()[1] > 0.005:\n",
    "            ax.set_ylim(top=0.005)\n",
    "        ax.set(ylabel='sum of squared column differences', xticks=xticks)\n",
    "        ax.set_title('model misfit for '+desc[dataname], size=20)\n",
    "        ax.set_xticklabels(xticklabels)#, rotation=8)\n",
    "        ax.grid(axis='y')\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotinfo contains information about the prior distribution and the reference value of \n",
    "# the parameters and initial conditions used for plotting. If these are changed in the \n",
    "# code above, change them here as well. \n",
    "plotinfo = {\n",
    "    'gamma_max':{'priordist':'uniform', 'priorparams':(0.0,10.0), 'refvalue':None},\n",
    "    'rho_max':{'priordist':'uniform', 'priorparams':(0.0,3.0), 'refvalue':None},\n",
    "    'xi':{'priordist':'normal', 'priorparams':(0.0,0.1), 'refvalue':None},\n",
    "    'xir':{'priordist':'normal', 'priorparams':(0.0,0.1), 'refvalue':None},\n",
    "    'E_star':{'priordist':'normal', 'priorparams':(1000.0,1000.0), 'refvalue':None},\n",
    "}\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "ncols = 2\n",
    "nrows = int(np.ceil(len(plotinfo)/ncols))\n",
    "for dataname in data:\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(24, 5*nrows), gridspec_kw={'hspace':0.3})\n",
    "    fig.suptitle(desc[dataname], size=30)\n",
    "    for ax in axs.flat:\n",
    "        ax.set_visible(False)\n",
    "    for ax,paramname in zip(axs.flat, plotinfo):\n",
    "        ax.set_visible(True)\n",
    "        plotted_prior = False\n",
    "        for imodel,name in enumerate(mcmcs):\n",
    "            if paramname in mcmcs[name][dataname].flatnames:\n",
    "                ax.hist(mcmcs[name][dataname][paramname], bins=20, density=True, color='C{}'.format(imodel), label=model_shortname[name], alpha=0.6)\n",
    "                xlim = ax.get_xlim()\n",
    "                if not plotted_prior and 'priordist' in plotinfo[paramname]:\n",
    "                    plotted_prior = True\n",
    "                    if plotinfo[paramname]['priordist'] == 'normal':\n",
    "                        p = plotinfo[paramname]['priorparams']\n",
    "                        x_min = min(p[0]-2*p[1], xlim[0])\n",
    "                        x_max = max(p[0]+2*p[1], xlim[1])\n",
    "                        x = np.linspace(x_min, x_max, 100)\n",
    "                        ax.plot(x, stats.norm.pdf(x, loc=p[0], scale=p[1]), label='prior')\n",
    "                    elif plotinfo[paramname]['priordist'] == 'uniform':\n",
    "                        p = plotinfo[paramname]['priorparams']\n",
    "                        y = 1.0/(p[1]-p[0])\n",
    "                        ax.plot([p[0],p[0],p[1],p[1]], [0,y,y,0], label='prior')\n",
    "            #ax.axvline(plotinfo[name]['refvalue'], color='darkred', label='reference value')\n",
    "            ax.set(title=paramname)\n",
    "    ax.legend()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
