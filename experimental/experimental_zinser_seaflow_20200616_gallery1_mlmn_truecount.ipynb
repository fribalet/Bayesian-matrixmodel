{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test of some code in `stancode_gallery1` for count data\n",
    " * using code from `/experimental/experimental_zinser_seaflow_20200518_modelfit_clone2_truecounts.ipynb` to compute counts\n",
    " \n",
    "### general information about the different growth/respiration versions\n",
    "\n",
    " * for the functional form of the different size-dependent growth and respiration formulations see [this notebook](sizedep_formulations.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data from files and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "import netCDF4 as nc4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dateutil.parser\n",
    "\n",
    "# load data\n",
    "datafiles = {\n",
    "    'seaflow':'data/SeaFlow_SizeDist_regrid-25-8.nc',\n",
    "    'zinser':'data/Zinser_SizeDist_calibrated-26-6.nc',\n",
    "}\n",
    "\n",
    "itestfiles = {\n",
    "    'seaflow':'data/Zinser_SizeDist_calibrated-26-6-itest.csv', # same as zinser\n",
    "    'zinser':'data/Zinser_SizeDist_calibrated-26-6-itest.csv',         \n",
    "}\n",
    "\n",
    "desc = {\n",
    "    'seaflow':'SeaFlow dataset',\n",
    "    'zinser':'Zinser dataset',    \n",
    "}\n",
    "\n",
    "data_gridded = {}\n",
    "for dataname in datafiles:\n",
    "    data_gridded[dataname] = {}\n",
    "    with nc4.Dataset(datafiles[dataname]) as nc:\n",
    "        for var in nc.variables:\n",
    "            data_gridded[dataname][var] = nc.variables[var][:]\n",
    "    desc[dataname] += ' (m={data[m]}, $\\Delta_v^{{-1}}$={data[delta_v_inv]})'.format(data=data_gridded[dataname])\n",
    "\n",
    "# Now we load in count data\n",
    "seaflow = pd.read_csv('data/SeaFlow_PSD_hourlyCOUNT_m32.csv')\n",
    "zinser = pd.read_csv('data/Zinser_Figure2A.csv')\n",
    "\n",
    "# Extract cell counts from files\n",
    "seaflow_counts = seaflow.values[:, 2:].T.astype(int)\n",
    "zinser_counts = zinser.values[:, 1].astype(int) # cells A column\n",
    "# zinser_counts = zinser.values[:, 2].astype(int) # cells B column\n",
    "# zinser_counts = zinser.values[:, 1].astype(int) + zinser.values[:, 2].astype(int) # sum of both columns\n",
    "\n",
    "# Replace SeaFlow values based on the 25-size class data with 32-size class data\n",
    "data_gridded['seaflow']['m'] = seaflow_counts.shape[0]\n",
    "data_gridded['seaflow']['size_bounds'] = seaflow.columns[2:].values.astype(float)/1000 # extract size classes from dataframe\n",
    "data_gridded['seaflow']['v_min'] = data_gridded['seaflow']['size_bounds'][0] # note these seem to be on a different scale\n",
    "data_gridded['seaflow']['delta_v_inv'] = int(np.round(1.0/np.log2(data_gridded['seaflow']['size_bounds'][1]/data_gridded['seaflow']['size_bounds'][0])))\n",
    "data_gridded['seaflow']['w_obs'] = (seaflow_counts/np.sum(seaflow_counts, axis=0)[None, :]).astype(float)\n",
    "data_gridded['seaflow']['counts'] = seaflow_counts\n",
    "data_gridded['seaflow']['obs_time'] = np.empty(shape=seaflow_counts.shape[1])\n",
    "ii = 0\n",
    "for timestamp in np.asarray(seaflow['time'], dtype=str):\n",
    "    datetime = dateutil.parser.isoparse(timestamp)\n",
    "    if ii == 0:\n",
    "        initial = datetime\n",
    "    data_gridded['seaflow']['obs_time'][ii] = (datetime - initial).total_seconds()/60\n",
    "    ii += 1\n",
    "\n",
    "# Add counts to Zinser data\n",
    "data_gridded['zinser']['counts'] = (data_gridded['zinser']['w_obs'] * zinser_counts[None, :]).astype(int)\n",
    "data_gridded['zinser']['obs_time'] = data_gridded['zinser']['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "def add_colorbar(ax, **cbarargs):\n",
    "    axins_cbar = inset_axes(ax, width='3%', height='90%', loc=5, bbox_to_anchor=(0.05,0.0,1,1), bbox_transform=ax.transAxes)\n",
    "    mpl.colorbar.ColorbarBase(axins_cbar, orientation='vertical', **cbarargs)\n",
    "\n",
    "for i,dataname in enumerate(data_gridded):\n",
    "    nrows = 2\n",
    "    sharex_flag = 'none'\n",
    "    if np.all(data_gridded[dataname]['time'] == data_gridded[dataname]['obs_time']):\n",
    "        sharex_flag = True\n",
    "    fig,axs = plt.subplots(nrows=nrows, sharex=sharex_flag, figsize=(12,4*nrows))\n",
    "    axs[0].set_title('raw data', size=20)\n",
    "    \n",
    "    ax = axs[0]\n",
    "    ax.plot(data_gridded[dataname]['time'], data_gridded[dataname]['PAR'], color='gold')\n",
    "    ax.set(ylabel='PAR')\n",
    "\n",
    "    v_min = data_gridded[dataname]['v_min']\n",
    "    delta_v = 1.0/data_gridded[dataname]['delta_v_inv']\n",
    "    v = v_min * 2**(np.arange(data_gridded[dataname]['m'])*delta_v) \n",
    "    \n",
    "    ax = axs[1]\n",
    "    pc = ax.pcolormesh(data_gridded[dataname]['obs_time'],v,data_gridded[dataname]['w_obs'])\n",
    "    ax.set(ylabel='size ($\\mu$m$^3$)')\n",
    "    ax.text(0.01, 0.95, desc[dataname], color='white', size=16, transform=ax.transAxes, ha='left', va='top')\n",
    "    add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='size class proportion')\n",
    "axs[-1].set_xlabel=('time (minutes)')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process data and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for Stan model\n",
    "\n",
    "if 'data' not in globals():\n",
    "    data = {}\n",
    "if 'mcmcs' not in globals():\n",
    "    mcmcs = {}\n",
    "if 'models' not in globals():\n",
    "    models = {}\n",
    "\n",
    "for dataname in data_gridded:\n",
    "    dt = 20 # in units of minutes\n",
    "    \n",
    "    data[dataname] = {'dt':dt}\n",
    "    for v in ('m','v_min','delta_v_inv'):\n",
    "        data[dataname][v] = data_gridded[dataname][v]\n",
    "\n",
    "    if 'seaflow' in dataname:\n",
    "        limit_days = 1\n",
    "        data[dataname]['obs'] = data_gridded[dataname]['w_obs']\n",
    "        data[dataname]['t_obs'] = data_gridded[dataname]['obs_time']\n",
    "        \n",
    "        # new: average SeaFlow data in hourly bins\n",
    "#         binsize = 60 # in minutes\n",
    "#         numbins = int(np.ceil(data_gridded[dataname]['time'][-1]/binsize))\n",
    "        \n",
    "#         data[dataname]['obs'] = np.full((data[dataname]['m'],numbins), fill_value=np.nan)\n",
    "#         data[dataname]['t_obs'] = np.full(numbins, fill_value=np.nan)\n",
    "        \n",
    "#         i = 0\n",
    "#         for ibin in range(numbins):\n",
    "#             binind = np.logical_and(data_gridded[dataname]['time'] >= ibin*binsize,\n",
    "#                                     data_gridded[dataname]['time'] < (ibin+1)*binsize)\n",
    "#             if np.any(binind):\n",
    "#                 # TODO we may want to make this a sum when dealing with counts\n",
    "#                 data[dataname]['obs'][:,i] = np.mean(data_gridded[dataname]['w_obs'][:,binind], axis=1)\n",
    "#                 data[dataname]['t_obs'][i] = (ibin+0.5) * binsize\n",
    "#                 i += 1\n",
    "        \n",
    "#         data[dataname]['obs'] = data[dataname]['obs'][:,:i]\n",
    "#         data[dataname]['t_obs'] = data[dataname]['t_obs'][:i]\n",
    "        \n",
    "        # median filter PAR\n",
    "        # see: medianfilter_par.ipynb\n",
    "        n = len(data_gridded[dataname]['PAR'])\n",
    "        wsh = 30 # half of median filter window size; window size is 2*wsh+1\n",
    "        par = np.array([np.median(data_gridded[dataname]['PAR'][max(0,i-wsh):min(n,i+wsh+1)]) for i in range(n)])\n",
    "    else:\n",
    "        limit_days = 2\n",
    "        \n",
    "        data[dataname]['obs'] = data_gridded[dataname]['w_obs']\n",
    "        data[dataname]['t_obs'] = data_gridded[dataname]['obs_time']\n",
    "        par = data_gridded[dataname]['PAR']\n",
    "        \n",
    "    if limit_days > 0:\n",
    "        limit_minutes = limit_days*1440\n",
    "        \n",
    "        ind_obs = data[dataname]['t_obs'] < limit_minutes\n",
    "        data[dataname]['t_obs'] = data[dataname]['t_obs'][ind_obs]\n",
    "        data[dataname]['obs'] = data[dataname]['obs'][:,ind_obs]\n",
    "        \n",
    "        data[dataname]['nt'] = int(limit_minutes//data[dataname]['dt'])\n",
    "\n",
    "    data[dataname]['nt_obs'] = data[dataname]['t_obs'].size\n",
    "    \n",
    "    # load cross-validation testing indices and add them to data\n",
    "    # data[dataname]['i_test'] = np.loadtxt(itestfiles[dataname]).astype(int)\n",
    "    data[dataname]['i_test'] = np.zeros(shape=25, dtype=int)\n",
    "    # remove last index, so that dimensions agree\n",
    "    data[dataname]['i_test'] = data[dataname]['i_test'][:-1]\n",
    "    \n",
    "    # add light data\n",
    "    t = np.arange(data[dataname]['nt'])*data[dataname]['dt']\n",
    "    data[dataname]['E'] = np.interp(t, xp=data_gridded[dataname]['time'], fp=par)\n",
    "    \n",
    "    # for now, add pseudo-count data\n",
    "#     data[dataname]['obs_count'] = (1000*data[dataname]['obs']).astype(int)\n",
    "    # real count data\n",
    "    data[dataname]['obs_count'] = data_gridded[dataname]['counts'][:, ind_obs]\n",
    "    \n",
    "    # consistency check\n",
    "    if len(data[dataname]['i_test']) != data[dataname]['nt_obs']:\n",
    "        raise ValueError('Invalid number of testing indices for \"{}\" (expected {}, got {}).'.format(dataname,data[dataname]['nt_obs'],len(data[dataname]['i_test'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,dataname in enumerate(data):\n",
    "    nrows = 2\n",
    "    fig,axs = plt.subplots(nrows=nrows, sharex=True, figsize=(12,4*nrows))\n",
    "    axs[0].set_title('processed data', size=20)\n",
    "    \n",
    "    ax = axs[0]\n",
    "    t = np.arange(data[dataname]['nt'])*data[dataname]['dt']\n",
    "    ax.plot(t, data[dataname]['E'], color='gold')\n",
    "    ax.set(ylabel='E')\n",
    "\n",
    "    v_min = data[dataname]['v_min']\n",
    "    delta_v = 1.0/data[dataname]['delta_v_inv']\n",
    "    v = v_min * 2**(np.arange(data[dataname]['m'])*delta_v) \n",
    "    \n",
    "    ax = axs[1]\n",
    "    pc = ax.pcolormesh(data[dataname]['t_obs'],v,data[dataname]['obs'])\n",
    "    ax.set(ylabel='size ($\\mu$m$^3$)')\n",
    "    ax.text(0.01, 0.95, desc[dataname], color='white', size=16, transform=ax.transAxes, ha='left', va='top')\n",
    "    add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='size class proportion')\n",
    "    ax.set_xlim(left=0.0)\n",
    "axs[-1].set_xlabel('time (minutes)')\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan\n",
    "refit_all = False\n",
    "refit_required = {}\n",
    "\n",
    "modelfiles = {\n",
    "#     'monodelta_respv2':'stancode/matrixmodel_estinilnorm_monodelta_respv2_normparam_trackgrowth_xval.stan',\n",
    "#     'monodelta_respv2_mn':'stancode/matrixmodel_multinom_estinilnorm_monodelta_respv2_normparam_trackgrowth_xval.stan',\n",
    "    'monodelta_respv2_mlmn':'stancode_gallery1/mlmn_version/matrixmodel_mlmultinom_estinilnorm2_monodelta2_respv2_normparam_trackgrowth_xval2.stan',\n",
    "    #'monodelta_respv2_mn_lightsig':'stancode/matrixmodel_estinilnorm_monodelta-lightsig_respv2_normparam_trackgrowth_xval.stan',\n",
    "#     'monodelta_gammaiv6_mn':'stancode/matrixmodel_multinom_estinilnorm_monodelta_gammaiv6_normparam_trackgrowth_xval.stan',   \n",
    "    # 'monodelta_respiv6_mn':'stancode/matrixmodel_multinom_estinilnorm_monodelta_respiv6_normparam_trackgrowth_xval.stan',   \n",
    "    # 'monodelta_respiv6_mlmn':'stancode/matrixmodel_mlmultinom_estinilnorm_monodelta_respiv6_normparam_trackgrowth_xval2.stan',   \n",
    "    #'monodelta_respiv6_mn_lightsig':'stancode/matrixmodel_multinom_estinilnorm_monodelta-lightsig_respiv6_normparam_trackgrowth_xval.stan',   \n",
    "#     'monodelta_respiv7_mn':'stancode/matrixmodel_multinom_estinilnorm_monodelta_respiv7_normparam_trackgrowth_xval.stan',   \n",
    "#     'monodelta_respiv7_mlmn':'stancode/matrixmodel_mlmultinom_estinilnorm_monodelta_respiv7_normparam_trackgrowth_xval.stan',   \n",
    "    #'monodelta_respiv7_mn_lightsig':'stancode/matrixmodel_multinom_estinilnorm_monodelta-lightsig_respiv7_normparam_trackgrowth_xval.stan',   \n",
    "}\n",
    "desc_model = {\n",
    "    'monodelta_respv2':'respiration v2 (no size-dep), old fit (for comparison only)',\n",
    "    'monodelta_respv2_mn':'respiration v2 (no size-dep), multinomial',\n",
    "    'monodelta_respv2_mlmn':'respiration v2 (no size-dep), multilevel multinomial',\n",
    "    'monodelta_respv2_mn_lightsig':'OLD: respiration v2 (no size-dep), light-dep div',\n",
    "    'monodelta_gammaiv6_mn':'size-dep growth v6, no respiration, multinomial',\n",
    "    'monodelta_respiv6_mn':'size-dep growth/resp v6, multinomial',\n",
    "    'monodelta_respiv6_mlmn':'size-dep growth/resp v6, multilevel multinomial',\n",
    "    'monodelta_respiv6_mn_lightsig':'size-dep growth/resp v6, multinomial, light-dep div',\n",
    "    'monodelta_respiv7_mn':'size-dep growth/resp v7, multinomial',\n",
    "    'monodelta_respiv7_mlmn':'size-dep growth/resp v7, multilevel multinomial',\n",
    "    'monodelta_respiv7_mn_lightsig':'size-dep growth/resp v7, multinomial, light-dep div',\n",
    "}\n",
    "\n",
    "for name in modelfiles:\n",
    "    with open(modelfiles[name]) as f: \n",
    "        stan_code = f.read()\n",
    "    refit_required[name] = True\n",
    "    if name in models and models[name].model_code == stan_code:\n",
    "        print('{}: unchanged code, not recompiling'.format(name))\n",
    "        refit_required[name] = False\n",
    "    else:\n",
    "        if name in models:\n",
    "            print('{}: code change detected, recompiling'.format(name))\n",
    "        else:\n",
    "            print('{}: compiling'.format(name))\n",
    "        models[name] = pystan.StanModel(file=modelfiles[name], model_name=name, obfuscate_model_name=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_max_rhat(fit):\n",
    "    s = fit.summary()\n",
    "    irhat = s['summary_colnames'].index(\"Rhat\")\n",
    "    return np.nanmax(s['summary'][:,irhat])\n",
    "\n",
    "if 'maxrhats' not in globals():\n",
    "    maxrhats = {}\n",
    "\n",
    "try_again = False\n",
    "\n",
    "# run a bunch of experiments -- this may take a while\n",
    "for name in models:\n",
    "    if name not in maxrhats:\n",
    "        maxrhats[name] = {}\n",
    "    for dataname in data:\n",
    "        if dataname not in maxrhats[name]:\n",
    "            maxrhats[name][dataname] = []\n",
    "        if name in mcmcs:\n",
    "            if dataname in mcmcs[name] and not refit_all and not refit_required[name]:\n",
    "                print('{} ({})'.format(name, desc_model[name])) \n",
    "                print('\\n'.join(x for x in mcmcs[name][dataname].__str__().split('\\n') if 'mod_obspos' not in x and 'theta' not in x and 'w_ini' not in x and 'incr' not in x))\n",
    "                rhat_max = get_max_rhat(mcmcs[name][dataname])\n",
    "                if try_again and rhat_max >= 1.1:\n",
    "                    print('{}: found Rhat={:.3f}, trying again'.format(name,rhat_max))\n",
    "                else:\n",
    "                    continue\n",
    "        else:\n",
    "            mcmcs[name] = {}\n",
    "        for itry in range(3):\n",
    "            mcmcs[name][dataname] = models[name].sampling(data=data[dataname], iter=2000)\n",
    "            # get max Rhat\n",
    "            rhat_max = get_max_rhat(mcmcs[name][dataname])\n",
    "            maxrhats[name][dataname].append(rhat_max)\n",
    "            if rhat_max < 1.1:\n",
    "                break\n",
    "            print('{}: in try {}/3 found Rhat={:.3f}, trying again'.format(name,itry+1,rhat_max))\n",
    "        print('{} ({})'.format(name, desc_model[name])) \n",
    "        print('\\n'.join(x for x in mcmcs[name][dataname].__str__().split('\\n') if 'mod_obspos' not in x and 'theta' not in x and 'w_ini' not in x and 'incr' not in x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['axes.labelsize'] = 20\n",
    "mpl.rcParams['legend.fontsize'] = 16\n",
    "mpl.rcParams['axes.titlesize'] = 26\n",
    "mpl.rcParams['figure.figsize'] = (24,12)\n",
    "mpl.rcParams['xtick.labelsize'] = 16\n",
    "mpl.rcParams['ytick.labelsize'] = 16\n",
    "\n",
    "maxrhats_final = {name:{dataname:get_max_rhat(mcmcs[name][dataname]) for dataname in data} for name in mcmcs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ylim_top = 0\n",
    "for dataname in data:\n",
    "    for name in mcmcs:\n",
    "        ylim_top = max(ylim_top, len(maxrhats[name][dataname]))\n",
    "ylim_top += 1\n",
    "\n",
    "fig, axs = plt.subplots(nrows=len(data), figsize=(max(24,len(mcmcs)*4.5),len(data)*9), sharex=True, sharey=True)\n",
    "for ax,dataname in zip(axs.flat,data):\n",
    "    xticks = []\n",
    "    xticklabels = []\n",
    "    for i,name in enumerate(mcmcs):\n",
    "        \n",
    "        height_bad = sum(rh > 1.1 for rh in maxrhats[name][dataname])\n",
    "        height_good = len(maxrhats[name][dataname]) - height_bad\n",
    "        \n",
    "        x = i\n",
    "        ax.bar(x=x, height=height_bad, color='tab:red', label='max $\\\\\\\\hat{R}$ > 1.1')\n",
    "        ax.bar(x=x, height=height_good, bottom=height_bad, color='tab:green', label='max $\\\\hat{R} \\le$ 1.1')\n",
    "        xticks.append(x)\n",
    "        xticklabels.append(desc_model[name].replace(',',',\\n'))\n",
    "    \n",
    "    ax.set(ylabel='number of Stan sampling runs', xticks=xticks, ylim=(0, ylim_top))\n",
    "    ax.set_title('convergence/$\\hat{R}$ statistics for '+desc[dataname], size=20)\n",
    "    ax.set_xticklabels(xticklabels)#, rotation=8)\n",
    "    ax.grid(axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = np.zeros(3)\n",
    "for dataname in data:\n",
    "    obs = data[dataname]['obs']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(max(24,len(mcmcs)*4.5),9))\n",
    "    xticks = []\n",
    "    xticklabels = []\n",
    "    for i,name in enumerate(mcmcs):\n",
    "        mod_mean = np.mean(mcmcs[name][dataname]['mod_obspos'], axis=0)\n",
    "        mod_mean /= np.sum(mod_mean, axis=0)\n",
    "        \n",
    "        e = np.sum((mod_mean-obs)**2,axis=0)\n",
    "        #print(desc_model[name],e)\n",
    "        \n",
    "        height[0] = np.mean(e)\n",
    "        height[1] = np.mean(e[data[dataname]['i_test'] == 0])\n",
    "        height[2] = np.mean(e[data[dataname]['i_test'] == 1])\n",
    "        \n",
    "        x = 4*i+np.arange(3)\n",
    "        ax.bar(x=x, height=height)\n",
    "        for xx,text in zip(x,['overall mean','training mean','test mean']):\n",
    "            ax.text(xx, 0, '  '+text, rotation=90, ha='center', va='bottom', size=20)\n",
    "        if maxrhats_final[name][dataname] > 1.1:\n",
    "            ax.text(x[1], 0, '  no convergence ($\\\\hat{R}>1.1$)', rotation=45, ha='center', va='bottom', size=30, color='darkred')\n",
    "        xticks.append(x[1])\n",
    "        xticklabels.append(desc_model[name].replace(',',',\\n'))\n",
    "    \n",
    "    if ax.get_ylim()[1] > 0.005:\n",
    "        ax.set_ylim(top=0.005)\n",
    "    ax.set(ylabel='sum of squared column differences', xticks=xticks)\n",
    "    ax.set_title('model misfit for '+desc[dataname], size=20)\n",
    "    ax.set_xticklabels(xticklabels)#, rotation=8)\n",
    "    ax.grid(axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for dataname in data:\n",
    "    num_mcmcs = len(mcmcs)\n",
    "    fig, ax = plt.subplots(figsize=(24,3*num_mcmcs))\n",
    "    ax.set_title('daily division rate for '+desc[dataname])\n",
    "    ax.violinplot([mcmcs[name][dataname]['divrate'] for name in mcmcs], showmedians=True, vert=False)\n",
    "    ax.invert_yaxis()\n",
    "    ax.grid(axis='x')\n",
    "    ax.set(yticks=np.arange(1,num_mcmcs+1), yticklabels=[desc_model[name].replace(',',',\\n') for name in mcmcs])\n",
    "    if 'zinser' in dataname:\n",
    "        ax.axvline(0.63, color='tab:green', lw=3)\n",
    "    for i,name in enumerate(mcmcs):\n",
    "        if maxrhats_final[name][dataname] > 1.1:\n",
    "            ax.text(0.5, i+1, 'no convergence ($\\\\hat{R}>1.1$)', color='darkred', size=26, transform=ax.get_yaxis_transform(), ha='center', va='center')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for dataname in data:\n",
    "    for name,mcmc in mcmcs.items():\n",
    "        j = data_gridded[dataname]['delta_v_inv'] + 1\n",
    "        m = data_gridded[dataname]['m']\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(20,6))\n",
    "        ax.set_title(desc_model[name] + '\\n' + desc[dataname])\n",
    "        ax.boxplot(mcmc[dataname]['delta'])\n",
    "        xlabels = [str(x) for x in range(j,m+1)]\n",
    "        xlabels[0] = 'j='+xlabels[0]\n",
    "        xlabels[-1] = 'm='+xlabels[-1]\n",
    "        ax.set_xticklabels(xlabels)\n",
    "        ax.grid(axis='y')\n",
    "        ax.set_ylabel('$\\\\delta_{max}$')\n",
    "        \n",
    "        if maxrhats_final[name][dataname] > 1.1:\n",
    "            ax.text(0.5, 0.5, 'no convergence ($\\\\hat{R}>1.1$)', color='darkred', size=26, transform=ax.transAxes, ha='center', va='center')\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "data_fig2a = pandas.read_csv('data/Zinser_Figure2A.csv')\n",
    "\n",
    "t_zinser = data_fig2a['exper time'] * 60\n",
    "a_norm = data_fig2a['cells A'].copy()\n",
    "a_norm /= a_norm[0]\n",
    "b_norm = data_fig2a['cells B'].copy()\n",
    "b_norm /= b_norm[0]\n",
    "\n",
    "colors = {'model':'darkred', 'obs':'0.1'}\n",
    "\n",
    "norm = mpl.colors.Normalize(0.0,0.2)\n",
    "norm_diff = mpl.colors.Normalize(-0.1,0.1)\n",
    "\n",
    "for dataname in data:\n",
    "    for name,mcmc in mcmcs.items():\n",
    "        t = data[dataname]['dt']*np.arange(data[dataname]['nt'])\n",
    "        v_ext = data[dataname]['v_min'] * 2**(np.arange(data[dataname]['m']+1)*delta_v) \n",
    "        v = v_ext[:-1]\n",
    "        v_width = v_ext[1:] - v_ext[:-1]\n",
    "        \n",
    "        res = {'model':np.mean(mcmc[dataname]['mod_obspos'], axis=0), 'obs':data[dataname]['obs']}\n",
    "        res_sum1 = res['model']/np.sum(res['model'], axis=0)[None,:]\n",
    "        diff = res_sum1-res['obs']\n",
    "\n",
    "        if maxrhats_final[name][dataname] > 1.1:\n",
    "            fig, ax = plt.subplots(figsize=(24,4))\n",
    "            ax.set_title(desc_model[name] + '\\n' + desc[dataname])\n",
    "            ax.set(xticks=[], yticks=[])\n",
    "            ax.text(0.5, 0.5, 'no convergence ($\\\\hat{R}>1.1$)', color='darkred', size=26, transform=ax.transAxes, ha='center', va='center')\n",
    "            continue\n",
    "        \n",
    "        fig,axs = plt.subplots(6,1,sharex=True,figsize=(24,40))\n",
    "        axs[0].set_title(desc_model[name] + '\\n' + desc[dataname])\n",
    "\n",
    "        ax = axs[0]\n",
    "        ax.plot(t, data[dataname]['E'], color='gold')\n",
    "        ax.set(xlim=(data[dataname]['t_obs'][0],t[-1]), ylabel='PAR')\n",
    "\n",
    "        ax = axs[1]\n",
    "        pc = ax.pcolormesh(data[dataname]['t_obs'],v,res['obs'],norm=norm)\n",
    "        ax.set(ylabel='size ($\\mu$m$^3$)', title='size distribution data')\n",
    "        add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='size class proportion')\n",
    "\n",
    "        ax = axs[2]\n",
    "        ax.set(ylabel='size ($\\mu$m$^3$)', title='size distribution model posterior')\n",
    "        pc = ax.pcolormesh(data[dataname]['t_obs'],v,res_sum1,norm=norm)\n",
    "\n",
    "        ax = axs[3]\n",
    "        pc = ax.pcolormesh(data[dataname]['t_obs'],v,diff,norm=norm_diff, cmap='PiYG')\n",
    "        ax.set(ylabel='size ($\\mu$m$^3$)', title='model - data misfit')\n",
    "        add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='difference in size class proportion')\n",
    "        \n",
    "        qq = np.percentile(np.sum(mcmc[dataname]['mod_obspos'], axis=1), axis=0, q=(5,25,50,75,95))\n",
    "    \n",
    "        ax = axs[4]\n",
    "        ax.fill_between(data[dataname]['t_obs'], qq[0,:], qq[-1,:], alpha=0.25, color='gold')\n",
    "        ax.fill_between(data[dataname]['t_obs'], qq[1,:], qq[-2,:], alpha=0.5, color='gold')\n",
    "        ax.plot(data[dataname]['t_obs'], qq[2,:], color='gold')\n",
    "        if 'zinser' in dataname:\n",
    "            ax.plot(t_zinser, a_norm, color='black', marker='s', label='Zinser normalized \"cells A\"')\n",
    "            ax.plot(t_zinser, b_norm, color='red', marker='^', label='Zinser normalized \"cells B\"')\n",
    "            for iday in range(2):\n",
    "                ax.axvspan(iday*24*60+12*60, iday*24*60+22*60, color='0.7', zorder=0)\n",
    "            ax.legend()\n",
    "        ax.grid(True)\n",
    "        ax.set(ylabel='sum across size classes', title='relative increase in population size (division)')\n",
    "\n",
    "        ax = axs[5]\n",
    "        prop = np.mean(np.abs(diff),axis=0)\n",
    "        ax.plot(data[dataname]['t_obs'], prop, label='mean(abs(diff)), avg: {:.6f}'.format(np.mean(prop)))\n",
    "        prop = np.sum(diff**2,axis=0)\n",
    "        ax.plot(data[dataname]['t_obs'], prop, label='sum(diff$^2$), avg: {:.6f}'.format(np.mean(prop)))\n",
    "        ax.set(xlabel='time (minutes)', ylabel='model-observation misfit')\n",
    "        ax.grid(True)\n",
    "        ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
