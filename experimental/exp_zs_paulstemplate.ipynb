{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# template notebook to be expanded\n",
    " * add description here\n",
    " \n",
    "### general information about the different growth/respiration versions\n",
    "\n",
    " * for the functional form of the different size-dependent growth and respiration formulations see [this notebook](sizedep_formulations.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## global switches and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use test data (not all data is used for fitting/training)\n",
    "use_testdata = False\n",
    "\n",
    "# create plots of the data\n",
    "show_data = True\n",
    "\n",
    "# netCDF output file (set to None to not save output)\n",
    "savename_output = None\n",
    "\n",
    "# save the Stan output instead a few stats (only active if filename is specified above)\n",
    "save_stan_output = True\n",
    "\n",
    "# specify the Stan variable names to save; if set to None, all variables are saved \n",
    "# (only active if save_stan_output is True)\n",
    "varnames_save = None\n",
    "\n",
    "# the number of tries to fit each Stan model to achieve an R-hat < 1.1\n",
    "num_tries = 3\n",
    "\n",
    "# the number of chains to run\n",
    "num_chains = 6\n",
    "\n",
    "# the prior_only option passed to each Stan model\n",
    "prior_only = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data from files and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "import netCDF4 as nc4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# load data\n",
    "datafiles = {\n",
    "    'seaflow':'data/SeaFlow_PSD_hourlyCOUNT_v3_regrid-25-8_day2.nc',\n",
    "    'zinser':'data/Zinser_SizeDist_logtransform-25-7.nc',\n",
    "}\n",
    "\n",
    "itestfiles = {\n",
    "    'seaflow':'data/Zinser_SizeDist_calibrated-26-6-itest.csv', # same as zinser\n",
    "    'zinser':'data/Zinser_SizeDist_calibrated-26-6-itest.csv',         \n",
    "}\n",
    "\n",
    "desc = {\n",
    "    'seaflow':'SeaFlow dataset',\n",
    "    'zinser':'Zinser dataset',    \n",
    "}\n",
    "\n",
    "size_units = 'fg C cell$^{-1}$'\n",
    "\n",
    "data_gridded = {}\n",
    "for dataname in datafiles:\n",
    "    data_gridded[dataname] = {}\n",
    "    with nc4.Dataset(datafiles[dataname]) as nc:\n",
    "        for var in nc.variables:\n",
    "            data_gridded[dataname][var] = nc.variables[var][:]\n",
    "\n",
    "    # create \"counts\" entry\n",
    "    if 'count' in data_gridded[dataname]:\n",
    "        data_gridded[dataname]['counts'] = (data_gridded[dataname]['count'][None,:] * data_gridded[dataname]['w_obs']).astype(int)\n",
    "    elif 'abundance' in data_gridded[dataname]:\n",
    "        logging.warning('{}: Using \"abundance\" data to generate count data for the model.'.format(dataname))\n",
    "        data_gridded[dataname]['counts'] = (data_gridded[dataname]['count'][None,:] * data_gridded[dataname]['w_obs']).astype(int)\n",
    "    else:\n",
    "        raise RuntimeError('Cannot find a \"count\" or \"abundance\" entry in \"{}\".'.format(datafiles[dataname]))\n",
    "        \n",
    "    \n",
    "    # add description\n",
    "    desc[dataname] += ' (m={data[m]}, $\\Delta_v^{{-1}}$={data[delta_v_inv]})'.format(data=data_gridded[dataname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "def add_colorbar(ax, **cbarargs):\n",
    "    axins_cbar = inset_axes(ax, width='3%', height='90%', loc=5, bbox_to_anchor=(0.05,0.0,1,1), bbox_transform=ax.transAxes)\n",
    "    mpl.colorbar.ColorbarBase(axins_cbar, orientation='vertical', **cbarargs)\n",
    "\n",
    "if show_data:\n",
    "    for i,dataname in enumerate(data_gridded):\n",
    "        nrows = 3\n",
    "\n",
    "        v_min = data_gridded[dataname]['v_min']\n",
    "        delta_v = 1.0/data_gridded[dataname]['delta_v_inv']\n",
    "        v = v_min * 2**(np.arange(data_gridded[dataname]['m'])*delta_v) \n",
    "\n",
    "        fig,axs = plt.subplots(nrows=nrows, sharex=True, figsize=(12,4*nrows))\n",
    "\n",
    "        ax = axs[0]\n",
    "        ax.set_title('raw '+desc[dataname], size=20)\n",
    "        ax.plot(data_gridded[dataname]['time'], data_gridded[dataname]['PAR'], color='gold')\n",
    "        ax.set(ylabel='PAR')\n",
    "\n",
    "        ax = axs[1]\n",
    "        pc = ax.pcolormesh(data_gridded[dataname]['time'], v, data_gridded[dataname]['w_obs'], shading='auto')\n",
    "        ax.set(ylabel='size ({})'.format(size_units))\n",
    "        #ax.text(0.01, 0.95, desc[dataname], color='white', size=16, transform=ax.transAxes, ha='left', va='top')\n",
    "        add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='size class proportion')\n",
    "\n",
    "        ax = axs[2]\n",
    "        pc = ax.pcolormesh(data_gridded[dataname]['time'], v, data_gridded[dataname]['counts'], shading='auto')\n",
    "        ax.set(ylabel='size ({})'.format(size_units))\n",
    "        #ax.text(0.01, 0.95, desc[dataname], color='white', size=16, transform=ax.transAxes, ha='left', va='top')\n",
    "        add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='counts')\n",
    "    axs[-1].set_xlabel=('time (minutes)')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process data and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for Stan model\n",
    "\n",
    "seaflow_filter_par = False\n",
    "\n",
    "if 'data' not in globals():\n",
    "    data = {}\n",
    "\n",
    "for dataname in data_gridded:\n",
    "    dt = 20 # in units of minutes\n",
    "    \n",
    "    data[dataname] = {'dt':dt}\n",
    "    for v in ('m','v_min','delta_v_inv'):\n",
    "        data[dataname][v] = data_gridded[dataname][v]\n",
    "\n",
    "    if 'seaflow' in dataname:\n",
    "        limit_days = None\n",
    "        data[dataname]['obs'] = data_gridded[dataname]['w_obs']\n",
    "        data[dataname]['t_obs'] = data_gridded[dataname]['time']\n",
    "        if limit_days is None:\n",
    "            limit_days = int(np.ceil(data[dataname]['t_obs'][-1]/1440))\n",
    "        \n",
    "        if seaflow_filter_par:\n",
    "            # median filter PAR\n",
    "            # see: medianfilter_par.ipynb\n",
    "            n = len(data_gridded[dataname]['PAR'])\n",
    "            wsh = 30 # half of median filter window size; window size is 2*wsh+1\n",
    "            par = np.array([np.median(data_gridded[dataname]['PAR'][max(0,i-wsh):min(n,i+wsh+1)]) for i in range(n)])\n",
    "        else:\n",
    "            par = data_gridded[dataname]['PAR']\n",
    "    else:\n",
    "        limit_days = 2\n",
    "        \n",
    "        data[dataname]['obs'] = data_gridded[dataname]['w_obs']\n",
    "        data[dataname]['t_obs'] = data_gridded[dataname]['time']\n",
    "        par = data_gridded[dataname]['PAR']\n",
    "        \n",
    "    if limit_days > 0:\n",
    "        limit_minutes = limit_days*1440\n",
    "        \n",
    "        ind_obs = data[dataname]['t_obs'] < limit_minutes\n",
    "        \n",
    "        if not np.all(ind_obs):\n",
    "            print('{}: limit_days is set to {}, removing {}/{} observation times'.format(dataname, limit_days, ind_obs.size-np.count_nonzero(ind_obs), ind_obs.size))\n",
    "        \n",
    "        data[dataname]['t_obs'] = data[dataname]['t_obs'][ind_obs]\n",
    "        data[dataname]['obs'] = data[dataname]['obs'][:,ind_obs]\n",
    "        \n",
    "        data[dataname]['nt'] = int(limit_minutes//data[dataname]['dt'])\n",
    "\n",
    "    data[dataname]['nt_obs'] = data[dataname]['t_obs'].size\n",
    "    \n",
    "    if use_testdata:\n",
    "        # load cross-validation testing indices and add them to data\n",
    "        data[dataname]['i_test'] = np.loadtxt(itestfiles[dataname]).astype(int)\n",
    "        # remove last index, so that dimensions agree\n",
    "        data[dataname]['i_test'] = data[dataname]['i_test'][:-1]\n",
    "    else:\n",
    "        # set all indices to zero\n",
    "        data[dataname]['i_test'] = np.zeros(data[dataname]['nt_obs'], dtype=int)\n",
    "        \n",
    "    # switch on or off data fitting\n",
    "    data[dataname]['prior_only'] = int(prior_only)\n",
    "    \n",
    "    # add light data\n",
    "    t = np.arange(data[dataname]['nt'])*data[dataname]['dt']\n",
    "    data[dataname]['E'] = np.interp(t, xp=data_gridded[dataname]['time'], fp=par)\n",
    "    \n",
    "    # real count data\n",
    "    data[dataname]['obs_count'] = data_gridded[dataname]['counts'][:, ind_obs]\n",
    "    \n",
    "    # consistency check\n",
    "    if len(data[dataname]['i_test']) != data[dataname]['nt_obs']:\n",
    "        raise ValueError('Invalid number of testing indices for \"{}\" (expected {}, got {}).'.format(dataname,data[dataname]['nt_obs'],len(data[dataname]['i_test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_data:\n",
    "    for i,dataname in enumerate(data):\n",
    "        nrows = 3\n",
    "\n",
    "        v_min = data[dataname]['v_min']\n",
    "        delta_v = 1.0/data[dataname]['delta_v_inv']\n",
    "        v = v_min * 2**(np.arange(data[dataname]['m'])*delta_v) \n",
    "        t = np.arange(data[dataname]['nt'])*data[dataname]['dt']\n",
    "\n",
    "\n",
    "        fig,axs = plt.subplots(nrows=nrows, sharex=True, figsize=(12,4*nrows))\n",
    "\n",
    "        ax = axs[0]\n",
    "        ax.set_title('processed '+desc[dataname], size=20)\n",
    "        ax.plot(t, data[dataname]['E'], color='gold')\n",
    "        ax.set(ylabel='E')\n",
    "\n",
    "        ax = axs[1]\n",
    "        pc = ax.pcolormesh(data[dataname]['t_obs'], v, data[dataname]['obs'], shading='auto')\n",
    "        ax.set(ylabel='size ({})'.format(size_units))\n",
    "        #ax.text(0.01, 0.95, desc[dataname], color='white', size=16, transform=ax.transAxes, ha='left', va='top')\n",
    "        add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='size class proportion')\n",
    "        ax.set_xlim(left=0.0)\n",
    "\n",
    "        ax = axs[2]\n",
    "        pc = ax.pcolormesh(data[dataname]['t_obs'], v, data[dataname]['obs_count'], shading='auto')\n",
    "        ax.set(ylabel='size ({})'.format(size_units))\n",
    "        #ax.text(0.01, 0.95, desc[dataname], color='white', size=16, transform=ax.transAxes, ha='left', va='top')\n",
    "        add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='counts')\n",
    "        ax.set_xlim(left=0.0)\n",
    "    axs[-1].set_xlabel('time (minutes)')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_model = {\n",
    "    #'m1':'m1',\n",
    "    'm2':'m2',\n",
    "    #'m3':'m3',\n",
    "    'm4':'m4',\n",
    "    'm5':'m5',\n",
    "    #'m6':'m6',\n",
    "    #'m7':'m7',\n",
    "    #'m8':'m8',\n",
    "    #'m9':'m9',\n",
    "    #'m10':'m10',\n",
    "    #'m11':'m11',\n",
    "    'm12':'m12',\n",
    "    #'m13':'m13',\n",
    "    'm14':'m14',\n",
    "}\n",
    "# preparing for some regular expression magic\n",
    "model_code_replacements = {\n",
    "    'm1':(),\n",
    "    'm2':(),\n",
    "    'm3':(),\n",
    "    'm4':(),\n",
    "    'm5':(),\n",
    "    'm6':(),\n",
    "    'm7':(),\n",
    "    'm8':(),\n",
    "    'm9':(),\n",
    "    'm10':(),\n",
    "    'm11':(),\n",
    "    'm12':(),\n",
    "    'm13':(),\n",
    "    'm14':(),\n",
    "}\n",
    "model_stan_key = {\n",
    "    'm1':'c1',\n",
    "    'm2':'c2',\n",
    "    'm3':'c3',\n",
    "    'm4':'c4',\n",
    "    'm5':'c5',\n",
    "    'm6':'c6',\n",
    "    'm7':'c7',\n",
    "    'm8':'c8',\n",
    "    'm9':'c9',\n",
    "    'm10':'c10',\n",
    "    'm11':'c11',\n",
    "    'm12':'c12',\n",
    "    'm13':'c13',\n",
    "    'm14':'c14',\n",
    "}\n",
    "stan_files = {\n",
    "    'c1':'stancode_gallery3/matrixmodel_mlmultinom_estinilnorm2_freedelta_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c2':'stancode_gallery3/matrixmodel_mlmultinom_estinilnorm2_monodelta2_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c3':'stancode_gallery3/matrixmodel_mlmultinom_estinilnorm2_monodelta2_gammaiv6_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c4':'stancode_gallery3/matrixmodel_mlmultinom_estinilnorm2_monodelta2_respv1_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c5':'stancode_gallery3/matrixmodel_mlmultinom_estinilnorm2_monodelta2_respv2_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c6':'stancode_gallery3/matrixmodel_mlmultinom_estinilnorm2_monodelta2_respiv6_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c7':'stancode_gallery3/matrixmodel_mlmultinom_estinilnorm2_monodelta2_respiv7_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c8':'stancode_gallery3/matrixmodel_mlmultinom_estinilnorm2_monodelta2-lightsig_respiv6_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c9':'stancode_gallery3/matrixmodel_mlmultinom_estinilnorm2_monodelta2-lightsig_respiv7_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c10':'stancode_gallery3/matrixmodel_mlmultinom_estinilnorm2_monodelta2-lightsig_respv2_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c11':'stancode_gallery3/matrixmodel_mlmultinom_estinilnorm2_monodelta2_resp_gammaiv6_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c12':'stancode_gallery3/matrixmodel_mlmultinom_estinilnorm2_monodelta2_resp_gammaiv7_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c13':'stancode_gallery3/matrixmodel_mlmultinom_estinilnorm2_monodelta2-lightsig_resp_gammaiv6_normparam_trackgrowthvol_xval2.stan',\n",
    "    'c14':'stancode_gallery3/matrixmodel_mlmultinom_estinilnorm2_monodelta2-lightsig_resp_gammaiv7_normparam_trackgrowthvol_xval2.stan',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pystan\n",
    "import re\n",
    "import time\n",
    "\n",
    "def get_max_rhat(fit):\n",
    "    s = fit.summary()\n",
    "    irhat = s['summary_colnames'].index(\"Rhat\")\n",
    "    return np.nanmax(s['summary'][:,irhat])\n",
    "\n",
    "if 'models' not in globals():\n",
    "    models = {}\n",
    "if 'mcmcs' not in globals():\n",
    "    mcmcs = {}\n",
    "if 'maxrhats' not in globals():\n",
    "    maxrhats = {}\n",
    "if 'sampling_time' not in globals():\n",
    "    sampling_time = {}\n",
    "if 'num_tries' not in globals():\n",
    "    num_tries = 3\n",
    "    \n",
    "try_again = True\n",
    "refit_all = False\n",
    "\n",
    "refit_required = {}\n",
    "stan_base_code = {}\n",
    "for key,stan_file in stan_files.items():\n",
    "    with open(stan_file) as f:\n",
    "        stan_base_code[key] = f.read()\n",
    "\n",
    "stan_code = {}\n",
    "for model in desc_model:\n",
    "    code_split = stan_base_code[model_stan_key[model]].split('\\n')\n",
    "    code_split_new = []\n",
    "    for line in code_split:\n",
    "        line_new = line\n",
    "        for replacement in model_code_replacements[model]:\n",
    "            m = re.match(replacement[0],line_new)\n",
    "            if m:\n",
    "                line_new = m.groups(0)[0]+replacement[1]\n",
    "                print('{}: patching in \"{}\"'.format(model, line_new))\n",
    "        code_split_new.append(line_new)\n",
    "                \n",
    "    stan_code[model] = '\\n'.join(code_split_new)\n",
    "\n",
    "for model in desc_model:\n",
    "    refit_required[model] = True\n",
    "    if model in models and models[model].model_code == stan_code[model]:\n",
    "        print('{}: unchanged code, not recompiling'.format(model))\n",
    "        refit_required[model] = False\n",
    "    else:\n",
    "        if model in models:\n",
    "            print('{}: code change detected, recompiling'.format(model))\n",
    "        else:\n",
    "            print('{}: compiling'.format(model))\n",
    "        models[model] = pystan.StanModel(model_code=stan_code[model], model_name=model, obfuscate_model_name=False)\n",
    "\n",
    "# run a bunch of experiments -- this may take a while\n",
    "for model in models:\n",
    "    if model not in maxrhats:\n",
    "        maxrhats[model] = {}\n",
    "    if model not in sampling_time:\n",
    "        sampling_time[model] = {}\n",
    "    for dataname in data:\n",
    "        if dataname not in maxrhats[model]:\n",
    "            maxrhats[model][dataname] = []\n",
    "        if dataname not in sampling_time[model]:\n",
    "            sampling_time[model][dataname] = []\n",
    "        if model in mcmcs:\n",
    "            if dataname in mcmcs[model] and not refit_all and not refit_required[model]:\n",
    "                print('{}: found existing results:'.format(model))\n",
    "                print('{} ({})'.format(model, desc_model[model])) \n",
    "                print('\\n'.join(x for x in mcmcs[model][dataname].__str__().split('\\n') if '[' not in x))\n",
    "                rhat_max = get_max_rhat(mcmcs[model][dataname])\n",
    "                if try_again and rhat_max >= 1.1:\n",
    "                    print('{}: found Rhat={:.3f}, trying again'.format(model,rhat_max))\n",
    "                else:\n",
    "                    print('{}: not re-running model'.format(model))\n",
    "                    print()\n",
    "                    continue\n",
    "            elif refit_all:\n",
    "                print('{}: refit_all is active, re-running model'.format(model))\n",
    "            elif refit_required[model]:\n",
    "                print('{}: change in model code requires re-running model'.format(model))\n",
    "        else:\n",
    "            mcmcs[model] = {}\n",
    "        for itry in range(num_tries):\n",
    "            t0 = time.time()\n",
    "            mcmcs[model][dataname] = models[model].sampling(data=data[dataname], iter=2000, chains=num_chains)\n",
    "            sampling_time[model][dataname].append(time.time() - t0) # in seconds\n",
    "            # get max Rhat\n",
    "            rhat_max = get_max_rhat(mcmcs[model][dataname])\n",
    "            maxrhats[model][dataname].append(rhat_max)\n",
    "            print('{}: in try {}/{} found Rhat={:.3f}'.format(model, itry+1, num_tries, rhat_max), end='')\n",
    "            if rhat_max < 1.1 or itry == num_tries - 1:\n",
    "                print()\n",
    "                break\n",
    "            print(', trying again')\n",
    "        \n",
    "        print('{} ({})'.format(model, desc_model[model])) \n",
    "        print('\\n'.join(x for x in mcmcs[model][dataname].__str__().split('\\n') if '[' not in x))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['axes.labelsize'] = 20\n",
    "mpl.rcParams['legend.fontsize'] = 16\n",
    "mpl.rcParams['axes.titlesize'] = 26\n",
    "mpl.rcParams['figure.figsize'] = (24,12)\n",
    "mpl.rcParams['xtick.labelsize'] = 16\n",
    "mpl.rcParams['ytick.labelsize'] = 16\n",
    "\n",
    "# set the color for each model\n",
    "num_model = len(mcmcs)\n",
    "if num_model <= 10:\n",
    "    colors_model = {model:'C{}'.format(imodel) for imodel,model in enumerate(mcmcs)}\n",
    "else:\n",
    "    colors_model = {model:mpl.cm.viridis(imodel/(num_model-1)) for imodel,model in enumerate(mcmcs)}\n",
    "    \n",
    "maxrhats_final = {model:{dataname:get_max_rhat(mcmcs[model][dataname]) for dataname in data} for model in mcmcs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_desc = {'divrate':'daily division rate','E_star':'E*'}\n",
    "# add known values here\n",
    "reference_values = {'zinser':{'divrate':0.69}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ylim_top = 0\n",
    "for dataname in data:\n",
    "    for model in mcmcs:\n",
    "        ylim_top = max(ylim_top, len(maxrhats[model][dataname]))\n",
    "ylim_top += 1\n",
    "\n",
    "fig, axs = plt.subplots(nrows=len(data), figsize=(max(24,len(mcmcs)*4.5),len(data)*9), squeeze=False, sharex=True, sharey=True)\n",
    "for ax,dataname in zip(axs.flat,data):\n",
    "    xticks = []\n",
    "    xticklabels = []\n",
    "    for i,model in enumerate(mcmcs):\n",
    "        \n",
    "        height_bad = sum(rh > 1.1 for rh in maxrhats[model][dataname])\n",
    "        height_good = len(maxrhats[model][dataname]) - height_bad\n",
    "        \n",
    "        x = i\n",
    "        ax.bar(x=x, height=height_bad, color='tab:red', label='max $\\\\\\\\hat{R}$ > 1.1')\n",
    "        ax.bar(x=x, height=height_good, bottom=height_bad, color='tab:green', label='max $\\\\hat{R} \\le$ 1.1')\n",
    "        \n",
    "        if len(sampling_time[model][dataname]) != height_bad+height_good:\n",
    "            print('{}, {}: Timing information inconsistent.'.format(dataname, desc_model[model]))\n",
    "        else:\n",
    "            for it, t in enumerate(sampling_time[model][dataname]):\n",
    "                ax.text(x, it+0.5, '{:.0f}:{:02.0f}'.format(t//60, t%60), ha='center', va='center', size=30)\n",
    "            \n",
    "        xticks.append(x)\n",
    "        xticklabels.append(desc_model[model].replace(',',',\\n'))\n",
    "    \n",
    "    ax.set(ylabel='number of Stan sampling runs', xticks=xticks, ylim=(0, ylim_top))\n",
    "    ax.set_title('convergence/$\\hat{R}$ statistics for '+desc[dataname], size=20)\n",
    "    ax.set_xticklabels(xticklabels)#, rotation=8)\n",
    "    ax.grid(axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated code can handle all data[dataname]['i_test'] == 0 and draw only a single bar\n",
    "if np.all(data[dataname]['i_test'] == 0):\n",
    "    num_bars = 1\n",
    "else:\n",
    "    num_bars = 3\n",
    "\n",
    "height = np.zeros(num_bars)\n",
    "for dataname in data:\n",
    "    obs = data[dataname]['obs']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(max(24,len(mcmcs)*4.5),9))\n",
    "    xticks = []\n",
    "    xticklabels = []\n",
    "    for i,model in enumerate(mcmcs):\n",
    "        mod_mean = np.mean(mcmcs[model][dataname]['mod_obspos'], axis=0)\n",
    "        mod_mean /= np.sum(mod_mean, axis=0)\n",
    "        \n",
    "        e = np.sum((mod_mean-obs)**2,axis=0)\n",
    "        #print(desc_model[model],e)\n",
    "        \n",
    "        height[0] = np.mean(e)\n",
    "        if num_bars > 1:\n",
    "            height[1] = np.mean(e[data[dataname]['i_test'] == 0])\n",
    "            height[2] = np.mean(e[data[dataname]['i_test'] == 1])\n",
    "        \n",
    "        x = (num_bars+1)*i+np.arange(num_bars)\n",
    "        ax.bar(x=x, height=height, color=colors_model[model])\n",
    "        for xx,text in zip(x,['overall mean','training mean','test mean']):\n",
    "            ax.text(xx, 0, '  '+text, rotation=90, ha='center', va='bottom', size=20)\n",
    "        if maxrhats_final[model][dataname] > 1.1:\n",
    "            ax.text(x[num_bars//3], 0, '  no convergence ($\\\\hat{R}>1.1$)', rotation=45, ha='center', va='bottom', size=30, color='darkred')\n",
    "        xticks.append(x[num_bars//3])\n",
    "        xticklabels.append(desc_model[model].replace(',',',\\n').replace('(','\\n('))\n",
    "    \n",
    "    if ax.get_ylim()[1] > 0.005:\n",
    "        ax.set_ylim(top=0.005)\n",
    "    ax.set(ylabel='sum of squared column differences', xticks=xticks)\n",
    "    ax.set_title('model misfit for '+desc[dataname], size=20)\n",
    "    ax.set_xticklabels(xticklabels)#, rotation=8)\n",
    "    ax.grid(axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'size_units' not in globals():\n",
    "    size_units = 'fg C cell$^{-1}$'\n",
    "\n",
    "prop_labels = {\n",
    "    'growth':'cell growth ({} h$^{{-1}}$)'.format(size_units),\n",
    "    'division':'division rate (h$^{-1}$)',\n",
    "    'respiration':'respiration + exudation\\n({} h$^{{-1}}$)'.format(size_units),\n",
    "}\n",
    "\n",
    "for dataname in data:\n",
    "    \n",
    "    t = data[dataname]['dt']*np.arange(data[dataname]['nt'])/60.0\n",
    "    dt_h = data[dataname]['dt']/60.0\n",
    "    \n",
    "    for model in mcmcs:\n",
    "        fig, axs = plt.subplots(nrows=3, figsize=(14,6*3), sharex=True)\n",
    "\n",
    "        cell_count = mcmcs[model][dataname]['cell_count']\n",
    "        \n",
    "        for ax, prop in zip(axs, ('growth', 'division', 'respiration')):\n",
    "\n",
    "            if prop == 'growth':\n",
    "                plotprop = mcmcs[model][dataname]['growth_vol_gain']/cell_count/dt_h\n",
    "                x = t\n",
    "            elif prop == 'division':\n",
    "                plotprop = (np.log(cell_count[:,1:])-np.log(cell_count[:,:-1]))/(t[1:]-t[:-1])\n",
    "                x = 0.5 * (t[1:] + t[:-1])\n",
    "            elif prop == 'respiration':\n",
    "                plotprop = mcmcs[model][dataname]['resp_vol_loss']/cell_count/dt_h\n",
    "                x = t\n",
    "            else:\n",
    "                raise ValueError('Unknown prop \"{}\".'.format(prop))\n",
    "            \n",
    "            qq = np.percentile(plotprop, q=(5,25,50,75,95), axis=0)\n",
    "\n",
    "            sc = ax.fill_between(x, qq[0,:], qq[-1,:], alpha=0.25, color=colors_model[model])\n",
    "            ax.fill_between(x, qq[1,:], qq[-2,:], alpha=0.5, facecolor=sc.get_facecolor()[0])\n",
    "            ax.plot(x, qq[2,:], color=sc.get_facecolor()[0][:-1], lw=2)\n",
    "\n",
    "            if dataname == 'zinser':\n",
    "                with nc4.Dataset('data/zinser_growthdivresp.nc') as nc:\n",
    "                    ax.plot(nc[prop+'/time'][:], np.maximum(0.0, nc[prop+'/'+prop][:]), color='black', marker='o', lw=2)\n",
    "            \n",
    "            ax.set_ylim(bottom=0.0)\n",
    "            ax.set_xlim((0, t[-1]))\n",
    "            ax.set(ylabel=prop_labels[prop])\n",
    "            ax.grid(True)\n",
    "        \n",
    "        axs[0].set_title(desc_model[model] + ' ' + desc[dataname])\n",
    "        axs[-1].set(xticks = np.arange(0,t[-1],6), xlabel='time since start of experiment (h)')\n",
    "        if axs[-1].get_ylim()[-1] < axs[0].get_ylim()[-1]:\n",
    "            axs[-1].set_ylim(top=axs[0].get_ylim()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_labels = True\n",
    "for dataname in data:\n",
    "    if 'zinser' in dataname:\n",
    "        fig, ax = plt.subplots(figsize=(14,14))\n",
    "        ax.set_title(desc[dataname], size=20)\n",
    "        \n",
    "        for model in mcmcs:\n",
    "            # misfit to data\n",
    "\n",
    "            obs = data[dataname]['obs']\n",
    "\n",
    "            tmp = mcmcs[model][dataname]['mod_obspos']\n",
    "            tmp/= np.sum(tmp, axis=1)[:,None,:]\n",
    "            tmp -= obs[None,:,:]\n",
    "            tmp **= 2\n",
    "            \n",
    "            if np.all(data[dataname]['i_test'] == 0):\n",
    "                e0 = np.mean(np.sum(tmp, axis=1), axis=1)\n",
    "                xlabel_suffix = ''\n",
    "            else:\n",
    "                e0 = np.mean(np.sum(tmp[:,:,data[dataname]['i_test'] == 1], axis=1), axis=1)\n",
    "                xlabel_suffix = ' (test data)'\n",
    "            \n",
    "            # misfit to division rate\n",
    "\n",
    "            e1 = np.abs(mcmcs[model][dataname]['divrate'] - reference_values[dataname]['divrate'])\n",
    "        \n",
    "            q0 = np.percentile(e0, q=(5,25,50,75,95))\n",
    "            q1 = np.percentile(e1, q=(5,25,50,75,95))\n",
    "            \n",
    "            eb = ax.errorbar(x=q0[2], y=q1[2], xerr=np.array((q0[2]-q0[0], q0[-1]-q0[2]))[:,None], marker='o', ms=10, label=desc_model[model], color=colors_model[model])\n",
    "            ax.errorbar(x=q0[2], y=q1[2], yerr=np.array((q1[2]-q1[0], q1[-1]-q1[2]))[:,None], color=eb[0].get_color())\n",
    "            \n",
    "            if add_labels:\n",
    "                ax.text(q0[2], q1[2], ' '+desc_model[model], color=eb[0].get_color(), size=20)\n",
    "            \n",
    "            if maxrhats_final[model][dataname] > 1.1:\n",
    "                ax.plot(q0[2], q1[2], marker='x', color='darkred', zorder=10, markersize=30, markeredgewidth=3)\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "        ax.set(xlabel='size distribution misfit'+xlabel_suffix, ylabel='daily division rate misfit')\n",
    "        ax.set_xlim(left=0.0)\n",
    "        ax.set_ylim(bottom=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datanames = tuple(data.keys())\n",
    "if len(datanames) > 1:\n",
    "    fig, ax = plt.subplots(figsize=(14,14))\n",
    "\n",
    "    for model in mcmcs:\n",
    "        qq = {}\n",
    "        # misfit to data\n",
    "        for dataname in datanames:\n",
    "            obs = data[dataname]['obs']\n",
    "\n",
    "            tmp = mcmcs[model][dataname]['mod_obspos']\n",
    "            tmp/= np.sum(tmp, axis=1)[:,None,:]\n",
    "            tmp -= obs[None,:,:]\n",
    "            tmp **= 2\n",
    "\n",
    "            if np.all(data[dataname]['i_test'] == 0):\n",
    "                e0 = np.mean(np.sum(tmp, axis=1), axis=1)\n",
    "            else:\n",
    "                e0 = np.mean(np.sum(tmp[:,:,data[dataname]['i_test'] == 1], axis=1), axis=1)\n",
    "\n",
    "            qq[dataname] = np.percentile(e0, q=(5,25,50,75,95))\n",
    "\n",
    "        q0 = qq[datanames[0]]\n",
    "        q1 = qq[datanames[1]]\n",
    "\n",
    "        eb = ax.errorbar(x=q0[2], y=q1[2], xerr=np.array((q0[2]-q0[0], q0[-1]-q0[2]))[:,None], marker='o', ms=10, label=desc_model[model], color=colors_model[model])\n",
    "        ax.errorbar(x=q0[2], y=q1[2], yerr=np.array((q1[2]-q1[0], q1[-1]-q1[2]))[:,None], color=eb[0].get_color())\n",
    "        if maxrhats_final[model][dataname] > 1.1:\n",
    "            ax.plot(q0[2], q1[2], marker='x', color='darkred', zorder=10, markersize=30, markeredgewidth=3)\n",
    "\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    ax.set(xlabel='{} size distribution misfit'.format(desc[datanames[0]]), \n",
    "           ylabel='{} size distribution misfit'.format(desc[datanames[1]]))\n",
    "    ax.set_xlim(left=0.0)\n",
    "    ax.set_ylim(bottom=0.0)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fig2a = pd.read_csv('data/Zinser_Figure2A.csv')\n",
    "t_zinser = data_fig2a['exper time'] * 60\n",
    "ab_mean_norm = 0.5*(data_fig2a['cells A'].values/data_fig2a['cells A'].values[0] + \n",
    "                    data_fig2a['cells B'].values/data_fig2a['cells B'].values[0])\n",
    "\n",
    "add_labels = True\n",
    "for dataname in data:\n",
    "    if 'zinser' in dataname:\n",
    "        fig, ax = plt.subplots(figsize=(14,14))\n",
    "        ax.set_title(desc[dataname], size=20)\n",
    "        \n",
    "        for model in mcmcs:\n",
    "            # make sure the time is right, if not implement something fancier\n",
    "            assert all(t_zinser.values[:-1] == data[dataname]['t_obs'])\n",
    "            \n",
    "            # misfit to normalized abundance\n",
    "            \n",
    "            e0 = np.mean(np.abs(np.sum(mcmcs[model][dataname]['mod_obspos'], axis=1)[:,1:]-ab_mean_norm[1:-1]), axis=1)\n",
    "            \n",
    "            # misfit to division rate\n",
    "\n",
    "            e1 = np.abs(mcmcs[model][dataname]['divrate'] - reference_values[dataname]['divrate'])\n",
    "        \n",
    "            q0 = np.percentile(e0, q=(5,25,50,75,95))\n",
    "            q1 = np.percentile(e1, q=(5,25,50,75,95))\n",
    "            \n",
    "            eb = ax.errorbar(x=q0[2], y=q1[2], xerr=np.array((q0[2]-q0[0], q0[-1]-q0[2]))[:,None], marker='o', ms=10, label=desc_model[model], color=colors_model[model])\n",
    "            ax.errorbar(x=q0[2], y=q1[2], yerr=np.array((q1[2]-q1[0], q1[-1]-q1[2]))[:,None], color=eb[0].get_color())\n",
    "            if add_labels:\n",
    "                ax.text(q0[2], q1[2], ' '+desc_model[model], color=eb[0].get_color(), size=20)\n",
    "            if maxrhats_final[model][dataname] > 1.1:\n",
    "                ax.plot(q0[2], q1[2], marker='x', color='darkred', zorder=10, markersize=30, markeredgewidth=3)\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "        ax.set(xlabel='normalized abundance misfit (hourly division rate)', ylabel='daily division rate misfit')\n",
    "        ax.set_xlim(left=0.0)\n",
    "        ax.set_ylim(bottom=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for param in ('divrate','E_star'):\n",
    "    for dataname in data:\n",
    "        num_mcmcs = len(mcmcs)\n",
    "        fig, ax = plt.subplots(figsize=(24,3*num_mcmcs))\n",
    "        ax.set_title('{} for {}'.format(param_desc[param], desc[dataname]))\n",
    "        ax.violinplot([mcmcs[model][dataname][param] for model in mcmcs], showmedians=True, vert=False)\n",
    "        ax.invert_yaxis()\n",
    "        ax.grid(axis='x')\n",
    "        ax.set(yticks=np.arange(1,num_mcmcs+1), yticklabels=[desc_model[model].replace(',',',\\n') for model in mcmcs])\n",
    "        if dataname in reference_values and param in reference_values[dataname]:\n",
    "            ax.axvline(reference_values[dataname][param], color='tab:green', lw=3)\n",
    "        for i,model in enumerate(mcmcs):\n",
    "            if maxrhats_final[model][dataname] > 1.1:\n",
    "                ax.text(0.5, i+1, 'no convergence ($\\\\hat{R}>1.1$)', color='darkred', size=26, transform=ax.get_yaxis_transform(), ha='center', va='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for dataname in data:\n",
    "    for model,mcmc in mcmcs.items():\n",
    "        j = data_gridded[dataname]['delta_v_inv'] + 1\n",
    "        m = data_gridded[dataname]['m']\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(20,6))\n",
    "        ax.set_title(desc_model[model] + '\\n' + desc[dataname])\n",
    "        ax.boxplot(mcmc[dataname]['delta'])\n",
    "        xlabels = [str(x) for x in range(j,m+1)]\n",
    "        xlabels[0] = 'j='+xlabels[0]\n",
    "        xlabels[-1] = 'm='+xlabels[-1]\n",
    "        ax.set_xticklabels(xlabels)\n",
    "        ax.grid(axis='y')\n",
    "        ax.set_ylabel('$\\\\delta_{max}$')\n",
    "        \n",
    "        if maxrhats_final[model][dataname] > 1.1:\n",
    "            ax.text(0.5, 0.5, 'no convergence ($\\\\hat{R}>1.1$)', color='darkred', size=26, transform=ax.transAxes, ha='center', va='center')\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_fig2a = pd.read_csv('data/Zinser_Figure2A.csv')\n",
    "\n",
    "t_zinser = data_fig2a['exper time'] * 60\n",
    "a_norm = data_fig2a['cells A'].copy()\n",
    "a_norm /= a_norm[0]\n",
    "b_norm = data_fig2a['cells B'].copy()\n",
    "b_norm /= b_norm[0]\n",
    "\n",
    "colors = {'model':'darkred', 'obs':'0.1'}\n",
    "\n",
    "norm = mpl.colors.Normalize(0.0,0.15)\n",
    "norm_diff = mpl.colors.Normalize(-0.1,0.1)\n",
    "\n",
    "for dataname in data:\n",
    "    t = data[dataname]['dt']*np.arange(data[dataname]['nt'])\n",
    "    delta_v = 1.0/data_gridded[dataname]['delta_v_inv']\n",
    "    v_ext = data[dataname]['v_min'] * 2**(np.arange(data[dataname]['m']+1)*delta_v) \n",
    "    v = v_ext[:-1]\n",
    "    v_width = v_ext[1:] - v_ext[:-1]\n",
    "        \n",
    "    for model,mcmc in mcmcs.items():\n",
    "        \n",
    "        res = {'model':np.mean(mcmc[dataname]['mod_obspos'], axis=0), 'obs':data[dataname]['obs']}\n",
    "        res_sum1 = res['model']/np.sum(res['model'], axis=0)[None,:]\n",
    "        diff = res_sum1-res['obs']\n",
    "\n",
    "        if maxrhats_final[model][dataname] > 1.1:\n",
    "            fig, ax = plt.subplots(figsize=(24,4))\n",
    "            ax.set_title(desc_model[model] + '\\n' + desc[dataname])\n",
    "            ax.set(xticks=[], yticks=[])\n",
    "            ax.text(0.5, 0.5, 'no convergence ($\\\\hat{R}>1.1$)', color='darkred', size=26, transform=ax.transAxes, ha='center', va='center')\n",
    "            continue\n",
    "        \n",
    "        fig,axs = plt.subplots(6,1,sharex=True,figsize=(24,40))\n",
    "        axs[0].set_title(desc_model[model] + '\\n' + desc[dataname])\n",
    "\n",
    "        ax = axs[0]\n",
    "        ax.plot(t, data[dataname]['E'], color='gold')\n",
    "        ax.set(xlim=(data[dataname]['t_obs'][0],t[-1]), ylabel='PAR')\n",
    "\n",
    "        ax = axs[1]\n",
    "        pc = ax.pcolormesh(data[dataname]['t_obs'], v, res['obs'],norm=norm, shading='auto')\n",
    "        ax.set(ylabel='size ({})'.format(size_units), title='size distribution data')\n",
    "        add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='size class proportion')\n",
    "\n",
    "        ax = axs[2]\n",
    "        ax.set(ylabel='size ({})'.format(size_units), title='size distribution model posterior')\n",
    "        pc = ax.pcolormesh(data[dataname]['t_obs'], v, res_sum1,norm=norm, shading='auto')\n",
    "\n",
    "        ax = axs[3]\n",
    "        pc = ax.pcolormesh(data[dataname]['t_obs'], v, diff,norm=norm_diff, cmap='PiYG', shading='auto')\n",
    "        ax.set(ylabel='size ({})'.format(size_units), title='model - data misfit')\n",
    "        add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='difference in size class proportion')\n",
    "        \n",
    "        qq = np.percentile(np.sum(mcmc[dataname]['mod_obspos'], axis=1), axis=0, q=(5,25,50,75,95))\n",
    "    \n",
    "        ax = axs[4]\n",
    "        ax.fill_between(data[dataname]['t_obs'], qq[0,:], qq[-1,:], alpha=0.25, color='gold')\n",
    "        ax.fill_between(data[dataname]['t_obs'], qq[1,:], qq[-2,:], alpha=0.5, color='gold')\n",
    "        ax.plot(data[dataname]['t_obs'], qq[2,:], color='gold')\n",
    "        if 'zinser' in dataname:\n",
    "            ax.plot(t_zinser, a_norm, color='black', marker='s', label='Zinser normalized \"cells A\"')\n",
    "            ax.plot(t_zinser, b_norm, color='red', marker='^', label='Zinser normalized \"cells B\"')\n",
    "            for iday in range(2):\n",
    "                ax.axvspan(iday*24*60+12*60, iday*24*60+22*60, color='0.7', zorder=0)\n",
    "            ax.legend()\n",
    "        ax.grid(True)\n",
    "        ax.set(ylabel='sum across size classes', title='relative increase in population size (division)')\n",
    "\n",
    "        ax = axs[5]\n",
    "        prop = np.mean(np.abs(diff),axis=0)\n",
    "        ax.plot(data[dataname]['t_obs'], prop, label='mean(abs(diff)), avg: {:.6f}'.format(np.mean(prop)))\n",
    "        prop = np.sum(diff**2,axis=0)\n",
    "        ax.plot(data[dataname]['t_obs'], prop, label='sum(diff$^2$), avg: {:.6f}'.format(np.mean(prop)))\n",
    "        ax.set(xlabel='time (minutes)', ylabel='model-observation misfit')\n",
    "        ax.grid(True)\n",
    "        ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'varnames_save' not in globals():\n",
    "    varnames_save = None\n",
    "\n",
    "save_only_converged = True\n",
    "\n",
    "if savename_output is not None:    \n",
    "    with nc4.Dataset(savename_output, 'w') as nc:\n",
    "        for dataname in data:\n",
    "            ncg = nc.createGroup(dataname)\n",
    "\n",
    "            if save_stan_output:\n",
    "                dimensions = {\n",
    "                    'obstime':int(data[dataname]['nt_obs']),\n",
    "                    'time':int(data[dataname]['nt']),\n",
    "                    'sizeclass':int(data[dataname]['m']),\n",
    "                    'm_minus_j_plus_1':int(data[dataname]['m']-data[dataname]['delta_v_inv']),\n",
    "                }\n",
    "                dimensions_inv = {v:k for k,v in dimensions.items()}\n",
    "                for d in dimensions:\n",
    "                    ncg.createDimension(d, dimensions[d])\n",
    "                    \n",
    "                ncg.createVariable('time', int, ('time',))\n",
    "                ncg.variables['time'][:] = int(data[dataname]['dt']) * np.arange(data[dataname]['nt'])\n",
    "                ncg.variables['time'].units = 'minutes since start of experiment'\n",
    "                \n",
    "                ncg.createVariable('obstime', int, ('obstime',))\n",
    "                ncg.variables['obstime'][:] = data[dataname]['t_obs'].astype(int)\n",
    "                ncg.variables['obstime'].units = 'minutes since start of experiment'\n",
    "                ncg.variables['obstime'].long_name = 'time of observations'\n",
    "\n",
    "                for v in ('dt', 'm', 'v_min', 'delta_v_inv', 'obs', 'i_test', 'E', 'obs_count'):\n",
    "                    if isinstance(data[dataname][v], int):\n",
    "                        ncg.createVariable(v, int, zlib=True)\n",
    "                        ncg.variables[v][:] = data[dataname][v]\n",
    "                    elif isinstance(data[dataname][v], float):\n",
    "                        ncg.createVariable(v, float, zlib=True)\n",
    "                        ncg.variables[v][:] = data[dataname][v]\n",
    "                    else:\n",
    "                        dims = tuple(dimensions_inv[d] for d in data[dataname][v].shape)\n",
    "                        ncg.createVariable(v, data[dataname][v].dtype, dims, zlib=True)\n",
    "                        ncg.variables[v][:] = data[dataname][v]\n",
    "                \n",
    "                for imodel,model in enumerate(mcmcs):\n",
    "                    if save_only_converged and get_max_rhat(mcmcs[model][dataname]) > 1.1:\n",
    "                        logging.warning('Model \"{}\" did not converge -- skipping.'.format(model))\n",
    "                        continue\n",
    "                    ncm = ncg.createGroup(model)\n",
    "                    \n",
    "                    dimensions['sample'] = mcmcs[model][dataname]['mod_obspos'].shape[0]\n",
    "                    dimensions_inv[dimensions['sample']] = 'sample'\n",
    "                    ncm.createDimension('sample', dimensions['sample'])\n",
    "                    if 'tau[1]' in mcmcs[model][dataname].flatnames:\n",
    "                        dimensions['tau'] = mcmcs[model][dataname]['tau'].shape[1]\n",
    "                        dimensions_inv[dimensions['tau']] = 'tau'\n",
    "                        ncm.createDimension('tau', dimensions['tau'])\n",
    "                    \n",
    "                    # write model description\n",
    "                    ncm.setncattr('description', desc_model[model])\n",
    "                    ncm.setncattr('code', stan_files[model_stan_key[model]])\n",
    "                    \n",
    "                    varnames = set(v.split('[')[0] for v in mcmcs[model][dataname].flatnames)\n",
    "                    if varnames_save is None:\n",
    "                        varnames_curr = varnames\n",
    "                    else:\n",
    "                        varnames_curr = varnames_save\n",
    "                        \n",
    "                    for v in varnames_curr:\n",
    "                        if v in varnames:\n",
    "                            dims = tuple(dimensions_inv[d] for d in mcmcs[model][dataname][v].shape)\n",
    "                            ncm.createVariable(v, float, dims, zlib=True)\n",
    "                            ncm.variables[v][:] = mcmcs[model][dataname][v]\n",
    "                        else:\n",
    "                            logging.warning('Cannot find variable \"{}\" for model \"{}\".'.format(v, model))\n",
    "            else:\n",
    "                for i,model in enumerate(mcmcs):\n",
    "                    if i == 0:\n",
    "                        ncg.createDimension('model', len(mcmcs))\n",
    "                        ncg.createDimension('sample', mcmcs[model][dataname]['divrate'].shape[0])\n",
    "\n",
    "                        ncg.createVariable('divrate', float, ('model','sample'))\n",
    "                        ncg.createVariable('sumsqdiff', float, ('model','sample'))\n",
    "                        ncg.variables['sumsqdiff'].setncattr('long_name', 'sum of squared column differences')\n",
    "\n",
    "                    ncg.variables['divrate'][i,:] = mcmcs[model][dataname]['divrate']\n",
    "\n",
    "                    obs = data[dataname]['obs']\n",
    "\n",
    "                    tmp = mcmcs[model][dataname]['mod_obspos']\n",
    "                    tmp/= np.sum(tmp, axis=1)[:,None,:]\n",
    "                    tmp -= obs[None,:,:]\n",
    "                    tmp **= 2\n",
    "\n",
    "                    if np.all(data[dataname]['i_test'] == 0):\n",
    "                        ncg.variables['sumsqdiff'][i,:] = np.mean(np.sum(tmp, axis=1), axis=1)\n",
    "                        if i == 0:\n",
    "                            ncg.variables['sumsqdiff'].setncattr('data_used', 'all data')\n",
    "                    else:\n",
    "                        nc.variables['sumsqdiff'][i,:] = np.mean(np.sum(tmp[:,:,data[dataname]['i_test'] == 1], axis=1), axis=1)\n",
    "                        if i == 0:\n",
    "                            ncg.variables['sumsqdiff'].setncattr('data_used', 'testing data')\n",
    "\n",
    "                    for iv,v in enumerate(('gamma_max','rho_max','xi','xir','E_star')):\n",
    "                        if i == 0:\n",
    "                            ncg.createVariable(v, float, ('model','sample'))\n",
    "                        if v in mcmcs[model][dataname].flatnames:\n",
    "                            ncg.variables[v][i,:] = mcmcs[model][dataname][v]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
